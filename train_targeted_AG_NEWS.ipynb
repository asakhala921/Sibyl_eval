{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted SIB Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    TrainerCallback, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers.trainer_callback import TrainerControl\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transforms import TextMix, SentMix, WordMix\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(text):\n",
    "    return tokenizer(text, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=250)\n",
    "\n",
    "def acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()\n",
    "\n",
    "def CEwST_loss(logits, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Cross Entropy with Soft Target (CEwST) Loss\n",
    "    :param logits: (batch, *)\n",
    "    :param target: (batch, *) same shape as logits, each item must be a valid distribution: target[i, :].sum() == 1.\n",
    "    \"\"\"\n",
    "    logprobs = torch.nn.functional.log_softmax(logits.view(logits.shape[0], -1), dim=1)\n",
    "    batchloss = - torch.sum(target.view(target.shape[0], -1) * logprobs, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return batchloss\n",
    "    elif reduction == 'mean':\n",
    "        return torch.mean(batchloss)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(batchloss)\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported reduction mode.')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1.mean(),\n",
    "        'precision': precision.mean(),\n",
    "        'recall': recall.mean()\n",
    "    }        \n",
    "        \n",
    "def compute_metrics_w_soft_target(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    acc = acc_at_k(labels, preds, k=2)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }\n",
    "\n",
    "class TargetedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = CEwST_loss(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "class TargetedMixturesCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A callback that calculates a confusion matrix on the validation\n",
    "    data and returns the most confused class pairings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, model, tokenizer, **kwargs):\n",
    "        cnf_mat = self.get_confusion_matrix(model, tokenizer, self.dataloader)\n",
    "        new_targets = self.get_most_confused_per_class(cnf_mat)\n",
    "        print(\"New targets:\", new_targets)\n",
    "        control = TrainerControl\n",
    "        control.new_targets = new_targets\n",
    "        if state.global_step < state.max_steps:\n",
    "            control.should_training_stop = False\n",
    "        else:\n",
    "            control.should_training_stop = True\n",
    "        return control\n",
    "        \n",
    "    def get_confusion_matrix(self, model, tokenizer, dataloader, normalize=True):\n",
    "        n_classes = max(dataloader.dataset['label']) + 1\n",
    "        confusion_matrix = torch.zeros(n_classes, n_classes)\n",
    "        with torch.no_grad():\n",
    "            for batch in iter(self.dataloader):\n",
    "                data, targets = batch['text'], batch['label']\n",
    "                data = tokenizer(data, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "                input_ids = data['input_ids'].to(self.device)\n",
    "                attention_mask = data['attention_mask'].to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask).logits\n",
    "                preds = torch.argmax(outputs, dim=1).cpu()\n",
    "                for t, p in zip(targets.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1    \n",
    "            if normalize:\n",
    "                confusion_matrix = confusion_matrix / confusion_matrix.sum(dim=0)\n",
    "        return confusion_matrix\n",
    "\n",
    "    def get_most_confused_per_class(self, confusion_matrix):\n",
    "        idx = torch.arange(len(confusion_matrix))\n",
    "        cnf = confusion_matrix.fill_diagonal_(0).max(dim=1)[1]\n",
    "        return torch.stack((idx, cnf)).T.tolist()\n",
    "\n",
    "class TargetedMixturesCollator:\n",
    "    def __init__(self, tokenize_fn, transform, target_pairs=[], target_prob=1.0, num_classes=4):\n",
    "        self.tokenize_fn = tokenize_fn\n",
    "        self.transform = transform\n",
    "        self.target_pairs = target_pairs\n",
    "        self.target_prob = target_prob\n",
    "        self.num_classes = num_classes\n",
    "        print(\"TargetedMixturesCollator initialized with {}\".format(transform.__class__.__name__))\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        text = [x['text'] for x in batch]\n",
    "        labels = [x['label'] for x in batch]\n",
    "        batch = (text, labels)\n",
    "        batch = self.transform(\n",
    "            batch, \n",
    "            self.target_pairs,   \n",
    "            self.target_prob,\n",
    "            self.num_classes\n",
    "        )\n",
    "        text, labels = batch\n",
    "        batch = self.tokenize_fn(text)\n",
    "        batch['labels'] = torch.tensor(labels)\n",
    "        return batch\n",
    "    \n",
    "class DefaultCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']\n",
    "ts = [TextMix(), SentMix(), WordMix()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "<ipython-input-5-175b65e2d780>:23: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use Dataset.rename_column instead.\n",
      "  test_dataset.rename_column_('label', 'labels')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2a73b27c547ec9dec1fcd29438965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='23000' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 23000/190000 1:26:46 < 10:30:07, 4.42 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.252600</td>\n",
       "      <td>0.919768</td>\n",
       "      <td>0.631333</td>\n",
       "      <td>45.692300</td>\n",
       "      <td>131.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.833500</td>\n",
       "      <td>0.810204</td>\n",
       "      <td>0.645148</td>\n",
       "      <td>45.579800</td>\n",
       "      <td>131.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>0.789817</td>\n",
       "      <td>0.664317</td>\n",
       "      <td>46.238700</td>\n",
       "      <td>129.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>0.785819</td>\n",
       "      <td>0.657255</td>\n",
       "      <td>46.583100</td>\n",
       "      <td>128.802000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.735700</td>\n",
       "      <td>0.782604</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>45.806500</td>\n",
       "      <td>130.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.739400</td>\n",
       "      <td>0.778329</td>\n",
       "      <td>0.735231</td>\n",
       "      <td>45.536300</td>\n",
       "      <td>131.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.744900</td>\n",
       "      <td>0.801634</td>\n",
       "      <td>0.705663</td>\n",
       "      <td>46.013000</td>\n",
       "      <td>130.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.748600</td>\n",
       "      <td>0.769013</td>\n",
       "      <td>0.619499</td>\n",
       "      <td>45.512900</td>\n",
       "      <td>131.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>0.783500</td>\n",
       "      <td>0.723460</td>\n",
       "      <td>46.041700</td>\n",
       "      <td>130.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.757600</td>\n",
       "      <td>0.810306</td>\n",
       "      <td>0.707109</td>\n",
       "      <td>45.343000</td>\n",
       "      <td>132.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.756800</td>\n",
       "      <td>0.774914</td>\n",
       "      <td>0.619632</td>\n",
       "      <td>45.459800</td>\n",
       "      <td>131.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>0.792197</td>\n",
       "      <td>0.635094</td>\n",
       "      <td>45.878100</td>\n",
       "      <td>130.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.731300</td>\n",
       "      <td>0.791658</td>\n",
       "      <td>0.768635</td>\n",
       "      <td>46.085900</td>\n",
       "      <td>130.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.807118</td>\n",
       "      <td>0.719334</td>\n",
       "      <td>46.039900</td>\n",
       "      <td>130.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.773198</td>\n",
       "      <td>0.720695</td>\n",
       "      <td>46.003100</td>\n",
       "      <td>130.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.773355</td>\n",
       "      <td>0.691846</td>\n",
       "      <td>46.732600</td>\n",
       "      <td>128.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.742700</td>\n",
       "      <td>0.793569</td>\n",
       "      <td>0.704106</td>\n",
       "      <td>46.141900</td>\n",
       "      <td>130.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.826250</td>\n",
       "      <td>0.618281</td>\n",
       "      <td>46.454200</td>\n",
       "      <td>129.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.823600</td>\n",
       "      <td>0.736815</td>\n",
       "      <td>45.908000</td>\n",
       "      <td>130.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.720100</td>\n",
       "      <td>0.791263</td>\n",
       "      <td>0.701784</td>\n",
       "      <td>45.321800</td>\n",
       "      <td>132.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.731100</td>\n",
       "      <td>0.798209</td>\n",
       "      <td>0.743873</td>\n",
       "      <td>46.764800</td>\n",
       "      <td>128.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.723400</td>\n",
       "      <td>0.775478</td>\n",
       "      <td>0.744223</td>\n",
       "      <td>45.760100</td>\n",
       "      <td>131.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.725200</td>\n",
       "      <td>0.794547</td>\n",
       "      <td>0.733508</td>\n",
       "      <td>46.265900</td>\n",
       "      <td>129.685000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-TextMix\n",
      "{'eval_loss': 23.948352813720703, 'eval_accuracy': 0.9246052631578947, 'eval_f1': 0.9246351834327998, 'eval_precision': 0.9259357368580343, 'eval_recall': 0.9246052631578947, 'eval_runtime': 100.3019, 'eval_samples_per_second': 75.771, 'epoch': 1.21, 'run': './results/bert-base-uncased-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89844a3cb93045359993c40a904b04a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='15000' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 15000/190000 56:45 < 11:02:11, 4.40 it/s, Epoch 0/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.244000</td>\n",
       "      <td>0.931424</td>\n",
       "      <td>0.616449</td>\n",
       "      <td>45.566500</td>\n",
       "      <td>131.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.853200</td>\n",
       "      <td>0.834879</td>\n",
       "      <td>0.648995</td>\n",
       "      <td>45.592900</td>\n",
       "      <td>131.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.769400</td>\n",
       "      <td>0.846330</td>\n",
       "      <td>0.623239</td>\n",
       "      <td>45.548400</td>\n",
       "      <td>131.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.784100</td>\n",
       "      <td>0.825528</td>\n",
       "      <td>0.646126</td>\n",
       "      <td>45.853100</td>\n",
       "      <td>130.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.797580</td>\n",
       "      <td>0.717232</td>\n",
       "      <td>45.468800</td>\n",
       "      <td>131.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.841722</td>\n",
       "      <td>0.682945</td>\n",
       "      <td>45.399500</td>\n",
       "      <td>132.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.752900</td>\n",
       "      <td>0.792255</td>\n",
       "      <td>0.639005</td>\n",
       "      <td>45.296600</td>\n",
       "      <td>132.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.771150</td>\n",
       "      <td>0.690759</td>\n",
       "      <td>45.566100</td>\n",
       "      <td>131.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.829266</td>\n",
       "      <td>0.651179</td>\n",
       "      <td>45.822800</td>\n",
       "      <td>130.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.857990</td>\n",
       "      <td>0.638667</td>\n",
       "      <td>45.775600</td>\n",
       "      <td>131.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.752700</td>\n",
       "      <td>0.829485</td>\n",
       "      <td>0.662583</td>\n",
       "      <td>45.251900</td>\n",
       "      <td>132.591000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.785365</td>\n",
       "      <td>0.650634</td>\n",
       "      <td>45.017800</td>\n",
       "      <td>133.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>0.782679</td>\n",
       "      <td>0.709125</td>\n",
       "      <td>46.305500</td>\n",
       "      <td>129.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.751800</td>\n",
       "      <td>0.816541</td>\n",
       "      <td>0.691128</td>\n",
       "      <td>46.419700</td>\n",
       "      <td>129.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>0.790498</td>\n",
       "      <td>0.697647</td>\n",
       "      <td>45.683900</td>\n",
       "      <td>131.337000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-SentMix\n",
      "{'eval_loss': 22.313922882080078, 'eval_accuracy': 0.9180263157894737, 'eval_f1': 0.9179626120032178, 'eval_precision': 0.9181496129451846, 'eval_recall': 0.9180263157894737, 'eval_runtime': 99.9503, 'eval_samples_per_second': 76.038, 'epoch': 0.79, 'run': './results/bert-base-uncased-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac43f36ba0d4531b82d8cf8eb37b52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='16000' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16000/190000 1:00:28 < 10:57:42, 4.41 it/s, Epoch 0/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.198200</td>\n",
       "      <td>0.970566</td>\n",
       "      <td>0.599436</td>\n",
       "      <td>45.117300</td>\n",
       "      <td>132.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.910600</td>\n",
       "      <td>0.886178</td>\n",
       "      <td>0.597241</td>\n",
       "      <td>45.904800</td>\n",
       "      <td>130.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.838100</td>\n",
       "      <td>0.877627</td>\n",
       "      <td>0.568523</td>\n",
       "      <td>45.186300</td>\n",
       "      <td>132.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>0.857383</td>\n",
       "      <td>0.573596</td>\n",
       "      <td>45.120800</td>\n",
       "      <td>132.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.803200</td>\n",
       "      <td>0.839064</td>\n",
       "      <td>0.594934</td>\n",
       "      <td>45.564200</td>\n",
       "      <td>131.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.791700</td>\n",
       "      <td>0.820047</td>\n",
       "      <td>0.633415</td>\n",
       "      <td>45.309900</td>\n",
       "      <td>132.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.836729</td>\n",
       "      <td>0.598929</td>\n",
       "      <td>44.933700</td>\n",
       "      <td>133.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>0.841498</td>\n",
       "      <td>0.604356</td>\n",
       "      <td>45.144000</td>\n",
       "      <td>132.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.838745</td>\n",
       "      <td>0.606598</td>\n",
       "      <td>45.313900</td>\n",
       "      <td>132.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>0.889793</td>\n",
       "      <td>0.583556</td>\n",
       "      <td>45.126500</td>\n",
       "      <td>132.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.850967</td>\n",
       "      <td>0.593325</td>\n",
       "      <td>45.355000</td>\n",
       "      <td>132.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>0.812685</td>\n",
       "      <td>0.600049</td>\n",
       "      <td>45.392700</td>\n",
       "      <td>132.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.813300</td>\n",
       "      <td>0.813407</td>\n",
       "      <td>0.556758</td>\n",
       "      <td>44.987000</td>\n",
       "      <td>133.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.793200</td>\n",
       "      <td>0.861788</td>\n",
       "      <td>0.615477</td>\n",
       "      <td>45.415300</td>\n",
       "      <td>132.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>0.884668</td>\n",
       "      <td>0.562452</td>\n",
       "      <td>44.437800</td>\n",
       "      <td>135.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.855413</td>\n",
       "      <td>0.602301</td>\n",
       "      <td>45.995000</td>\n",
       "      <td>130.449000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-WordMix\n",
      "{'eval_loss': 20.192277908325195, 'eval_accuracy': 0.9017105263157895, 'eval_f1': 0.90160491349668, 'eval_precision': 0.9016304552985033, 'eval_recall': 0.9017105263157895, 'eval_runtime': 99.3157, 'eval_samples_per_second': 76.524, 'epoch': 0.84, 'run': './results/bert-base-uncased-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e3562fbb9c49acb2172d45056df19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24000' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 24000/190000 1:31:19 < 10:31:40, 4.38 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.171100</td>\n",
       "      <td>0.777479</td>\n",
       "      <td>0.696322</td>\n",
       "      <td>43.851300</td>\n",
       "      <td>136.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.783400</td>\n",
       "      <td>0.821144</td>\n",
       "      <td>0.621363</td>\n",
       "      <td>43.728500</td>\n",
       "      <td>137.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.761800</td>\n",
       "      <td>0.784308</td>\n",
       "      <td>0.708993</td>\n",
       "      <td>43.978700</td>\n",
       "      <td>136.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>0.831048</td>\n",
       "      <td>0.646918</td>\n",
       "      <td>44.381800</td>\n",
       "      <td>135.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.751900</td>\n",
       "      <td>0.788297</td>\n",
       "      <td>0.680780</td>\n",
       "      <td>43.237600</td>\n",
       "      <td>138.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.753600</td>\n",
       "      <td>0.886401</td>\n",
       "      <td>0.690509</td>\n",
       "      <td>44.232400</td>\n",
       "      <td>135.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.801046</td>\n",
       "      <td>0.702739</td>\n",
       "      <td>43.407200</td>\n",
       "      <td>138.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.812113</td>\n",
       "      <td>0.699046</td>\n",
       "      <td>43.780200</td>\n",
       "      <td>137.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.751200</td>\n",
       "      <td>0.822854</td>\n",
       "      <td>0.709752</td>\n",
       "      <td>44.116800</td>\n",
       "      <td>136.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.739200</td>\n",
       "      <td>0.805018</td>\n",
       "      <td>0.732566</td>\n",
       "      <td>43.564400</td>\n",
       "      <td>137.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.825346</td>\n",
       "      <td>0.671931</td>\n",
       "      <td>44.120800</td>\n",
       "      <td>135.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.759100</td>\n",
       "      <td>0.790504</td>\n",
       "      <td>0.729058</td>\n",
       "      <td>43.661100</td>\n",
       "      <td>137.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.817658</td>\n",
       "      <td>0.682695</td>\n",
       "      <td>43.847100</td>\n",
       "      <td>136.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.737700</td>\n",
       "      <td>0.767831</td>\n",
       "      <td>0.778082</td>\n",
       "      <td>43.709700</td>\n",
       "      <td>137.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.733900</td>\n",
       "      <td>0.850375</td>\n",
       "      <td>0.649458</td>\n",
       "      <td>43.987500</td>\n",
       "      <td>136.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.799286</td>\n",
       "      <td>0.561868</td>\n",
       "      <td>44.031900</td>\n",
       "      <td>136.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.752800</td>\n",
       "      <td>0.804272</td>\n",
       "      <td>0.749038</td>\n",
       "      <td>43.862100</td>\n",
       "      <td>136.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.756800</td>\n",
       "      <td>0.830706</td>\n",
       "      <td>0.677461</td>\n",
       "      <td>43.824900</td>\n",
       "      <td>136.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.827887</td>\n",
       "      <td>0.752632</td>\n",
       "      <td>43.748900</td>\n",
       "      <td>137.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.745800</td>\n",
       "      <td>0.807942</td>\n",
       "      <td>0.694362</td>\n",
       "      <td>43.834700</td>\n",
       "      <td>136.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>0.834173</td>\n",
       "      <td>0.673906</td>\n",
       "      <td>44.517900</td>\n",
       "      <td>134.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>0.815317</td>\n",
       "      <td>0.701142</td>\n",
       "      <td>43.851300</td>\n",
       "      <td>136.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.742600</td>\n",
       "      <td>0.825405</td>\n",
       "      <td>0.744385</td>\n",
       "      <td>43.443900</td>\n",
       "      <td>138.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.752200</td>\n",
       "      <td>0.806877</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>43.214100</td>\n",
       "      <td>138.844000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 1], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-TextMix\n",
      "{'eval_loss': 24.647722244262695, 'eval_accuracy': 0.9227631578947368, 'eval_f1': 0.922686848959688, 'eval_precision': 0.9234344268649703, 'eval_recall': 0.9227631578947368, 'eval_runtime': 98.622, 'eval_samples_per_second': 77.062, 'epoch': 1.26, 'run': './results/roberta-base-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df8b96bacaf4096a47e0be111d8e25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='16000' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16000/190000 1:00:25 < 10:57:07, 4.41 it/s, Epoch 0/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.156800</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>0.697237</td>\n",
       "      <td>42.806000</td>\n",
       "      <td>140.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.814275</td>\n",
       "      <td>0.664701</td>\n",
       "      <td>42.511200</td>\n",
       "      <td>141.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.840406</td>\n",
       "      <td>0.674202</td>\n",
       "      <td>42.442200</td>\n",
       "      <td>141.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.799433</td>\n",
       "      <td>0.680204</td>\n",
       "      <td>43.614300</td>\n",
       "      <td>137.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.783400</td>\n",
       "      <td>0.806203</td>\n",
       "      <td>0.709784</td>\n",
       "      <td>43.338900</td>\n",
       "      <td>138.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>0.835609</td>\n",
       "      <td>0.737616</td>\n",
       "      <td>42.527700</td>\n",
       "      <td>141.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.750900</td>\n",
       "      <td>0.800669</td>\n",
       "      <td>0.709315</td>\n",
       "      <td>43.176700</td>\n",
       "      <td>138.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.769141</td>\n",
       "      <td>0.715467</td>\n",
       "      <td>43.179700</td>\n",
       "      <td>138.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.743400</td>\n",
       "      <td>0.789614</td>\n",
       "      <td>0.647352</td>\n",
       "      <td>42.520100</td>\n",
       "      <td>141.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.742600</td>\n",
       "      <td>0.775250</td>\n",
       "      <td>0.694938</td>\n",
       "      <td>43.171300</td>\n",
       "      <td>138.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.777694</td>\n",
       "      <td>0.644478</td>\n",
       "      <td>42.606000</td>\n",
       "      <td>140.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.747600</td>\n",
       "      <td>0.831084</td>\n",
       "      <td>0.626917</td>\n",
       "      <td>43.097300</td>\n",
       "      <td>139.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.815742</td>\n",
       "      <td>0.686171</td>\n",
       "      <td>42.372000</td>\n",
       "      <td>141.603000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.836649</td>\n",
       "      <td>0.667741</td>\n",
       "      <td>43.108900</td>\n",
       "      <td>139.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>0.855791</td>\n",
       "      <td>0.647213</td>\n",
       "      <td>43.063000</td>\n",
       "      <td>139.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.797834</td>\n",
       "      <td>0.706327</td>\n",
       "      <td>43.327100</td>\n",
       "      <td>138.482000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 1], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-SentMix\n",
      "{'eval_loss': 25.880184173583984, 'eval_accuracy': 0.9156578947368421, 'eval_f1': 0.9155026600303513, 'eval_precision': 0.9180396179041801, 'eval_recall': 0.9156578947368421, 'eval_runtime': 98.7575, 'eval_samples_per_second': 76.956, 'epoch': 0.84, 'run': './results/roberta-base-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb97d6f5675453fbec01b2e5955aef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='27000' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 27000/190000 1:44:15 < 10:29:26, 4.32 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.174100</td>\n",
       "      <td>0.874719</td>\n",
       "      <td>0.648887</td>\n",
       "      <td>45.563500</td>\n",
       "      <td>131.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>0.863883</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>44.117500</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.812900</td>\n",
       "      <td>0.825971</td>\n",
       "      <td>0.556426</td>\n",
       "      <td>44.579800</td>\n",
       "      <td>134.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.791600</td>\n",
       "      <td>0.834896</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>44.207700</td>\n",
       "      <td>135.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.800100</td>\n",
       "      <td>0.829944</td>\n",
       "      <td>0.540258</td>\n",
       "      <td>45.391700</td>\n",
       "      <td>132.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>0.825413</td>\n",
       "      <td>0.548490</td>\n",
       "      <td>45.714600</td>\n",
       "      <td>131.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.860661</td>\n",
       "      <td>0.596208</td>\n",
       "      <td>45.040800</td>\n",
       "      <td>133.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.815200</td>\n",
       "      <td>0.876942</td>\n",
       "      <td>0.588277</td>\n",
       "      <td>44.751800</td>\n",
       "      <td>134.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>45.146200</td>\n",
       "      <td>132.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.833423</td>\n",
       "      <td>0.580528</td>\n",
       "      <td>44.435400</td>\n",
       "      <td>135.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.788900</td>\n",
       "      <td>0.844842</td>\n",
       "      <td>0.539041</td>\n",
       "      <td>44.846800</td>\n",
       "      <td>133.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.875327</td>\n",
       "      <td>0.576940</td>\n",
       "      <td>44.711600</td>\n",
       "      <td>134.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.834829</td>\n",
       "      <td>0.586973</td>\n",
       "      <td>44.113300</td>\n",
       "      <td>136.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.783900</td>\n",
       "      <td>0.825577</td>\n",
       "      <td>0.605279</td>\n",
       "      <td>44.065700</td>\n",
       "      <td>136.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.783100</td>\n",
       "      <td>0.808437</td>\n",
       "      <td>0.569786</td>\n",
       "      <td>44.542500</td>\n",
       "      <td>134.703000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.801200</td>\n",
       "      <td>0.827543</td>\n",
       "      <td>0.574674</td>\n",
       "      <td>44.770100</td>\n",
       "      <td>134.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>0.813073</td>\n",
       "      <td>0.643056</td>\n",
       "      <td>44.406300</td>\n",
       "      <td>135.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.871781</td>\n",
       "      <td>0.596513</td>\n",
       "      <td>44.561000</td>\n",
       "      <td>134.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>0.835573</td>\n",
       "      <td>0.613340</td>\n",
       "      <td>44.373000</td>\n",
       "      <td>135.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.790400</td>\n",
       "      <td>0.864560</td>\n",
       "      <td>0.560649</td>\n",
       "      <td>45.156000</td>\n",
       "      <td>132.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>0.940603</td>\n",
       "      <td>0.576039</td>\n",
       "      <td>44.633800</td>\n",
       "      <td>134.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.781700</td>\n",
       "      <td>0.830819</td>\n",
       "      <td>0.569769</td>\n",
       "      <td>44.649800</td>\n",
       "      <td>134.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.813900</td>\n",
       "      <td>0.835144</td>\n",
       "      <td>0.620425</td>\n",
       "      <td>44.590800</td>\n",
       "      <td>134.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.875561</td>\n",
       "      <td>0.599335</td>\n",
       "      <td>43.889800</td>\n",
       "      <td>136.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.811100</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>0.571236</td>\n",
       "      <td>45.081700</td>\n",
       "      <td>133.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.822300</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.577091</td>\n",
       "      <td>44.099300</td>\n",
       "      <td>136.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>0.854935</td>\n",
       "      <td>0.592922</td>\n",
       "      <td>44.569600</td>\n",
       "      <td>134.621000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 1], [1, 0], [2, 0], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 2], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 1], [1, 2], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 1], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-WordMix\n",
      "{'eval_loss': 20.235855102539062, 'eval_accuracy': 0.8998684210526315, 'eval_f1': 0.9003638006056494, 'eval_precision': 0.9047092816783304, 'eval_recall': 0.8998684210526315, 'eval_runtime': 98.7674, 'eval_samples_per_second': 76.948, 'epoch': 1.42, 'run': './results/roberta-base-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a2ca1830b84a5b9a7a293889fd0007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9001' max='190000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9001/190000 53:09 < 17:49:20, 2.82 it/s, Epoch 0.47/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.869547</td>\n",
       "      <td>0.651120</td>\n",
       "      <td>108.713400</td>\n",
       "      <td>55.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>0.850099</td>\n",
       "      <td>0.641214</td>\n",
       "      <td>105.876100</td>\n",
       "      <td>56.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.813988</td>\n",
       "      <td>0.635406</td>\n",
       "      <td>106.682400</td>\n",
       "      <td>56.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.754100</td>\n",
       "      <td>0.826314</td>\n",
       "      <td>0.676050</td>\n",
       "      <td>109.282900</td>\n",
       "      <td>54.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.768200</td>\n",
       "      <td>0.784603</td>\n",
       "      <td>0.702011</td>\n",
       "      <td>106.563700</td>\n",
       "      <td>56.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.758900</td>\n",
       "      <td>0.780498</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>108.693500</td>\n",
       "      <td>55.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.861906</td>\n",
       "      <td>0.645757</td>\n",
       "      <td>108.088200</td>\n",
       "      <td>55.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.801567</td>\n",
       "      <td>0.679880</td>\n",
       "      <td>108.252800</td>\n",
       "      <td>55.426000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='86' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 86/188 00:50 < 01:00, 1.69 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "        \n",
    "    for t in ts: \n",
    "        \n",
    "        t_str = t.__class__.__name__\n",
    "        checkpoint = './results/' + MODEL_NAME + '-targeted-' + t_str\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4).to(device)\n",
    "\n",
    "        dataset = load_dataset('ag_news', split='train') \n",
    "        dataset_dict = dataset.train_test_split(\n",
    "            test_size = 0.05,\n",
    "            train_size = 0.95,\n",
    "            shuffle = True\n",
    "        )\n",
    "        train_dataset = dataset_dict['train']\n",
    "        eval_dataset = dataset_dict['test']\n",
    "\n",
    "        test_dataset = load_dataset('ag_news', split='test') \n",
    "        test_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        train_batch_size = 6\n",
    "        eval_batch_size = 32\n",
    "        num_epoch = 10\n",
    "        gradient_accumulation_steps = 1\n",
    "        max_steps = int((len(train_dataset) * num_epoch / gradient_accumulation_steps) / train_batch_size)\n",
    "\n",
    "        tmcb = TargetedMixturesCallback(\n",
    "            dataloader=DataLoader(eval_dataset, batch_size=32),\n",
    "            device=device\n",
    "        )\n",
    "        escb = EarlyStoppingCallback(\n",
    "            early_stopping_patience=10\n",
    "        )\n",
    "        tmc = TargetedMixturesCollator(\n",
    "            tokenize_fn=tokenize_fn, \n",
    "            transform=t,\n",
    "            target_prob=0.5\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\\\n",
    "            output_dir=checkpoint,\n",
    "            overwrite_output_dir=True,\n",
    "            max_steps=max_steps,\n",
    "            save_steps=int(max_steps / 10),\n",
    "            save_total_limit=1,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "            warmup_steps=int(max_steps / 10),\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=1000,\n",
    "            logging_first_step=True,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            remove_unused_columns=False\n",
    "        )\n",
    "\n",
    "        trainer = TargetedTrainer(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_metrics_w_soft_target,                  \n",
    "            train_dataset=train_dataset,         \n",
    "            eval_dataset=eval_dataset,\n",
    "            data_collator=tmc,\n",
    "            callbacks=[tmcb, escb]\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # test with ORIG data\n",
    "        trainer.eval_dataset = test_dataset\n",
    "        trainer.compute_metrics = compute_metrics\n",
    "        trainer.data_collator = DefaultCollator()\n",
    "        trainer.remove_callback(tmcb)\n",
    "\n",
    "        out_orig = trainer.evaluate()\n",
    "        out_orig['run'] = checkpoint\n",
    "        out_orig['test'] = \"ORIG\"\n",
    "        print('ORIG for {}\\n{}'.format(checkpoint, out_orig))\n",
    "\n",
    "        results.append(out_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_AG_NEWS_targeted_r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG for ./results/bert-base-uncased-targeted-TextMix\n",
    "# {'eval_loss': 31.2364559173584, 'eval_accuracy': 0.9381578947368421, 'eval_f1': 0.9381945850526017, 'eval_precision': 0.938240633851668, 'eval_recall': 0.9381578947368421, 'eval_runtime': 117.2622, 'eval_samples_per_second': 64.812, 'epoch': 5.0, 'run': 'TextMix', 'test': 'ORIG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
