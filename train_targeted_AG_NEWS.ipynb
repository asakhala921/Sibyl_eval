{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted SIB Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    TrainerCallback, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers.trainer_callback import TrainerControl\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transforms import TextMix, SentMix, WordMix\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(text):\n",
    "    return tokenizer(text, padding=True, truncation=True, max_length=200, return_tensors='pt')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=200)\n",
    "\n",
    "def acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()\n",
    "\n",
    "def CEwST_loss(logits, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Cross Entropy with Soft Target (CEwST) Loss\n",
    "    :param logits: (batch, *)\n",
    "    :param target: (batch, *) same shape as logits, each item must be a valid distribution: target[i, :].sum() == 1.\n",
    "    \"\"\"\n",
    "    logprobs = torch.nn.functional.log_softmax(logits.view(logits.shape[0], -1), dim=1)\n",
    "    batchloss = - torch.sum(target.view(target.shape[0], -1) * logprobs, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return batchloss\n",
    "    elif reduction == 'mean':\n",
    "        return torch.mean(batchloss)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(batchloss)\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported reduction mode.')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1.mean(),\n",
    "        'precision': precision.mean(),\n",
    "        'recall': recall.mean()\n",
    "    }        \n",
    "        \n",
    "def compute_metrics_w_soft_target(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    acc = acc_at_k(labels, preds, k=2)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }\n",
    "\n",
    "class TargetedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = CEwST_loss(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "class TargetedMixturesCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A callback that calculates a confusion matrix on the validation\n",
    "    data and returns the most confused class pairings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, model, tokenizer, **kwargs):\n",
    "        cnf_mat = self.get_confusion_matrix(model, tokenizer, self.dataloader)\n",
    "        new_targets = self.get_most_confused_per_class(cnf_mat)\n",
    "        print(\"New targets:\", new_targets)\n",
    "        control = TrainerControl\n",
    "        control.new_targets = new_targets\n",
    "        if state.global_step < state.max_steps:\n",
    "            control.should_training_stop = False\n",
    "        else:\n",
    "            control.should_training_stop = True\n",
    "        return control\n",
    "        \n",
    "    def get_confusion_matrix(self, model, tokenizer, dataloader, normalize=True):\n",
    "        n_classes = max(dataloader.dataset['label']) + 1\n",
    "        confusion_matrix = torch.zeros(n_classes, n_classes)\n",
    "        with torch.no_grad():\n",
    "            for batch in iter(self.dataloader):\n",
    "                data, targets = batch['text'], batch['label']\n",
    "                data = tokenizer(data, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "                input_ids = data['input_ids'].to(self.device)\n",
    "                attention_mask = data['attention_mask'].to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask).logits\n",
    "                preds = torch.argmax(outputs, dim=1).cpu()\n",
    "                for t, p in zip(targets.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1    \n",
    "            if normalize:\n",
    "                confusion_matrix = confusion_matrix / confusion_matrix.sum(dim=0)\n",
    "        return confusion_matrix\n",
    "\n",
    "    def get_most_confused_per_class(self, confusion_matrix):\n",
    "        idx = torch.arange(len(confusion_matrix))\n",
    "        cnf = confusion_matrix.fill_diagonal_(0).max(dim=1)[1]\n",
    "        return torch.stack((idx, cnf)).T.tolist()\n",
    "\n",
    "class TargetedMixturesCollator:\n",
    "    def __init__(self, tokenize_fn, transform, target_pairs=[], target_prob=1.0, num_classes=4):\n",
    "        self.tokenize_fn = tokenize_fn\n",
    "        self.transform = transform\n",
    "        self.target_pairs = target_pairs\n",
    "        self.target_prob = target_prob\n",
    "        self.num_classes = num_classes\n",
    "        print(\"TargetedMixturesCollator initialized with {}\".format(transform.__class__.__name__))\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        text = [x['text'] for x in batch]\n",
    "        labels = [x['label'] for x in batch]\n",
    "        batch = (text, labels)\n",
    "        batch = self.transform(\n",
    "            batch, \n",
    "            self.target_pairs,   \n",
    "            self.target_prob,\n",
    "            self.num_classes\n",
    "        )\n",
    "        text, labels = batch\n",
    "        batch = self.tokenize_fn(text)\n",
    "        batch['labels'] = torch.tensor(labels)\n",
    "        return batch\n",
    "    \n",
    "class DefaultCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']\n",
    "ts = [TextMix(), SentMix(), WordMix()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "<ipython-input-5-71a978c8cc15>:23: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use Dataset.rename_column instead.\n",
      "  test_dataset.rename_column_('label', 'labels')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73ea33c030940609f045b117561fbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='32000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 32000/114000 2:37:54 < 6:44:40, 3.38 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.123000</td>\n",
       "      <td>0.818767</td>\n",
       "      <td>0.672051</td>\n",
       "      <td>41.791100</td>\n",
       "      <td>143.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.810600</td>\n",
       "      <td>0.782954</td>\n",
       "      <td>0.667070</td>\n",
       "      <td>41.773100</td>\n",
       "      <td>143.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>0.783479</td>\n",
       "      <td>0.642045</td>\n",
       "      <td>41.935400</td>\n",
       "      <td>143.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.658484</td>\n",
       "      <td>41.691600</td>\n",
       "      <td>143.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.765900</td>\n",
       "      <td>0.763694</td>\n",
       "      <td>0.683334</td>\n",
       "      <td>41.718900</td>\n",
       "      <td>143.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.746200</td>\n",
       "      <td>0.768270</td>\n",
       "      <td>0.738120</td>\n",
       "      <td>41.628200</td>\n",
       "      <td>144.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.763900</td>\n",
       "      <td>0.735198</td>\n",
       "      <td>0.705449</td>\n",
       "      <td>41.824000</td>\n",
       "      <td>143.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>0.747112</td>\n",
       "      <td>0.687160</td>\n",
       "      <td>41.889100</td>\n",
       "      <td>143.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>0.756710</td>\n",
       "      <td>0.742128</td>\n",
       "      <td>41.748000</td>\n",
       "      <td>143.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.741200</td>\n",
       "      <td>0.789278</td>\n",
       "      <td>0.759883</td>\n",
       "      <td>41.588100</td>\n",
       "      <td>144.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.764600</td>\n",
       "      <td>0.745138</td>\n",
       "      <td>0.768679</td>\n",
       "      <td>41.702300</td>\n",
       "      <td>143.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.734100</td>\n",
       "      <td>0.781620</td>\n",
       "      <td>0.719426</td>\n",
       "      <td>41.787000</td>\n",
       "      <td>143.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.736072</td>\n",
       "      <td>0.775224</td>\n",
       "      <td>41.728600</td>\n",
       "      <td>143.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.783706</td>\n",
       "      <td>0.727560</td>\n",
       "      <td>42.082400</td>\n",
       "      <td>142.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>0.754335</td>\n",
       "      <td>0.725043</td>\n",
       "      <td>41.732700</td>\n",
       "      <td>143.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.721400</td>\n",
       "      <td>0.737162</td>\n",
       "      <td>0.737561</td>\n",
       "      <td>41.379000</td>\n",
       "      <td>145.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.740500</td>\n",
       "      <td>0.735611</td>\n",
       "      <td>0.772673</td>\n",
       "      <td>41.754300</td>\n",
       "      <td>143.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.709200</td>\n",
       "      <td>0.748185</td>\n",
       "      <td>0.818385</td>\n",
       "      <td>41.773600</td>\n",
       "      <td>143.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.752163</td>\n",
       "      <td>0.740732</td>\n",
       "      <td>42.067000</td>\n",
       "      <td>142.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.722214</td>\n",
       "      <td>0.738684</td>\n",
       "      <td>41.744000</td>\n",
       "      <td>143.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.717800</td>\n",
       "      <td>0.741026</td>\n",
       "      <td>0.746598</td>\n",
       "      <td>41.527200</td>\n",
       "      <td>144.483000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.718987</td>\n",
       "      <td>0.831182</td>\n",
       "      <td>41.672100</td>\n",
       "      <td>143.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.806618</td>\n",
       "      <td>41.644800</td>\n",
       "      <td>144.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>0.776734</td>\n",
       "      <td>0.787477</td>\n",
       "      <td>41.692900</td>\n",
       "      <td>143.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.706300</td>\n",
       "      <td>0.746044</td>\n",
       "      <td>0.800654</td>\n",
       "      <td>41.821100</td>\n",
       "      <td>143.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.752130</td>\n",
       "      <td>0.798149</td>\n",
       "      <td>41.841200</td>\n",
       "      <td>143.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.715602</td>\n",
       "      <td>0.787429</td>\n",
       "      <td>41.929100</td>\n",
       "      <td>143.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.763519</td>\n",
       "      <td>0.817877</td>\n",
       "      <td>41.708400</td>\n",
       "      <td>143.856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.699200</td>\n",
       "      <td>0.741979</td>\n",
       "      <td>0.817925</td>\n",
       "      <td>41.726200</td>\n",
       "      <td>143.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.760298</td>\n",
       "      <td>0.818598</td>\n",
       "      <td>41.425200</td>\n",
       "      <td>144.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.729502</td>\n",
       "      <td>0.826273</td>\n",
       "      <td>41.635200</td>\n",
       "      <td>144.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>0.736428</td>\n",
       "      <td>0.773498</td>\n",
       "      <td>41.892700</td>\n",
       "      <td>143.223000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-TextMix\n",
      "{'eval_loss': 24.480539321899414, 'eval_accuracy': 0.9343421052631579, 'eval_f1': 0.9342633670695392, 'eval_precision': 0.9342082629365714, 'eval_recall': 0.934342105263158, 'eval_runtime': 61.8223, 'eval_samples_per_second': 122.933, 'epoch': 2.81, 'run': './results/bert-base-uncased-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8288a8fd0b5498f9370715da2f2517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='60000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 60000/114000 4:56:16 < 4:26:39, 3.38 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.141800</td>\n",
       "      <td>0.819791</td>\n",
       "      <td>0.674739</td>\n",
       "      <td>41.784300</td>\n",
       "      <td>143.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.819400</td>\n",
       "      <td>0.804909</td>\n",
       "      <td>0.634521</td>\n",
       "      <td>41.172600</td>\n",
       "      <td>145.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.772200</td>\n",
       "      <td>0.771695</td>\n",
       "      <td>0.671235</td>\n",
       "      <td>41.391600</td>\n",
       "      <td>144.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.764600</td>\n",
       "      <td>0.769283</td>\n",
       "      <td>0.698796</td>\n",
       "      <td>41.136000</td>\n",
       "      <td>145.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.752300</td>\n",
       "      <td>0.806216</td>\n",
       "      <td>0.657800</td>\n",
       "      <td>41.170400</td>\n",
       "      <td>145.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.798659</td>\n",
       "      <td>0.720266</td>\n",
       "      <td>41.517900</td>\n",
       "      <td>144.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.762700</td>\n",
       "      <td>0.782367</td>\n",
       "      <td>0.677025</td>\n",
       "      <td>40.962100</td>\n",
       "      <td>146.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>0.779678</td>\n",
       "      <td>0.682811</td>\n",
       "      <td>41.426300</td>\n",
       "      <td>144.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.775168</td>\n",
       "      <td>0.681278</td>\n",
       "      <td>41.462400</td>\n",
       "      <td>144.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.767761</td>\n",
       "      <td>0.690635</td>\n",
       "      <td>41.590400</td>\n",
       "      <td>144.264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.757400</td>\n",
       "      <td>0.787970</td>\n",
       "      <td>0.668663</td>\n",
       "      <td>41.449400</td>\n",
       "      <td>144.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>0.783350</td>\n",
       "      <td>0.706462</td>\n",
       "      <td>41.231600</td>\n",
       "      <td>145.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>0.705458</td>\n",
       "      <td>41.591500</td>\n",
       "      <td>144.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.751800</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.728952</td>\n",
       "      <td>41.352200</td>\n",
       "      <td>145.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.779984</td>\n",
       "      <td>0.733933</td>\n",
       "      <td>41.623600</td>\n",
       "      <td>144.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.741800</td>\n",
       "      <td>0.760561</td>\n",
       "      <td>0.690133</td>\n",
       "      <td>41.424900</td>\n",
       "      <td>144.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.726600</td>\n",
       "      <td>0.749656</td>\n",
       "      <td>0.728311</td>\n",
       "      <td>41.262700</td>\n",
       "      <td>145.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.782585</td>\n",
       "      <td>0.735354</td>\n",
       "      <td>41.065100</td>\n",
       "      <td>146.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.720300</td>\n",
       "      <td>0.766690</td>\n",
       "      <td>0.721960</td>\n",
       "      <td>41.298600</td>\n",
       "      <td>145.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.743133</td>\n",
       "      <td>0.725499</td>\n",
       "      <td>41.371500</td>\n",
       "      <td>145.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>0.747307</td>\n",
       "      <td>0.763836</td>\n",
       "      <td>41.325500</td>\n",
       "      <td>145.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>0.780231</td>\n",
       "      <td>0.756840</td>\n",
       "      <td>41.523200</td>\n",
       "      <td>144.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.775332</td>\n",
       "      <td>0.720701</td>\n",
       "      <td>41.454400</td>\n",
       "      <td>144.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>0.788965</td>\n",
       "      <td>0.723139</td>\n",
       "      <td>41.529100</td>\n",
       "      <td>144.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.788923</td>\n",
       "      <td>0.750556</td>\n",
       "      <td>41.465200</td>\n",
       "      <td>144.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.686300</td>\n",
       "      <td>0.770865</td>\n",
       "      <td>0.756619</td>\n",
       "      <td>41.224400</td>\n",
       "      <td>145.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.757133</td>\n",
       "      <td>0.785409</td>\n",
       "      <td>41.411700</td>\n",
       "      <td>144.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.702200</td>\n",
       "      <td>0.751026</td>\n",
       "      <td>0.795002</td>\n",
       "      <td>41.300500</td>\n",
       "      <td>145.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>0.744508</td>\n",
       "      <td>0.774164</td>\n",
       "      <td>41.483000</td>\n",
       "      <td>144.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>0.780125</td>\n",
       "      <td>0.723562</td>\n",
       "      <td>41.352300</td>\n",
       "      <td>145.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>0.738656</td>\n",
       "      <td>0.783777</td>\n",
       "      <td>41.603300</td>\n",
       "      <td>144.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.730912</td>\n",
       "      <td>0.807202</td>\n",
       "      <td>41.394000</td>\n",
       "      <td>144.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.753170</td>\n",
       "      <td>0.805950</td>\n",
       "      <td>41.598100</td>\n",
       "      <td>144.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.738451</td>\n",
       "      <td>0.808564</td>\n",
       "      <td>41.287200</td>\n",
       "      <td>145.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.670700</td>\n",
       "      <td>0.783856</td>\n",
       "      <td>0.820341</td>\n",
       "      <td>41.356500</td>\n",
       "      <td>145.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.776692</td>\n",
       "      <td>0.813876</td>\n",
       "      <td>41.584400</td>\n",
       "      <td>144.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.681700</td>\n",
       "      <td>0.780208</td>\n",
       "      <td>0.793028</td>\n",
       "      <td>41.394800</td>\n",
       "      <td>144.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.756764</td>\n",
       "      <td>0.818294</td>\n",
       "      <td>41.658900</td>\n",
       "      <td>144.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.767632</td>\n",
       "      <td>0.804836</td>\n",
       "      <td>41.685200</td>\n",
       "      <td>143.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.773483</td>\n",
       "      <td>0.817264</td>\n",
       "      <td>41.644400</td>\n",
       "      <td>144.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.677100</td>\n",
       "      <td>0.754714</td>\n",
       "      <td>0.828353</td>\n",
       "      <td>41.141600</td>\n",
       "      <td>145.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.758841</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>41.363000</td>\n",
       "      <td>145.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.756483</td>\n",
       "      <td>0.814776</td>\n",
       "      <td>41.066000</td>\n",
       "      <td>146.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.758293</td>\n",
       "      <td>0.779075</td>\n",
       "      <td>41.468500</td>\n",
       "      <td>144.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>0.755329</td>\n",
       "      <td>0.762388</td>\n",
       "      <td>41.608200</td>\n",
       "      <td>144.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>0.752504</td>\n",
       "      <td>0.834659</td>\n",
       "      <td>41.492200</td>\n",
       "      <td>144.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>0.760544</td>\n",
       "      <td>0.834415</td>\n",
       "      <td>41.111500</td>\n",
       "      <td>145.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>0.759794</td>\n",
       "      <td>0.799281</td>\n",
       "      <td>41.514500</td>\n",
       "      <td>144.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.782179</td>\n",
       "      <td>0.807461</td>\n",
       "      <td>41.410800</td>\n",
       "      <td>144.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.668200</td>\n",
       "      <td>0.764047</td>\n",
       "      <td>0.844572</td>\n",
       "      <td>41.391900</td>\n",
       "      <td>144.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.755606</td>\n",
       "      <td>0.843180</td>\n",
       "      <td>41.353600</td>\n",
       "      <td>145.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.659800</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>0.804424</td>\n",
       "      <td>41.486800</td>\n",
       "      <td>144.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>0.770625</td>\n",
       "      <td>0.815174</td>\n",
       "      <td>41.451900</td>\n",
       "      <td>144.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.776466</td>\n",
       "      <td>0.831405</td>\n",
       "      <td>41.379100</td>\n",
       "      <td>145.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.643600</td>\n",
       "      <td>0.776221</td>\n",
       "      <td>0.814785</td>\n",
       "      <td>41.477400</td>\n",
       "      <td>144.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>0.745348</td>\n",
       "      <td>0.834112</td>\n",
       "      <td>41.534300</td>\n",
       "      <td>144.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.658700</td>\n",
       "      <td>0.762092</td>\n",
       "      <td>0.836420</td>\n",
       "      <td>41.371500</td>\n",
       "      <td>145.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.642700</td>\n",
       "      <td>0.766395</td>\n",
       "      <td>0.817222</td>\n",
       "      <td>41.186500</td>\n",
       "      <td>145.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.631900</td>\n",
       "      <td>0.743475</td>\n",
       "      <td>0.832205</td>\n",
       "      <td>41.439500</td>\n",
       "      <td>144.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.780227</td>\n",
       "      <td>0.829997</td>\n",
       "      <td>41.711200</td>\n",
       "      <td>143.846000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-SentMix\n",
      "{'eval_loss': 26.8177547454834, 'eval_accuracy': 0.9328947368421052, 'eval_f1': 0.9329163788471664, 'eval_precision': 0.9337170333495173, 'eval_recall': 0.9328947368421052, 'eval_runtime': 61.8966, 'eval_samples_per_second': 122.785, 'epoch': 5.26, 'run': './results/bert-base-uncased-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eced7ea335140459cd971ad06bb9dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 24000/114000 1:59:08 < 7:26:50, 3.36 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.103400</td>\n",
       "      <td>0.864784</td>\n",
       "      <td>0.640724</td>\n",
       "      <td>41.023700</td>\n",
       "      <td>146.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.858700</td>\n",
       "      <td>0.840726</td>\n",
       "      <td>0.605792</td>\n",
       "      <td>41.296500</td>\n",
       "      <td>145.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>0.817732</td>\n",
       "      <td>0.564329</td>\n",
       "      <td>40.773600</td>\n",
       "      <td>147.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.798400</td>\n",
       "      <td>0.800068</td>\n",
       "      <td>0.624055</td>\n",
       "      <td>41.195600</td>\n",
       "      <td>145.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.801600</td>\n",
       "      <td>0.819686</td>\n",
       "      <td>0.550635</td>\n",
       "      <td>41.339000</td>\n",
       "      <td>145.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.816500</td>\n",
       "      <td>0.585087</td>\n",
       "      <td>41.260400</td>\n",
       "      <td>145.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.794700</td>\n",
       "      <td>0.826997</td>\n",
       "      <td>0.556226</td>\n",
       "      <td>41.357900</td>\n",
       "      <td>145.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.780800</td>\n",
       "      <td>0.819812</td>\n",
       "      <td>0.613131</td>\n",
       "      <td>41.161800</td>\n",
       "      <td>145.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.783700</td>\n",
       "      <td>0.835647</td>\n",
       "      <td>0.548450</td>\n",
       "      <td>41.187600</td>\n",
       "      <td>145.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.802300</td>\n",
       "      <td>0.830718</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>41.166900</td>\n",
       "      <td>145.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.796653</td>\n",
       "      <td>0.606278</td>\n",
       "      <td>41.371600</td>\n",
       "      <td>145.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.802800</td>\n",
       "      <td>0.845214</td>\n",
       "      <td>0.600070</td>\n",
       "      <td>40.999300</td>\n",
       "      <td>146.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.776200</td>\n",
       "      <td>0.816593</td>\n",
       "      <td>0.603925</td>\n",
       "      <td>41.292600</td>\n",
       "      <td>145.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.797960</td>\n",
       "      <td>0.646006</td>\n",
       "      <td>41.306000</td>\n",
       "      <td>145.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.753800</td>\n",
       "      <td>0.828202</td>\n",
       "      <td>0.591713</td>\n",
       "      <td>41.169700</td>\n",
       "      <td>145.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.800544</td>\n",
       "      <td>0.618686</td>\n",
       "      <td>40.961000</td>\n",
       "      <td>146.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>0.785945</td>\n",
       "      <td>0.645454</td>\n",
       "      <td>41.273300</td>\n",
       "      <td>145.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>0.818536</td>\n",
       "      <td>0.636267</td>\n",
       "      <td>41.197000</td>\n",
       "      <td>145.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.780300</td>\n",
       "      <td>0.804948</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>41.254300</td>\n",
       "      <td>145.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>0.788902</td>\n",
       "      <td>0.623386</td>\n",
       "      <td>41.308800</td>\n",
       "      <td>145.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.751400</td>\n",
       "      <td>0.801264</td>\n",
       "      <td>0.634714</td>\n",
       "      <td>41.367200</td>\n",
       "      <td>145.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>0.840641</td>\n",
       "      <td>0.622933</td>\n",
       "      <td>41.022900</td>\n",
       "      <td>146.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.838268</td>\n",
       "      <td>0.621960</td>\n",
       "      <td>41.235600</td>\n",
       "      <td>145.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>0.826707</td>\n",
       "      <td>0.629646</td>\n",
       "      <td>41.310200</td>\n",
       "      <td>145.243000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 1], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-WordMix\n",
      "{'eval_loss': 20.79989242553711, 'eval_accuracy': 0.91, 'eval_f1': 0.9096879772493497, 'eval_precision': 0.9113614704353348, 'eval_recall': 0.9100000000000001, 'eval_runtime': 61.8091, 'eval_samples_per_second': 122.959, 'epoch': 2.11, 'run': './results/bert-base-uncased-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f495c2ea344738aaf070abeb4d5575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='26000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 26000/114000 2:10:22 < 7:21:18, 3.32 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.040800</td>\n",
       "      <td>0.755991</td>\n",
       "      <td>0.689623</td>\n",
       "      <td>41.133400</td>\n",
       "      <td>145.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.781500</td>\n",
       "      <td>0.783156</td>\n",
       "      <td>0.679361</td>\n",
       "      <td>40.863400</td>\n",
       "      <td>146.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.765500</td>\n",
       "      <td>0.784874</td>\n",
       "      <td>0.705539</td>\n",
       "      <td>40.865600</td>\n",
       "      <td>146.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.763100</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.698786</td>\n",
       "      <td>40.804000</td>\n",
       "      <td>147.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.805542</td>\n",
       "      <td>0.689215</td>\n",
       "      <td>41.093200</td>\n",
       "      <td>146.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.771100</td>\n",
       "      <td>0.787268</td>\n",
       "      <td>0.678828</td>\n",
       "      <td>40.859400</td>\n",
       "      <td>146.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.755123</td>\n",
       "      <td>0.724273</td>\n",
       "      <td>40.867100</td>\n",
       "      <td>146.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.754100</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.716210</td>\n",
       "      <td>40.564600</td>\n",
       "      <td>147.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.756100</td>\n",
       "      <td>0.765260</td>\n",
       "      <td>0.686166</td>\n",
       "      <td>40.826200</td>\n",
       "      <td>146.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.797582</td>\n",
       "      <td>0.618166</td>\n",
       "      <td>40.912300</td>\n",
       "      <td>146.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.753100</td>\n",
       "      <td>0.760403</td>\n",
       "      <td>0.704303</td>\n",
       "      <td>40.733800</td>\n",
       "      <td>147.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.744200</td>\n",
       "      <td>0.768991</td>\n",
       "      <td>0.733001</td>\n",
       "      <td>40.955400</td>\n",
       "      <td>146.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>0.813799</td>\n",
       "      <td>0.708851</td>\n",
       "      <td>40.865800</td>\n",
       "      <td>146.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.729600</td>\n",
       "      <td>0.779796</td>\n",
       "      <td>0.674614</td>\n",
       "      <td>41.147000</td>\n",
       "      <td>145.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.792873</td>\n",
       "      <td>0.758249</td>\n",
       "      <td>40.859300</td>\n",
       "      <td>146.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.737900</td>\n",
       "      <td>0.749520</td>\n",
       "      <td>0.809297</td>\n",
       "      <td>40.762700</td>\n",
       "      <td>147.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.741500</td>\n",
       "      <td>0.769832</td>\n",
       "      <td>0.764569</td>\n",
       "      <td>40.982500</td>\n",
       "      <td>146.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.717200</td>\n",
       "      <td>0.784139</td>\n",
       "      <td>0.682039</td>\n",
       "      <td>40.763700</td>\n",
       "      <td>147.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.734700</td>\n",
       "      <td>0.780028</td>\n",
       "      <td>0.756884</td>\n",
       "      <td>40.838100</td>\n",
       "      <td>146.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.758220</td>\n",
       "      <td>0.739959</td>\n",
       "      <td>41.042600</td>\n",
       "      <td>146.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.725300</td>\n",
       "      <td>0.747194</td>\n",
       "      <td>0.791223</td>\n",
       "      <td>40.793500</td>\n",
       "      <td>147.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>0.755465</td>\n",
       "      <td>0.740972</td>\n",
       "      <td>41.003900</td>\n",
       "      <td>146.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.758428</td>\n",
       "      <td>0.787274</td>\n",
       "      <td>41.206700</td>\n",
       "      <td>145.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.695600</td>\n",
       "      <td>0.761499</td>\n",
       "      <td>0.792532</td>\n",
       "      <td>40.881600</td>\n",
       "      <td>146.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.716500</td>\n",
       "      <td>0.777168</td>\n",
       "      <td>0.794200</td>\n",
       "      <td>41.080300</td>\n",
       "      <td>146.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.702300</td>\n",
       "      <td>0.775880</td>\n",
       "      <td>0.798994</td>\n",
       "      <td>40.784300</td>\n",
       "      <td>147.115000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-TextMix\n",
      "{'eval_loss': 23.608760833740234, 'eval_accuracy': 0.93, 'eval_f1': 0.9302832264201846, 'eval_precision': 0.9312619021637497, 'eval_recall': 0.9299999999999999, 'eval_runtime': 60.8437, 'eval_samples_per_second': 124.91, 'epoch': 2.28, 'run': './results/roberta-base-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bdd447687e4aa081496928773fbf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='36000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 36000/114000 3:00:36 < 6:31:19, 3.32 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.059000</td>\n",
       "      <td>0.743698</td>\n",
       "      <td>0.693887</td>\n",
       "      <td>41.028100</td>\n",
       "      <td>146.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>0.797040</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>41.099400</td>\n",
       "      <td>145.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.756848</td>\n",
       "      <td>0.678766</td>\n",
       "      <td>41.400300</td>\n",
       "      <td>144.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.784700</td>\n",
       "      <td>0.768974</td>\n",
       "      <td>0.666649</td>\n",
       "      <td>40.858600</td>\n",
       "      <td>146.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.789600</td>\n",
       "      <td>0.759688</td>\n",
       "      <td>0.711485</td>\n",
       "      <td>40.984400</td>\n",
       "      <td>146.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.760200</td>\n",
       "      <td>0.752660</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>41.304200</td>\n",
       "      <td>145.264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>0.738920</td>\n",
       "      <td>0.734301</td>\n",
       "      <td>41.259700</td>\n",
       "      <td>145.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.751500</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.745563</td>\n",
       "      <td>41.092400</td>\n",
       "      <td>146.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.763181</td>\n",
       "      <td>0.714846</td>\n",
       "      <td>41.186500</td>\n",
       "      <td>145.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.744711</td>\n",
       "      <td>0.678383</td>\n",
       "      <td>41.265000</td>\n",
       "      <td>145.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.610739</td>\n",
       "      <td>41.060800</td>\n",
       "      <td>146.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.757700</td>\n",
       "      <td>0.766808</td>\n",
       "      <td>0.616334</td>\n",
       "      <td>40.886100</td>\n",
       "      <td>146.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.741170</td>\n",
       "      <td>0.694746</td>\n",
       "      <td>41.089800</td>\n",
       "      <td>146.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.734648</td>\n",
       "      <td>0.672285</td>\n",
       "      <td>41.274100</td>\n",
       "      <td>145.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.745700</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.693824</td>\n",
       "      <td>41.258200</td>\n",
       "      <td>145.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.743600</td>\n",
       "      <td>0.748826</td>\n",
       "      <td>0.722180</td>\n",
       "      <td>41.014800</td>\n",
       "      <td>146.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>0.744732</td>\n",
       "      <td>0.758012</td>\n",
       "      <td>41.231100</td>\n",
       "      <td>145.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.741500</td>\n",
       "      <td>0.776892</td>\n",
       "      <td>0.725788</td>\n",
       "      <td>41.161900</td>\n",
       "      <td>145.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.732200</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.654243</td>\n",
       "      <td>41.044700</td>\n",
       "      <td>146.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.734800</td>\n",
       "      <td>0.769726</td>\n",
       "      <td>0.777674</td>\n",
       "      <td>41.298800</td>\n",
       "      <td>145.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.740600</td>\n",
       "      <td>0.747009</td>\n",
       "      <td>0.732112</td>\n",
       "      <td>41.176200</td>\n",
       "      <td>145.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>0.722430</td>\n",
       "      <td>0.760777</td>\n",
       "      <td>41.121900</td>\n",
       "      <td>145.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>0.736291</td>\n",
       "      <td>0.731390</td>\n",
       "      <td>40.980200</td>\n",
       "      <td>146.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.769787</td>\n",
       "      <td>0.771270</td>\n",
       "      <td>40.954500</td>\n",
       "      <td>146.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.781040</td>\n",
       "      <td>41.389200</td>\n",
       "      <td>144.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.714600</td>\n",
       "      <td>0.750903</td>\n",
       "      <td>0.800752</td>\n",
       "      <td>41.331600</td>\n",
       "      <td>145.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.734498</td>\n",
       "      <td>0.798036</td>\n",
       "      <td>41.072500</td>\n",
       "      <td>146.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>0.730910</td>\n",
       "      <td>0.771492</td>\n",
       "      <td>41.014800</td>\n",
       "      <td>146.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.704300</td>\n",
       "      <td>0.755154</td>\n",
       "      <td>0.732761</td>\n",
       "      <td>41.008500</td>\n",
       "      <td>146.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.711900</td>\n",
       "      <td>0.744173</td>\n",
       "      <td>0.753088</td>\n",
       "      <td>41.117900</td>\n",
       "      <td>145.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>0.749402</td>\n",
       "      <td>0.734922</td>\n",
       "      <td>41.526900</td>\n",
       "      <td>144.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.699800</td>\n",
       "      <td>0.748812</td>\n",
       "      <td>0.784529</td>\n",
       "      <td>41.207500</td>\n",
       "      <td>145.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.767125</td>\n",
       "      <td>0.746709</td>\n",
       "      <td>41.349600</td>\n",
       "      <td>145.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.702000</td>\n",
       "      <td>0.728922</td>\n",
       "      <td>0.783418</td>\n",
       "      <td>41.262500</td>\n",
       "      <td>145.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>0.746346</td>\n",
       "      <td>0.751217</td>\n",
       "      <td>40.835800</td>\n",
       "      <td>146.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.731126</td>\n",
       "      <td>0.757744</td>\n",
       "      <td>41.077100</td>\n",
       "      <td>146.067000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-SentMix\n",
      "{'eval_loss': 23.41080665588379, 'eval_accuracy': 0.9351315789473684, 'eval_f1': 0.9352812099451323, 'eval_precision': 0.9360632134689295, 'eval_recall': 0.9351315789473684, 'eval_runtime': 60.5309, 'eval_samples_per_second': 125.556, 'epoch': 3.16, 'run': './results/roberta-base-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa48bbe62a4d4d0398ad6e1325c0f4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='40000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 40000/114000 3:20:24 < 6:10:46, 3.33 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.070600</td>\n",
       "      <td>0.829852</td>\n",
       "      <td>0.623684</td>\n",
       "      <td>39.985400</td>\n",
       "      <td>150.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.849100</td>\n",
       "      <td>0.828516</td>\n",
       "      <td>0.582391</td>\n",
       "      <td>40.416700</td>\n",
       "      <td>148.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.806700</td>\n",
       "      <td>0.828665</td>\n",
       "      <td>0.590196</td>\n",
       "      <td>40.090100</td>\n",
       "      <td>149.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.811400</td>\n",
       "      <td>0.824903</td>\n",
       "      <td>0.547974</td>\n",
       "      <td>40.542500</td>\n",
       "      <td>147.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.817200</td>\n",
       "      <td>0.806744</td>\n",
       "      <td>0.591967</td>\n",
       "      <td>40.496500</td>\n",
       "      <td>148.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.595121</td>\n",
       "      <td>40.549900</td>\n",
       "      <td>147.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.805800</td>\n",
       "      <td>0.781646</td>\n",
       "      <td>0.614757</td>\n",
       "      <td>40.546800</td>\n",
       "      <td>147.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.837159</td>\n",
       "      <td>0.586261</td>\n",
       "      <td>40.414100</td>\n",
       "      <td>148.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.835895</td>\n",
       "      <td>0.570278</td>\n",
       "      <td>40.471700</td>\n",
       "      <td>148.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.800100</td>\n",
       "      <td>0.789346</td>\n",
       "      <td>0.556848</td>\n",
       "      <td>40.340800</td>\n",
       "      <td>148.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.808200</td>\n",
       "      <td>0.808473</td>\n",
       "      <td>0.570567</td>\n",
       "      <td>40.273100</td>\n",
       "      <td>148.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.798700</td>\n",
       "      <td>0.799473</td>\n",
       "      <td>0.613282</td>\n",
       "      <td>40.363200</td>\n",
       "      <td>148.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.799400</td>\n",
       "      <td>0.801159</td>\n",
       "      <td>0.550251</td>\n",
       "      <td>40.880000</td>\n",
       "      <td>146.771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.822398</td>\n",
       "      <td>0.595519</td>\n",
       "      <td>40.353200</td>\n",
       "      <td>148.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.827857</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>40.554200</td>\n",
       "      <td>147.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>0.836238</td>\n",
       "      <td>0.597627</td>\n",
       "      <td>40.294200</td>\n",
       "      <td>148.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>0.808652</td>\n",
       "      <td>0.618154</td>\n",
       "      <td>40.334700</td>\n",
       "      <td>148.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.791100</td>\n",
       "      <td>0.801915</td>\n",
       "      <td>0.595209</td>\n",
       "      <td>40.415000</td>\n",
       "      <td>148.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>0.776243</td>\n",
       "      <td>0.623674</td>\n",
       "      <td>40.253500</td>\n",
       "      <td>149.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.782900</td>\n",
       "      <td>0.784745</td>\n",
       "      <td>0.626705</td>\n",
       "      <td>40.807700</td>\n",
       "      <td>147.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.789279</td>\n",
       "      <td>0.599310</td>\n",
       "      <td>40.405100</td>\n",
       "      <td>148.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.772200</td>\n",
       "      <td>0.834115</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>40.631000</td>\n",
       "      <td>147.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.794200</td>\n",
       "      <td>0.776424</td>\n",
       "      <td>0.630858</td>\n",
       "      <td>40.435900</td>\n",
       "      <td>148.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.765800</td>\n",
       "      <td>0.807990</td>\n",
       "      <td>0.636551</td>\n",
       "      <td>40.206500</td>\n",
       "      <td>149.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.800713</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>40.732000</td>\n",
       "      <td>147.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.631966</td>\n",
       "      <td>40.408900</td>\n",
       "      <td>148.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.785400</td>\n",
       "      <td>0.804549</td>\n",
       "      <td>0.624670</td>\n",
       "      <td>40.276800</td>\n",
       "      <td>148.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.777100</td>\n",
       "      <td>0.806952</td>\n",
       "      <td>0.623234</td>\n",
       "      <td>40.270300</td>\n",
       "      <td>148.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.784178</td>\n",
       "      <td>0.607082</td>\n",
       "      <td>40.462700</td>\n",
       "      <td>148.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.781540</td>\n",
       "      <td>0.665460</td>\n",
       "      <td>40.475800</td>\n",
       "      <td>148.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.653697</td>\n",
       "      <td>40.335600</td>\n",
       "      <td>148.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.747300</td>\n",
       "      <td>0.760778</td>\n",
       "      <td>0.657064</td>\n",
       "      <td>40.300200</td>\n",
       "      <td>148.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.751100</td>\n",
       "      <td>0.769910</td>\n",
       "      <td>0.651426</td>\n",
       "      <td>40.555100</td>\n",
       "      <td>147.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.782740</td>\n",
       "      <td>0.642136</td>\n",
       "      <td>40.150100</td>\n",
       "      <td>149.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.792446</td>\n",
       "      <td>0.635239</td>\n",
       "      <td>40.539500</td>\n",
       "      <td>148.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.736900</td>\n",
       "      <td>0.780560</td>\n",
       "      <td>0.664733</td>\n",
       "      <td>40.314400</td>\n",
       "      <td>148.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>0.778372</td>\n",
       "      <td>0.608004</td>\n",
       "      <td>40.650300</td>\n",
       "      <td>147.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.770945</td>\n",
       "      <td>0.628015</td>\n",
       "      <td>40.283600</td>\n",
       "      <td>148.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.745200</td>\n",
       "      <td>0.752190</td>\n",
       "      <td>0.661519</td>\n",
       "      <td>40.514200</td>\n",
       "      <td>148.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>0.778108</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>40.096800</td>\n",
       "      <td>149.638000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-WordMix\n",
      "{'eval_loss': 21.083614349365234, 'eval_accuracy': 0.9173684210526316, 'eval_f1': 0.9174963589172196, 'eval_precision': 0.9179184898911081, 'eval_recall': 0.9173684210526316, 'eval_runtime': 61.4087, 'eval_samples_per_second': 123.761, 'epoch': 3.51, 'run': './results/roberta-base-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1aa70ac7ad41bb8d42da1d088145e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='92000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 92000/114000 12:12:55 < 2:55:16, 2.09 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>0.799566</td>\n",
       "      <td>0.679052</td>\n",
       "      <td>94.024700</td>\n",
       "      <td>63.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.787916</td>\n",
       "      <td>0.666406</td>\n",
       "      <td>93.353700</td>\n",
       "      <td>64.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.778800</td>\n",
       "      <td>0.826211</td>\n",
       "      <td>0.632343</td>\n",
       "      <td>92.833900</td>\n",
       "      <td>64.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>0.773624</td>\n",
       "      <td>0.645425</td>\n",
       "      <td>93.361500</td>\n",
       "      <td>64.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.799342</td>\n",
       "      <td>0.633472</td>\n",
       "      <td>94.511400</td>\n",
       "      <td>63.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.762800</td>\n",
       "      <td>0.783223</td>\n",
       "      <td>0.636232</td>\n",
       "      <td>94.031600</td>\n",
       "      <td>63.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.791242</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>93.067200</td>\n",
       "      <td>64.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.744500</td>\n",
       "      <td>0.804915</td>\n",
       "      <td>0.650863</td>\n",
       "      <td>92.655400</td>\n",
       "      <td>64.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.768611</td>\n",
       "      <td>0.759018</td>\n",
       "      <td>93.481300</td>\n",
       "      <td>64.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.757800</td>\n",
       "      <td>0.777972</td>\n",
       "      <td>0.623639</td>\n",
       "      <td>92.755300</td>\n",
       "      <td>64.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.800856</td>\n",
       "      <td>0.718929</td>\n",
       "      <td>93.052400</td>\n",
       "      <td>64.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.741600</td>\n",
       "      <td>0.791840</td>\n",
       "      <td>0.712370</td>\n",
       "      <td>93.573900</td>\n",
       "      <td>64.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>0.752379</td>\n",
       "      <td>0.719596</td>\n",
       "      <td>92.847500</td>\n",
       "      <td>64.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.735900</td>\n",
       "      <td>0.777860</td>\n",
       "      <td>0.734478</td>\n",
       "      <td>92.802000</td>\n",
       "      <td>64.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.742800</td>\n",
       "      <td>0.758931</td>\n",
       "      <td>0.733699</td>\n",
       "      <td>92.371100</td>\n",
       "      <td>64.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.784267</td>\n",
       "      <td>0.706352</td>\n",
       "      <td>92.423100</td>\n",
       "      <td>64.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.766259</td>\n",
       "      <td>0.702968</td>\n",
       "      <td>93.448000</td>\n",
       "      <td>64.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.727400</td>\n",
       "      <td>0.793711</td>\n",
       "      <td>0.771026</td>\n",
       "      <td>93.126200</td>\n",
       "      <td>64.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.723158</td>\n",
       "      <td>92.585400</td>\n",
       "      <td>64.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.830530</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>92.934300</td>\n",
       "      <td>64.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>0.775349</td>\n",
       "      <td>0.720919</td>\n",
       "      <td>93.193900</td>\n",
       "      <td>64.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.729800</td>\n",
       "      <td>0.766265</td>\n",
       "      <td>0.772177</td>\n",
       "      <td>93.582800</td>\n",
       "      <td>64.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.793765</td>\n",
       "      <td>0.763877</td>\n",
       "      <td>92.897500</td>\n",
       "      <td>64.587000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.779295</td>\n",
       "      <td>0.794020</td>\n",
       "      <td>93.950900</td>\n",
       "      <td>63.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.700800</td>\n",
       "      <td>0.757580</td>\n",
       "      <td>0.789625</td>\n",
       "      <td>92.978800</td>\n",
       "      <td>64.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.700900</td>\n",
       "      <td>0.768149</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>93.820200</td>\n",
       "      <td>63.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.762485</td>\n",
       "      <td>0.783272</td>\n",
       "      <td>93.002400</td>\n",
       "      <td>64.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.792225</td>\n",
       "      <td>0.790947</td>\n",
       "      <td>94.311000</td>\n",
       "      <td>63.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.770184</td>\n",
       "      <td>0.772697</td>\n",
       "      <td>93.472800</td>\n",
       "      <td>64.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.785559</td>\n",
       "      <td>0.790417</td>\n",
       "      <td>92.794000</td>\n",
       "      <td>64.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.757446</td>\n",
       "      <td>0.805089</td>\n",
       "      <td>93.537000</td>\n",
       "      <td>64.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.765250</td>\n",
       "      <td>0.810287</td>\n",
       "      <td>92.775900</td>\n",
       "      <td>64.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.720800</td>\n",
       "      <td>0.758223</td>\n",
       "      <td>0.778718</td>\n",
       "      <td>92.867400</td>\n",
       "      <td>64.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>0.761666</td>\n",
       "      <td>0.776684</td>\n",
       "      <td>93.615900</td>\n",
       "      <td>64.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.679800</td>\n",
       "      <td>0.810117</td>\n",
       "      <td>0.780168</td>\n",
       "      <td>92.758700</td>\n",
       "      <td>64.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>0.814392</td>\n",
       "      <td>93.780600</td>\n",
       "      <td>63.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.785507</td>\n",
       "      <td>0.818646</td>\n",
       "      <td>92.531500</td>\n",
       "      <td>64.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.771645</td>\n",
       "      <td>0.762277</td>\n",
       "      <td>92.940200</td>\n",
       "      <td>64.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.669900</td>\n",
       "      <td>0.750429</td>\n",
       "      <td>0.816843</td>\n",
       "      <td>92.875800</td>\n",
       "      <td>64.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.677200</td>\n",
       "      <td>0.760784</td>\n",
       "      <td>0.823003</td>\n",
       "      <td>93.746600</td>\n",
       "      <td>64.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.677700</td>\n",
       "      <td>0.786879</td>\n",
       "      <td>0.819385</td>\n",
       "      <td>93.353100</td>\n",
       "      <td>64.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.672800</td>\n",
       "      <td>0.787513</td>\n",
       "      <td>0.802332</td>\n",
       "      <td>92.448900</td>\n",
       "      <td>64.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.797420</td>\n",
       "      <td>0.806466</td>\n",
       "      <td>93.718500</td>\n",
       "      <td>64.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>0.764258</td>\n",
       "      <td>0.831884</td>\n",
       "      <td>93.160500</td>\n",
       "      <td>64.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.792637</td>\n",
       "      <td>0.797325</td>\n",
       "      <td>93.180100</td>\n",
       "      <td>64.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.797126</td>\n",
       "      <td>0.821729</td>\n",
       "      <td>94.165700</td>\n",
       "      <td>63.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.825863</td>\n",
       "      <td>92.799000</td>\n",
       "      <td>64.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.797324</td>\n",
       "      <td>0.816444</td>\n",
       "      <td>93.347000</td>\n",
       "      <td>64.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>0.779677</td>\n",
       "      <td>0.796635</td>\n",
       "      <td>93.049300</td>\n",
       "      <td>64.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.799182</td>\n",
       "      <td>0.808314</td>\n",
       "      <td>93.049300</td>\n",
       "      <td>64.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.793589</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>93.843900</td>\n",
       "      <td>63.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.665100</td>\n",
       "      <td>0.787911</td>\n",
       "      <td>0.855360</td>\n",
       "      <td>92.520200</td>\n",
       "      <td>64.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.654800</td>\n",
       "      <td>0.795054</td>\n",
       "      <td>0.809053</td>\n",
       "      <td>93.453700</td>\n",
       "      <td>64.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.759093</td>\n",
       "      <td>0.848945</td>\n",
       "      <td>92.437000</td>\n",
       "      <td>64.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.662800</td>\n",
       "      <td>0.790998</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>91.785500</td>\n",
       "      <td>65.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.793758</td>\n",
       "      <td>0.816012</td>\n",
       "      <td>92.211200</td>\n",
       "      <td>65.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.798586</td>\n",
       "      <td>0.842602</td>\n",
       "      <td>93.590800</td>\n",
       "      <td>64.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.790297</td>\n",
       "      <td>0.857412</td>\n",
       "      <td>92.277300</td>\n",
       "      <td>65.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.651700</td>\n",
       "      <td>0.786782</td>\n",
       "      <td>0.849579</td>\n",
       "      <td>93.668600</td>\n",
       "      <td>64.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.814980</td>\n",
       "      <td>0.832580</td>\n",
       "      <td>92.318400</td>\n",
       "      <td>64.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.778601</td>\n",
       "      <td>0.827745</td>\n",
       "      <td>92.233100</td>\n",
       "      <td>65.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>0.812034</td>\n",
       "      <td>0.830233</td>\n",
       "      <td>92.478800</td>\n",
       "      <td>64.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>0.791414</td>\n",
       "      <td>0.853889</td>\n",
       "      <td>92.563600</td>\n",
       "      <td>64.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.775329</td>\n",
       "      <td>0.846433</td>\n",
       "      <td>92.120800</td>\n",
       "      <td>65.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.649200</td>\n",
       "      <td>0.782525</td>\n",
       "      <td>0.854010</td>\n",
       "      <td>92.555000</td>\n",
       "      <td>64.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.654900</td>\n",
       "      <td>0.818155</td>\n",
       "      <td>0.833121</td>\n",
       "      <td>93.354500</td>\n",
       "      <td>64.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.786968</td>\n",
       "      <td>0.863827</td>\n",
       "      <td>93.088200</td>\n",
       "      <td>64.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.642800</td>\n",
       "      <td>0.810454</td>\n",
       "      <td>0.839361</td>\n",
       "      <td>92.960500</td>\n",
       "      <td>64.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.642600</td>\n",
       "      <td>0.868823</td>\n",
       "      <td>0.840677</td>\n",
       "      <td>93.098700</td>\n",
       "      <td>64.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.629400</td>\n",
       "      <td>0.850075</td>\n",
       "      <td>0.842643</td>\n",
       "      <td>92.780000</td>\n",
       "      <td>64.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.638200</td>\n",
       "      <td>0.805261</td>\n",
       "      <td>0.842836</td>\n",
       "      <td>93.026400</td>\n",
       "      <td>64.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.629200</td>\n",
       "      <td>0.821114</td>\n",
       "      <td>0.862820</td>\n",
       "      <td>93.875100</td>\n",
       "      <td>63.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>0.870151</td>\n",
       "      <td>93.085200</td>\n",
       "      <td>64.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.851245</td>\n",
       "      <td>92.910000</td>\n",
       "      <td>64.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>0.789230</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>92.299300</td>\n",
       "      <td>65.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.792831</td>\n",
       "      <td>0.859009</td>\n",
       "      <td>93.074900</td>\n",
       "      <td>64.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.630600</td>\n",
       "      <td>0.781621</td>\n",
       "      <td>0.846485</td>\n",
       "      <td>92.486800</td>\n",
       "      <td>64.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.630400</td>\n",
       "      <td>0.824126</td>\n",
       "      <td>0.869010</td>\n",
       "      <td>92.204000</td>\n",
       "      <td>65.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.805866</td>\n",
       "      <td>0.871937</td>\n",
       "      <td>92.254000</td>\n",
       "      <td>65.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.637300</td>\n",
       "      <td>0.818739</td>\n",
       "      <td>0.853279</td>\n",
       "      <td>92.237500</td>\n",
       "      <td>65.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.606400</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.848570</td>\n",
       "      <td>92.685300</td>\n",
       "      <td>64.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.834111</td>\n",
       "      <td>0.881500</td>\n",
       "      <td>92.628500</td>\n",
       "      <td>64.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.782692</td>\n",
       "      <td>0.874461</td>\n",
       "      <td>92.813400</td>\n",
       "      <td>64.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.622400</td>\n",
       "      <td>0.814240</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>92.817900</td>\n",
       "      <td>64.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>0.832730</td>\n",
       "      <td>0.875367</td>\n",
       "      <td>93.611800</td>\n",
       "      <td>64.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.815935</td>\n",
       "      <td>0.856867</td>\n",
       "      <td>92.712600</td>\n",
       "      <td>64.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.823250</td>\n",
       "      <td>0.860768</td>\n",
       "      <td>93.875400</td>\n",
       "      <td>63.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.619600</td>\n",
       "      <td>0.838780</td>\n",
       "      <td>0.863699</td>\n",
       "      <td>92.394000</td>\n",
       "      <td>64.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>0.621400</td>\n",
       "      <td>0.827301</td>\n",
       "      <td>0.871320</td>\n",
       "      <td>93.443200</td>\n",
       "      <td>64.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.632900</td>\n",
       "      <td>0.850779</td>\n",
       "      <td>0.871320</td>\n",
       "      <td>93.762400</td>\n",
       "      <td>63.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>0.829654</td>\n",
       "      <td>0.872948</td>\n",
       "      <td>92.761100</td>\n",
       "      <td>64.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.615600</td>\n",
       "      <td>0.832762</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>92.670400</td>\n",
       "      <td>64.746000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 02:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/xlnet-base-cased-targeted-TextMix\n",
      "{'eval_loss': 29.766590118408203, 'eval_accuracy': 0.9384210526315789, 'eval_f1': 0.9382906761700585, 'eval_precision': 0.9386953278978558, 'eval_recall': 0.9384210526315789, 'eval_runtime': 138.3363, 'eval_samples_per_second': 54.939, 'epoch': 8.07, 'run': './results/xlnet-base-cased-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2965f8c133bc4ad8adabd3c8a17a6aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='28000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 28000/114000 3:46:07 < 11:34:33, 2.06 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>0.814202</td>\n",
       "      <td>0.658599</td>\n",
       "      <td>94.983400</td>\n",
       "      <td>63.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.824300</td>\n",
       "      <td>0.783878</td>\n",
       "      <td>0.653501</td>\n",
       "      <td>93.936900</td>\n",
       "      <td>63.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.789554</td>\n",
       "      <td>0.652811</td>\n",
       "      <td>94.666000</td>\n",
       "      <td>63.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.762800</td>\n",
       "      <td>0.775472</td>\n",
       "      <td>0.649541</td>\n",
       "      <td>95.132300</td>\n",
       "      <td>63.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>0.785967</td>\n",
       "      <td>0.690353</td>\n",
       "      <td>94.692200</td>\n",
       "      <td>63.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.774028</td>\n",
       "      <td>0.720262</td>\n",
       "      <td>94.132000</td>\n",
       "      <td>63.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.760700</td>\n",
       "      <td>0.749642</td>\n",
       "      <td>0.709219</td>\n",
       "      <td>93.524800</td>\n",
       "      <td>64.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.791381</td>\n",
       "      <td>0.697819</td>\n",
       "      <td>94.529700</td>\n",
       "      <td>63.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>0.752182</td>\n",
       "      <td>0.659591</td>\n",
       "      <td>93.804400</td>\n",
       "      <td>63.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.763600</td>\n",
       "      <td>0.771678</td>\n",
       "      <td>0.653735</td>\n",
       "      <td>94.129600</td>\n",
       "      <td>63.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.767091</td>\n",
       "      <td>0.663051</td>\n",
       "      <td>94.846500</td>\n",
       "      <td>63.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>0.758307</td>\n",
       "      <td>0.707062</td>\n",
       "      <td>94.495100</td>\n",
       "      <td>63.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.742900</td>\n",
       "      <td>0.798023</td>\n",
       "      <td>0.567793</td>\n",
       "      <td>95.239700</td>\n",
       "      <td>62.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>0.770519</td>\n",
       "      <td>0.724761</td>\n",
       "      <td>94.759000</td>\n",
       "      <td>63.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.761844</td>\n",
       "      <td>0.696371</td>\n",
       "      <td>94.846200</td>\n",
       "      <td>63.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>0.727301</td>\n",
       "      <td>95.564600</td>\n",
       "      <td>62.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.735600</td>\n",
       "      <td>0.770845</td>\n",
       "      <td>0.752536</td>\n",
       "      <td>94.367300</td>\n",
       "      <td>63.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.720100</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>0.756398</td>\n",
       "      <td>95.826900</td>\n",
       "      <td>62.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.744300</td>\n",
       "      <td>0.762870</td>\n",
       "      <td>0.707984</td>\n",
       "      <td>94.568700</td>\n",
       "      <td>63.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.768149</td>\n",
       "      <td>0.700548</td>\n",
       "      <td>94.293100</td>\n",
       "      <td>63.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.742800</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>0.745184</td>\n",
       "      <td>94.049700</td>\n",
       "      <td>63.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>0.763965</td>\n",
       "      <td>0.707982</td>\n",
       "      <td>93.540000</td>\n",
       "      <td>64.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.725400</td>\n",
       "      <td>0.767219</td>\n",
       "      <td>0.727772</td>\n",
       "      <td>94.949900</td>\n",
       "      <td>63.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.769057</td>\n",
       "      <td>0.716144</td>\n",
       "      <td>93.946800</td>\n",
       "      <td>63.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.706900</td>\n",
       "      <td>0.817849</td>\n",
       "      <td>0.664132</td>\n",
       "      <td>94.780900</td>\n",
       "      <td>63.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>0.768273</td>\n",
       "      <td>0.751065</td>\n",
       "      <td>93.464900</td>\n",
       "      <td>64.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.706400</td>\n",
       "      <td>0.776075</td>\n",
       "      <td>0.724187</td>\n",
       "      <td>93.523000</td>\n",
       "      <td>64.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.752183</td>\n",
       "      <td>0.728176</td>\n",
       "      <td>93.847100</td>\n",
       "      <td>63.934000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 3], [2, 3], [3, 0]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 3], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 02:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/xlnet-base-cased-targeted-SentMix\n",
      "{'eval_loss': 22.84684181213379, 'eval_accuracy': 0.9336842105263158, 'eval_f1': 0.9337134499138177, 'eval_precision': 0.9341871089752022, 'eval_recall': 0.9336842105263158, 'eval_runtime': 138.3086, 'eval_samples_per_second': 54.95, 'epoch': 2.46, 'run': './results/xlnet-base-cased-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\0eeeaaa5fb6dffd81458e293dfea1adba2881ffcbdc3fb56baeb5a892566c29a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db1945dd34a42b99b1e471e38538ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='26000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 26000/114000 3:26:25 < 11:38:44, 2.10 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.075800</td>\n",
       "      <td>0.865502</td>\n",
       "      <td>0.628614</td>\n",
       "      <td>91.005300</td>\n",
       "      <td>65.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.839501</td>\n",
       "      <td>0.589337</td>\n",
       "      <td>91.002400</td>\n",
       "      <td>65.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.848991</td>\n",
       "      <td>0.554825</td>\n",
       "      <td>90.788400</td>\n",
       "      <td>66.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>0.815506</td>\n",
       "      <td>0.597819</td>\n",
       "      <td>91.164300</td>\n",
       "      <td>65.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.843520</td>\n",
       "      <td>0.603635</td>\n",
       "      <td>92.382200</td>\n",
       "      <td>64.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.805740</td>\n",
       "      <td>0.604512</td>\n",
       "      <td>91.636200</td>\n",
       "      <td>65.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.795100</td>\n",
       "      <td>0.798661</td>\n",
       "      <td>0.569320</td>\n",
       "      <td>92.520700</td>\n",
       "      <td>64.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.838620</td>\n",
       "      <td>0.586105</td>\n",
       "      <td>92.114100</td>\n",
       "      <td>65.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>0.804375</td>\n",
       "      <td>0.594340</td>\n",
       "      <td>91.772800</td>\n",
       "      <td>65.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.806600</td>\n",
       "      <td>0.812990</td>\n",
       "      <td>0.592974</td>\n",
       "      <td>91.519500</td>\n",
       "      <td>65.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.821900</td>\n",
       "      <td>0.871610</td>\n",
       "      <td>0.601896</td>\n",
       "      <td>92.352100</td>\n",
       "      <td>64.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.785900</td>\n",
       "      <td>0.805220</td>\n",
       "      <td>0.579357</td>\n",
       "      <td>91.817400</td>\n",
       "      <td>65.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>0.802571</td>\n",
       "      <td>0.589135</td>\n",
       "      <td>91.690100</td>\n",
       "      <td>65.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>0.822070</td>\n",
       "      <td>0.593240</td>\n",
       "      <td>92.223500</td>\n",
       "      <td>65.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.792300</td>\n",
       "      <td>0.863568</td>\n",
       "      <td>0.531536</td>\n",
       "      <td>91.800000</td>\n",
       "      <td>65.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.803579</td>\n",
       "      <td>0.631149</td>\n",
       "      <td>90.668600</td>\n",
       "      <td>66.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.777100</td>\n",
       "      <td>0.798774</td>\n",
       "      <td>0.580652</td>\n",
       "      <td>90.703600</td>\n",
       "      <td>66.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.778200</td>\n",
       "      <td>0.816770</td>\n",
       "      <td>0.571093</td>\n",
       "      <td>91.932900</td>\n",
       "      <td>65.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.780700</td>\n",
       "      <td>0.824459</td>\n",
       "      <td>0.586898</td>\n",
       "      <td>91.725900</td>\n",
       "      <td>65.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.804800</td>\n",
       "      <td>0.838568</td>\n",
       "      <td>0.622124</td>\n",
       "      <td>92.285300</td>\n",
       "      <td>65.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.771600</td>\n",
       "      <td>0.805636</td>\n",
       "      <td>0.612496</td>\n",
       "      <td>91.161800</td>\n",
       "      <td>65.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.772300</td>\n",
       "      <td>0.826735</td>\n",
       "      <td>0.626180</td>\n",
       "      <td>92.112800</td>\n",
       "      <td>65.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.609673</td>\n",
       "      <td>92.152700</td>\n",
       "      <td>65.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.760300</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>0.580982</td>\n",
       "      <td>91.431900</td>\n",
       "      <td>65.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.760700</td>\n",
       "      <td>0.802553</td>\n",
       "      <td>0.600187</td>\n",
       "      <td>91.370800</td>\n",
       "      <td>65.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.806824</td>\n",
       "      <td>0.616312</td>\n",
       "      <td>91.480500</td>\n",
       "      <td>65.588000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 3], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 0], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 0]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 2], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "New targets: [[0, 2], [1, 0], [2, 3], [3, 2]]\n",
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 02:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/xlnet-base-cased-targeted-WordMix\n",
      "{'eval_loss': 19.878807067871094, 'eval_accuracy': 0.9064473684210527, 'eval_f1': 0.9063317617010482, 'eval_precision': 0.9085388074682332, 'eval_recall': 0.9064473684210527, 'eval_runtime': 138.3666, 'eval_samples_per_second': 54.927, 'epoch': 2.28, 'run': './results/xlnet-base-cased-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "        \n",
    "    for t in ts: \n",
    "        \n",
    "        t_str = t.__class__.__name__\n",
    "        checkpoint = './results/' + MODEL_NAME + '-targeted-' + t_str\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4).to(device)\n",
    "\n",
    "        dataset = load_dataset('ag_news', split='train') \n",
    "        dataset_dict = dataset.train_test_split(\n",
    "            test_size = 0.05,\n",
    "            train_size = 0.95,\n",
    "            shuffle = True\n",
    "        )\n",
    "        train_dataset = dataset_dict['train']\n",
    "        eval_dataset = dataset_dict['test']\n",
    "\n",
    "        test_dataset = load_dataset('ag_news', split='test') \n",
    "        test_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        train_batch_size = 10\n",
    "        eval_batch_size  = 32\n",
    "        num_epoch = 10\n",
    "        gradient_accumulation_steps = 1\n",
    "        max_steps = int((len(train_dataset) * num_epoch / gradient_accumulation_steps) / train_batch_size)\n",
    "\n",
    "        tmcb = TargetedMixturesCallback(\n",
    "            dataloader=DataLoader(eval_dataset, batch_size=32),\n",
    "            device=device\n",
    "        )\n",
    "        escb = EarlyStoppingCallback(\n",
    "            early_stopping_patience=10\n",
    "        )\n",
    "        tmc = TargetedMixturesCollator(\n",
    "            tokenize_fn=tokenize_fn, \n",
    "            transform=t,\n",
    "            target_prob=0.5\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\\\n",
    "            output_dir=checkpoint,\n",
    "            overwrite_output_dir=True,\n",
    "            max_steps=max_steps,\n",
    "            save_steps=int(max_steps / 10),\n",
    "            save_total_limit=1,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "            warmup_steps=int(max_steps / 10),\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=1000,\n",
    "            logging_first_step=True,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            remove_unused_columns=False\n",
    "        )\n",
    "\n",
    "        trainer = TargetedTrainer(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_metrics_w_soft_target,                  \n",
    "            train_dataset=train_dataset,         \n",
    "            eval_dataset=eval_dataset,\n",
    "            data_collator=tmc,\n",
    "            callbacks=[tmcb, escb]\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # test with ORIG data\n",
    "        trainer.eval_dataset = test_dataset\n",
    "        trainer.compute_metrics = compute_metrics\n",
    "        trainer.data_collator = DefaultCollator()\n",
    "        trainer.remove_callback(tmcb)\n",
    "\n",
    "        out_orig = trainer.evaluate()\n",
    "        out_orig['run'] = checkpoint\n",
    "        out_orig['test'] = \"ORIG\"\n",
    "        print('ORIG for {}\\n{}'.format(checkpoint, out_orig))\n",
    "\n",
    "        results.append(out_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>run</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.480539</td>\n",
       "      <td>0.934342</td>\n",
       "      <td>0.934263</td>\n",
       "      <td>0.934208</td>\n",
       "      <td>0.934342</td>\n",
       "      <td>61.8223</td>\n",
       "      <td>122.933</td>\n",
       "      <td>2.81</td>\n",
       "      <td>./results/bert-base-uncased-targeted-TextMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.817755</td>\n",
       "      <td>0.932895</td>\n",
       "      <td>0.932916</td>\n",
       "      <td>0.933717</td>\n",
       "      <td>0.932895</td>\n",
       "      <td>61.8966</td>\n",
       "      <td>122.785</td>\n",
       "      <td>5.26</td>\n",
       "      <td>./results/bert-base-uncased-targeted-SentMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.799892</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909688</td>\n",
       "      <td>0.911361</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>61.8091</td>\n",
       "      <td>122.959</td>\n",
       "      <td>2.11</td>\n",
       "      <td>./results/bert-base-uncased-targeted-WordMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.608761</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.930283</td>\n",
       "      <td>0.931262</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>60.8437</td>\n",
       "      <td>124.910</td>\n",
       "      <td>2.28</td>\n",
       "      <td>./results/roberta-base-targeted-TextMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.410807</td>\n",
       "      <td>0.935132</td>\n",
       "      <td>0.935281</td>\n",
       "      <td>0.936063</td>\n",
       "      <td>0.935132</td>\n",
       "      <td>60.5309</td>\n",
       "      <td>125.556</td>\n",
       "      <td>3.16</td>\n",
       "      <td>./results/roberta-base-targeted-SentMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.083614</td>\n",
       "      <td>0.917368</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.917918</td>\n",
       "      <td>0.917368</td>\n",
       "      <td>61.4087</td>\n",
       "      <td>123.761</td>\n",
       "      <td>3.51</td>\n",
       "      <td>./results/roberta-base-targeted-WordMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.766590</td>\n",
       "      <td>0.938421</td>\n",
       "      <td>0.938291</td>\n",
       "      <td>0.938695</td>\n",
       "      <td>0.938421</td>\n",
       "      <td>138.3363</td>\n",
       "      <td>54.939</td>\n",
       "      <td>8.07</td>\n",
       "      <td>./results/xlnet-base-cased-targeted-TextMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.846842</td>\n",
       "      <td>0.933684</td>\n",
       "      <td>0.933713</td>\n",
       "      <td>0.934187</td>\n",
       "      <td>0.933684</td>\n",
       "      <td>138.3086</td>\n",
       "      <td>54.950</td>\n",
       "      <td>2.46</td>\n",
       "      <td>./results/xlnet-base-cased-targeted-SentMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.878807</td>\n",
       "      <td>0.906447</td>\n",
       "      <td>0.906332</td>\n",
       "      <td>0.908539</td>\n",
       "      <td>0.906447</td>\n",
       "      <td>138.3666</td>\n",
       "      <td>54.927</td>\n",
       "      <td>2.28</td>\n",
       "      <td>./results/xlnet-base-cased-targeted-WordMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "0  24.480539       0.934342  0.934263        0.934208     0.934342   \n",
       "1  26.817755       0.932895  0.932916        0.933717     0.932895   \n",
       "2  20.799892       0.910000  0.909688        0.911361     0.910000   \n",
       "3  23.608761       0.930000  0.930283        0.931262     0.930000   \n",
       "4  23.410807       0.935132  0.935281        0.936063     0.935132   \n",
       "5  21.083614       0.917368  0.917496        0.917918     0.917368   \n",
       "6  29.766590       0.938421  0.938291        0.938695     0.938421   \n",
       "7  22.846842       0.933684  0.933713        0.934187     0.933684   \n",
       "8  19.878807       0.906447  0.906332        0.908539     0.906447   \n",
       "\n",
       "   eval_runtime  eval_samples_per_second  epoch  \\\n",
       "0       61.8223                  122.933   2.81   \n",
       "1       61.8966                  122.785   5.26   \n",
       "2       61.8091                  122.959   2.11   \n",
       "3       60.8437                  124.910   2.28   \n",
       "4       60.5309                  125.556   3.16   \n",
       "5       61.4087                  123.761   3.51   \n",
       "6      138.3363                   54.939   8.07   \n",
       "7      138.3086                   54.950   2.46   \n",
       "8      138.3666                   54.927   2.28   \n",
       "\n",
       "                                            run  test  \n",
       "0  ./results/bert-base-uncased-targeted-TextMix  ORIG  \n",
       "1  ./results/bert-base-uncased-targeted-SentMix  ORIG  \n",
       "2  ./results/bert-base-uncased-targeted-WordMix  ORIG  \n",
       "3       ./results/roberta-base-targeted-TextMix  ORIG  \n",
       "4       ./results/roberta-base-targeted-SentMix  ORIG  \n",
       "5       ./results/roberta-base-targeted-WordMix  ORIG  \n",
       "6   ./results/xlnet-base-cased-targeted-TextMix  ORIG  \n",
       "7   ./results/xlnet-base-cased-targeted-SentMix  ORIG  \n",
       "8   ./results/xlnet-base-cased-targeted-WordMix  ORIG  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_AG_NEWS_targeted_r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG for ./results/bert-base-uncased-targeted-TextMix\n",
    "# {'eval_loss': 31.2364559173584, 'eval_accuracy': 0.9381578947368421, 'eval_f1': 0.9381945850526017, 'eval_precision': 0.938240633851668, 'eval_recall': 0.9381578947368421, 'eval_runtime': 117.2622, 'eval_samples_per_second': 64.812, 'epoch': 5.0, 'run': 'TextMix', 'test': 'ORIG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
