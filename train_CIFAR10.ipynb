{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DverR9dCWR4K"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_DJonB4oNCb",
    "outputId": "1fb2de2a-a103-410a-baba-eba5e200a344"
   },
   "outputs": [],
   "source": [
    "# https://github.com/ildoonet/pytorch-randaugment\n",
    "# !pip install git+https://github.com/ildoonet/pytorch-randaugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wLXwJptDuA1B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from RandAugment import RandAugment\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1C6dWZ5Ku9Ld"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Duxenxmw3dT"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "95b79b5226e14cd9b7691c26bbe21499",
      "278896a7f7d8400aa232a5d1b7f35fd1",
      "556508dab46f4c60a810d5446ff6cfd0",
      "6450ad15ebf84a8781c4820e18b3fed8",
      "a72b484ea4904348b930c87eaa0f98d3",
      "c8be339df5294b92ba333b06e60baa7f",
      "cc0437758ed1470db51d5d6c55594874",
      "362f833f86134a4cb9da25a1014f75c4"
     ]
    },
    "id": "R-S87NL4uDlo",
    "outputId": "34ae79bd-4115-4d26-f137-b598fbe4ce90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD),\n",
    "])\n",
    "\n",
    "# Add RandAugment with N, M(hyperparameter)\n",
    "transform.transforms.insert(0, RandAugment(n=3, m=2))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='C:\\data\\CIFAR10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='C:\\data\\CIFAR10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoMVlov5wsGy"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pDRZE4-3uieU"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(module):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(module.weight.data, mode='fan_out')\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        module.weight.data.fill_(1)\n",
    "        module.bias.data.zero_()\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 remove_first_relu,\n",
    "                 add_last_bn,\n",
    "                 preact=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self._remove_first_relu = remove_first_relu\n",
    "        self._add_last_bn = add_last_bn\n",
    "        self._preact = preact\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,  # downsample with first conv\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        if add_last_bn:\n",
    "            self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut.add_module(\n",
    "                'conv',\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,  # downsample\n",
    "                    padding=0,\n",
    "                    bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self._preact:\n",
    "            x = F.relu(\n",
    "                self.bn1(x), inplace=True)  # shortcut after preactivation\n",
    "            y = self.conv1(x)\n",
    "        else:\n",
    "            # preactivation only for residual path\n",
    "            y = self.bn1(x)\n",
    "            if not self._remove_first_relu:\n",
    "                y = F.relu(y, inplace=True)\n",
    "            y = self.conv1(y)\n",
    "\n",
    "        y = F.relu(self.bn2(y), inplace=True)\n",
    "        y = self.conv2(y)\n",
    "\n",
    "        if self._add_last_bn:\n",
    "            y = self.bn3(y)\n",
    "\n",
    "        y += self.shortcut(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 remove_first_relu,\n",
    "                 add_last_bn,\n",
    "                 preact=False):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        self._remove_first_relu = remove_first_relu\n",
    "        self._add_last_bn = add_last_bn\n",
    "        self._preact = preact\n",
    "\n",
    "        bottleneck_channels = out_channels // self.expansion\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,  # downsample with 3x3 conv\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False)\n",
    "\n",
    "        if add_last_bn:\n",
    "            self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()  # identity\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut.add_module(\n",
    "                'conv',\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,  # downsample\n",
    "                    padding=0,\n",
    "                    bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self._preact:\n",
    "            x = F.relu(\n",
    "                self.bn1(x), inplace=True)  # shortcut after preactivation\n",
    "            y = self.conv1(x)\n",
    "        else:\n",
    "            # preactivation only for residual path\n",
    "            y = self.bn1(x)\n",
    "            if not self._remove_first_relu:\n",
    "                y = F.relu(y, inplace=True)\n",
    "            y = self.conv1(y)\n",
    "\n",
    "        y = F.relu(self.bn2(y), inplace=True)\n",
    "        y = self.conv2(y)\n",
    "        y = F.relu(self.bn3(y), inplace=True)\n",
    "        y = self.conv3(y)\n",
    "\n",
    "        if self._add_last_bn:\n",
    "            y = self.bn4(y)\n",
    "\n",
    "        y += self.shortcut(x)\n",
    "        return y\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        input_shape = config['input_shape']\n",
    "        n_classes = config['n_classes']\n",
    "\n",
    "        base_channels = config['base_channels']\n",
    "        self._remove_first_relu = False\n",
    "        self._add_last_bn = False\n",
    "        block_type = config['block_type']\n",
    "        depth = config['depth']\n",
    "        preact_stage = [True, True, True]\n",
    "\n",
    "        assert block_type in ['basic', 'bottleneck']\n",
    "        if block_type == 'basic':\n",
    "            block = BasicBlock\n",
    "            n_blocks_per_stage = (depth - 2) // 6\n",
    "            assert n_blocks_per_stage * 6 + 2 == depth\n",
    "        else:\n",
    "            block = BottleneckBlock\n",
    "            n_blocks_per_stage = (depth - 2) // 9\n",
    "            assert n_blocks_per_stage * 9 + 2 == depth\n",
    "\n",
    "        n_channels = [\n",
    "            base_channels,\n",
    "            base_channels * 2 * block.expansion,\n",
    "            base_channels * 4 * block.expansion,\n",
    "        ]\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            input_shape[1],\n",
    "            n_channels[0],\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        self.stage1 = self._make_stage(\n",
    "            n_channels[0],\n",
    "            n_channels[0],\n",
    "            n_blocks_per_stage,\n",
    "            block,\n",
    "            stride=1,\n",
    "            preact=preact_stage[0])\n",
    "        self.stage2 = self._make_stage(\n",
    "            n_channels[0],\n",
    "            n_channels[1],\n",
    "            n_blocks_per_stage,\n",
    "            block,\n",
    "            stride=2,\n",
    "            preact=preact_stage[1])\n",
    "        self.stage3 = self._make_stage(\n",
    "            n_channels[1],\n",
    "            n_channels[2],\n",
    "            n_blocks_per_stage,\n",
    "            block,\n",
    "            stride=2,\n",
    "            preact=preact_stage[2])\n",
    "        self.bn = nn.BatchNorm2d(n_channels[2])\n",
    "\n",
    "        # compute conv feature size\n",
    "        with torch.no_grad():\n",
    "            self.feature_size = self._forward_conv(\n",
    "                torch.zeros(*input_shape)).view(-1).shape[0]\n",
    "\n",
    "        self.fc = nn.Linear(self.feature_size, n_classes)\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(initialize_weights)\n",
    "\n",
    "    def _make_stage(self, in_channels, out_channels, n_blocks, block, stride,\n",
    "                    preact):\n",
    "        stage = nn.Sequential()\n",
    "        for index in range(n_blocks):\n",
    "            block_name = 'block{}'.format(index + 1)\n",
    "            if index == 0:\n",
    "                stage.add_module(\n",
    "                    block_name,\n",
    "                    block(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        stride=stride,\n",
    "                        remove_first_relu=self._remove_first_relu,\n",
    "                        add_last_bn=self._add_last_bn,\n",
    "                        preact=preact))\n",
    "            else:\n",
    "                stage.add_module(\n",
    "                    block_name,\n",
    "                    block(\n",
    "                        out_channels,\n",
    "                        out_channels,\n",
    "                        stride=1,\n",
    "                        remove_first_relu=self._remove_first_relu,\n",
    "                        add_last_bn=self._add_last_bn,\n",
    "                        preact=False))\n",
    "        return stage\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = F.relu(\n",
    "            self.bn(x),\n",
    "            inplace=True)  # apply BN and ReLU before average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-N4MXd1wzx6"
   },
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gh3_hjBpy5LQ"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, num):\n",
    "        self.val = val\n",
    "        self.sum += val * num\n",
    "        self.count += num\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train(epoch, model, optimizer, criterion, train_loader, device):\n",
    "    global global_step\n",
    "\n",
    "    print('Train {}'.format(epoch))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_meter = AverageMeter()\n",
    "    accuracy_meter = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, (data, targets) in enumerate(train_loader):\n",
    "        global_step += 1\n",
    "\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num = data.size(0)\n",
    "\n",
    "        loss_ = loss.item()\n",
    "        loss_meter.update(loss_, num)\n",
    "\n",
    "        if len(targets.shape) > 1:\n",
    "            k=2\n",
    "            y_weights, y_idx = torch.topk(targets, k=k, dim=1)\n",
    "            out_weights, out_idx = torch.topk(outputs, k=k, dim=1)\n",
    "            correct_ = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "            accuracy = correct_ / num\n",
    "        else:\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_ = preds.eq(targets).sum().item()\n",
    "            accuracy = correct_ / num\n",
    "\n",
    "        accuracy_meter.update(accuracy, num)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch {} Step {}/{} '\n",
    "                        'Loss {:.4f} ({:.4f}) '\n",
    "                        'Accuracy {:.4f} ({:.4f})'.format(\n",
    "                            epoch,\n",
    "                            step,\n",
    "                            len(train_loader),\n",
    "                            loss_meter.val,\n",
    "                            loss_meter.avg,\n",
    "                            accuracy_meter.val,\n",
    "                            accuracy_meter.avg,\n",
    "                        ))\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print('Elapsed {:.2f}'.format(elapsed))\n",
    "\n",
    "    train_log = {\n",
    "        'epoch': epoch,\n",
    "        'train': {\n",
    "            'loss': loss_meter.avg,\n",
    "            'accuracy': accuracy,\n",
    "            'time': elapsed,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return train_log\n",
    "\n",
    "def test(epoch, model, criterion, test_loader, device):\n",
    "    print('Test {}'.format(epoch))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_meter = AverageMeter()\n",
    "    correct_meter = AverageMeter()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for step, (data, targets) in enumerate(test_loader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            correct_ = preds.eq(targets).sum().item()\n",
    "            correct_meter.update(correct_, 1)\n",
    "\n",
    "            num = data.size(0)\n",
    "\n",
    "            loss_ = loss.item()\n",
    "            loss_meter.update(loss_, num)\n",
    "\n",
    "    accuracy = correct_meter.sum / len(test_loader.dataset)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "        epoch, loss_meter.avg, accuracy))\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print('Elapsed {:.2f}'.format(elapsed))\n",
    "\n",
    "    test_log = {\n",
    "        'epoch': epoch,\n",
    "        'test': {\n",
    "            'loss': loss_meter.avg,\n",
    "            'accuracy': accuracy,\n",
    "            'time': elapsed\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VCV9fDZ3lmc"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CwHk5yKH39Z-"
   },
   "outputs": [],
   "source": [
    "save_dir = \"./pretrained/\"\n",
    "\n",
    "epochs = 300\n",
    "early_stopping_tolerance = 10\n",
    "\n",
    "base_lr = 0.2\n",
    "weight_decay = 1e-4\n",
    "momentum = 0.9\n",
    "nesterov = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cLd7T96xuFtm"
   },
   "outputs": [],
   "source": [
    "model = Network({\n",
    "    'block_type': 'basic',\n",
    "    'depth': 20,\n",
    "    'base_channels': 64,\n",
    "    'input_shape': [1,3,32,32],\n",
    "    'n_classes': 10}).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=base_lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    "    nesterov=nesterov)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WwCBpArulwO",
    "outputId": "42b65e1e-e0a7-4a05-bce1-32bd3516faf5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "early_stopping_steps = 0\n",
    "\n",
    "epoch_logs = []\n",
    "best_acc = 0\n",
    "for epoch in range(1, epochs+1):        \n",
    "    \n",
    "    train_log = train(epoch, model, optimizer, criterion, trainloader, device)\n",
    "    test_log  = test(epoch, model, criterion, testloader, device)\n",
    "\n",
    "    early_stopping_steps += 1\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_logs.append(train_log)\n",
    "    epoch_logs.append(test_log)\n",
    "\n",
    "    if test_log['test']['accuracy'] > best_acc:\n",
    "        early_stopping_steps = 0\n",
    "        for item in os.listdir(save_dir):\n",
    "            if item.endswith(\".pth\"):\n",
    "                os.remove(os.path.join(save_dir, item))\n",
    "        best_acc = test_log['test']['accuracy']\n",
    "        model_path = os.path.join(save_dir, '.CIFAR10', 'resnet_cifar10_' + str(round(best_acc, 2)) + '.pth')\n",
    "        torch.save(model, model_path)\n",
    "\n",
    "    if early_stopping_steps > early_stopping_tolerance:\n",
    "        break\n",
    "        \n",
    "print('best_acc', best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQch9nArWW7I"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "CwiNG-ZEuo01",
    "outputId": "c14172ea-adb2-417f-9d92-30921453833a"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        data, targets = batch\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(data)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpCgAn66uz8s"
   },
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        data, targets = batch\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(targets, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FoMVlov5wsGy",
    "h-N4MXd1wzx6"
   ],
   "name": "Copy of train_CIFAR10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "278896a7f7d8400aa232a5d1b7f35fd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "362f833f86134a4cb9da25a1014f75c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "556508dab46f4c60a810d5446ff6cfd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8be339df5294b92ba333b06e60baa7f",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a72b484ea4904348b930c87eaa0f98d3",
      "value": 170498071
     }
    },
    "6450ad15ebf84a8781c4820e18b3fed8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_362f833f86134a4cb9da25a1014f75c4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cc0437758ed1470db51d5d6c55594874",
      "value": " 170499072/? [02:47&lt;00:00, 1019032.23it/s]"
     }
    },
    "95b79b5226e14cd9b7691c26bbe21499": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_556508dab46f4c60a810d5446ff6cfd0",
       "IPY_MODEL_6450ad15ebf84a8781c4820e18b3fed8"
      ],
      "layout": "IPY_MODEL_278896a7f7d8400aa232a5d1b7f35fd1"
     }
    },
    "a72b484ea4904348b930c87eaa0f98d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c8be339df5294b92ba333b06e60baa7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc0437758ed1470db51d5d6c55594874": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
