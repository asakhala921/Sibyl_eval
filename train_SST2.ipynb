{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "utjMLdmqsUuA"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WT_xnGBpTNuZ"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y, nb_classes=2):\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.expand_dims(np.array(y), 0)\n",
    "    res = np.eye(nb_classes)[np.array(y).reshape(-1)]\n",
    "    return res.reshape(list(y.shape)+[nb_classes])[0]\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=250)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1.mean(),\n",
    "        'precision': precision.mean(),\n",
    "        'recall': recall.mean()\n",
    "    }\n",
    "\n",
    "def acc_at_k(y_true, y_pred, k=2):\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    if acc.item() > 1:\n",
    "        print(y_true.shape, y_true)\n",
    "        print(y_pred.shape, y_pred)\n",
    "    return acc.item()\n",
    "\n",
    "def CEwST_loss(logits, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Cross Entropy with Soft Target (CEwST) Loss\n",
    "    :param logits: (batch, *)\n",
    "    :param target: (batch, *) same shape as logits, each item must be a valid distribution: target[i, :].sum() == 1.\n",
    "    \"\"\"\n",
    "    logprobs = torch.nn.functional.log_softmax(logits.view(logits.shape[0], -1), dim=1)\n",
    "    batchloss = - torch.sum(target.view(target.shape[0], -1) * logprobs, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return batchloss\n",
    "    elif reduction == 'mean':\n",
    "        return torch.mean(batchloss)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(batchloss)\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported reduction mode.')\n",
    "\n",
    "def compute_metrics_w_soft_target(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    acc = acc_at_k(labels, preds, k=2)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }\n",
    "\n",
    "class Trainer_w_soft_target(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = CEwST_loss(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "    \n",
    "class DefaultCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']\n",
    "# ['ORIG', 'INV', 'SIB', 'INVSIB', 'TextMix', 'SentMix', 'WordMix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nq1i8QiBtY0e"
   },
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "59b96dd300ae4a56b2d58ca0de0bb7f6",
      "e3c71b92f2a0484bb70123a86f855f9d",
      "dd27134d896448b6b385ce45da7556ee",
      "c92040617a854d8d96cc8ba678f0b271",
      "367cfe385d38427dbdf4325a70c0dc2e",
      "f86a86b6b9c64cc989e89b27693d8a2f",
      "14dc24ef59d341a88d1bdb69f3cacde6",
      "46cc6e7671244f1d9167855a45a36af8",
      "81821a97e02445539ccabcc2091cba95",
      "212a6447739d45b5b57e5815ff538f57",
      "4b1f7506e1a44d109d918b1f16d6bb75",
      "f177b91513ec4039bc7c6e61d15db9a2",
      "00554915f7ad47b9b80d65294dbfdd37",
      "d5f641be531341dbb007330b7e245169",
      "7158ce3f315647aba9299519fcec4be7",
      "0768ccf7a2e64f819c7401d7db258d16"
     ]
    },
    "id": "T-krnPy6TDSB",
    "outputId": "7161b883-f15a-449f-86fa-e8bbbfc6e9c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "rename_column_ is deprecated and will be removed in the next major version of datasets. Use the dataset.rename_column method instead.\n",
      "Loading cached split indices for dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-f091fffe09931764.arrow and C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b8768bf7f4b494b6.arrow\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-688409d894c01b4c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-3194875e5f0f5a37.arrow\n",
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='54000' max='71978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54000/71978 1:41:31 < 33:48, 8.86 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.292297</td>\n",
       "      <td>0.913230</td>\n",
       "      <td>0.912701</td>\n",
       "      <td>0.911576</td>\n",
       "      <td>0.915729</td>\n",
       "      <td>7.599600</td>\n",
       "      <td>398.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.282485</td>\n",
       "      <td>0.916859</td>\n",
       "      <td>0.914942</td>\n",
       "      <td>0.921683</td>\n",
       "      <td>0.911367</td>\n",
       "      <td>7.614300</td>\n",
       "      <td>398.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.322373</td>\n",
       "      <td>0.925437</td>\n",
       "      <td>0.924978</td>\n",
       "      <td>0.923799</td>\n",
       "      <td>0.928048</td>\n",
       "      <td>7.602000</td>\n",
       "      <td>398.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.332350</td>\n",
       "      <td>0.920488</td>\n",
       "      <td>0.918630</td>\n",
       "      <td>0.925671</td>\n",
       "      <td>0.914931</td>\n",
       "      <td>7.596200</td>\n",
       "      <td>399.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.299632</td>\n",
       "      <td>0.931376</td>\n",
       "      <td>0.930746</td>\n",
       "      <td>0.929743</td>\n",
       "      <td>0.932152</td>\n",
       "      <td>7.591800</td>\n",
       "      <td>399.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.260900</td>\n",
       "      <td>0.264620</td>\n",
       "      <td>0.928736</td>\n",
       "      <td>0.928145</td>\n",
       "      <td>0.926992</td>\n",
       "      <td>0.929994</td>\n",
       "      <td>7.596900</td>\n",
       "      <td>398.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.332025</td>\n",
       "      <td>0.931046</td>\n",
       "      <td>0.929848</td>\n",
       "      <td>0.932649</td>\n",
       "      <td>0.927892</td>\n",
       "      <td>7.590400</td>\n",
       "      <td>399.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.297886</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.932449</td>\n",
       "      <td>0.931331</td>\n",
       "      <td>0.934152</td>\n",
       "      <td>7.591000</td>\n",
       "      <td>399.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.324828</td>\n",
       "      <td>0.925437</td>\n",
       "      <td>0.923869</td>\n",
       "      <td>0.929176</td>\n",
       "      <td>0.920784</td>\n",
       "      <td>7.588900</td>\n",
       "      <td>399.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.283990</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>0.938267</td>\n",
       "      <td>0.937938</td>\n",
       "      <td>0.938622</td>\n",
       "      <td>7.586700</td>\n",
       "      <td>399.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.290693</td>\n",
       "      <td>0.941603</td>\n",
       "      <td>0.940937</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>0.941294</td>\n",
       "      <td>7.580300</td>\n",
       "      <td>399.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.374736</td>\n",
       "      <td>0.920488</td>\n",
       "      <td>0.920097</td>\n",
       "      <td>0.919217</td>\n",
       "      <td>0.923956</td>\n",
       "      <td>7.569700</td>\n",
       "      <td>400.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.294186</td>\n",
       "      <td>0.942923</td>\n",
       "      <td>0.942204</td>\n",
       "      <td>0.942372</td>\n",
       "      <td>0.942042</td>\n",
       "      <td>7.579000</td>\n",
       "      <td>399.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.284431</td>\n",
       "      <td>0.940944</td>\n",
       "      <td>0.940226</td>\n",
       "      <td>0.940194</td>\n",
       "      <td>0.940259</td>\n",
       "      <td>7.598600</td>\n",
       "      <td>398.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.301595</td>\n",
       "      <td>0.941274</td>\n",
       "      <td>0.940538</td>\n",
       "      <td>0.940671</td>\n",
       "      <td>0.940409</td>\n",
       "      <td>7.593400</td>\n",
       "      <td>399.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.150600</td>\n",
       "      <td>0.250693</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>0.943574</td>\n",
       "      <td>0.943478</td>\n",
       "      <td>0.943672</td>\n",
       "      <td>7.579700</td>\n",
       "      <td>399.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.239584</td>\n",
       "      <td>0.950511</td>\n",
       "      <td>0.949839</td>\n",
       "      <td>0.950501</td>\n",
       "      <td>0.949246</td>\n",
       "      <td>7.580600</td>\n",
       "      <td>399.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.267051</td>\n",
       "      <td>0.944573</td>\n",
       "      <td>0.943879</td>\n",
       "      <td>0.944013</td>\n",
       "      <td>0.943749</td>\n",
       "      <td>7.580000</td>\n",
       "      <td>399.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.216486</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>0.944274</td>\n",
       "      <td>0.943940</td>\n",
       "      <td>0.944633</td>\n",
       "      <td>7.572700</td>\n",
       "      <td>400.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.252960</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>0.943481</td>\n",
       "      <td>0.944174</td>\n",
       "      <td>0.942864</td>\n",
       "      <td>7.576700</td>\n",
       "      <td>400.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.261508</td>\n",
       "      <td>0.945892</td>\n",
       "      <td>0.945263</td>\n",
       "      <td>0.945015</td>\n",
       "      <td>0.945525</td>\n",
       "      <td>7.586100</td>\n",
       "      <td>399.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.292319</td>\n",
       "      <td>0.945563</td>\n",
       "      <td>0.944810</td>\n",
       "      <td>0.945587</td>\n",
       "      <td>0.944127</td>\n",
       "      <td>7.579900</td>\n",
       "      <td>399.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.299534</td>\n",
       "      <td>0.947212</td>\n",
       "      <td>0.946495</td>\n",
       "      <td>0.947152</td>\n",
       "      <td>0.945907</td>\n",
       "      <td>7.569800</td>\n",
       "      <td>400.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.288571</td>\n",
       "      <td>0.945563</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>0.944084</td>\n",
       "      <td>0.946328</td>\n",
       "      <td>7.576100</td>\n",
       "      <td>400.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.293837</td>\n",
       "      <td>0.947212</td>\n",
       "      <td>0.946590</td>\n",
       "      <td>0.946401</td>\n",
       "      <td>0.946787</td>\n",
       "      <td>7.582400</td>\n",
       "      <td>399.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.318765</td>\n",
       "      <td>0.942263</td>\n",
       "      <td>0.941722</td>\n",
       "      <td>0.940737</td>\n",
       "      <td>0.943062</td>\n",
       "      <td>7.581600</td>\n",
       "      <td>399.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.305723</td>\n",
       "      <td>0.945563</td>\n",
       "      <td>0.944885</td>\n",
       "      <td>0.944985</td>\n",
       "      <td>0.944787</td>\n",
       "      <td>7.582600</td>\n",
       "      <td>399.732000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+ORIG\n",
      "{'eval_loss': 0.28216299414634705, 'eval_accuracy': 0.9383815887156645, 'eval_f1': 0.9373408328474395, 'eval_precision': 0.9382654159668381, 'eval_recall': 0.9365290144689284, 'eval_runtime': 16.9324, 'eval_samples_per_second': 397.758, 'epoch': 7.5, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "remove_columns_ is deprecated and will be removed in the next major version of datasets. Use the dataset.remove_columns method instead.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72deb12f266b4358942856699c79cbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405682450fec4bc98de8bf243e7c2ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='28000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 28000/143957 2:35:42 < 10:44:52, 3.00 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.397224</td>\n",
       "      <td>0.833223</td>\n",
       "      <td>0.831385</td>\n",
       "      <td>0.831350</td>\n",
       "      <td>0.831420</td>\n",
       "      <td>78.821900</td>\n",
       "      <td>76.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.327296</td>\n",
       "      <td>0.856813</td>\n",
       "      <td>0.853541</td>\n",
       "      <td>0.860192</td>\n",
       "      <td>0.850494</td>\n",
       "      <td>78.866600</td>\n",
       "      <td>76.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.336336</td>\n",
       "      <td>0.860607</td>\n",
       "      <td>0.857529</td>\n",
       "      <td>0.863688</td>\n",
       "      <td>0.854593</td>\n",
       "      <td>78.886000</td>\n",
       "      <td>76.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>0.354546</td>\n",
       "      <td>0.866381</td>\n",
       "      <td>0.864359</td>\n",
       "      <td>0.866175</td>\n",
       "      <td>0.863074</td>\n",
       "      <td>78.870400</td>\n",
       "      <td>76.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>0.346059</td>\n",
       "      <td>0.862587</td>\n",
       "      <td>0.858510</td>\n",
       "      <td>0.870678</td>\n",
       "      <td>0.854180</td>\n",
       "      <td>78.892400</td>\n",
       "      <td>76.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.362666</td>\n",
       "      <td>0.855328</td>\n",
       "      <td>0.851567</td>\n",
       "      <td>0.860560</td>\n",
       "      <td>0.847961</td>\n",
       "      <td>78.913300</td>\n",
       "      <td>76.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.346570</td>\n",
       "      <td>0.861597</td>\n",
       "      <td>0.859049</td>\n",
       "      <td>0.862748</td>\n",
       "      <td>0.856924</td>\n",
       "      <td>78.974500</td>\n",
       "      <td>76.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>0.412682</td>\n",
       "      <td>0.866216</td>\n",
       "      <td>0.864153</td>\n",
       "      <td>0.866126</td>\n",
       "      <td>0.862784</td>\n",
       "      <td>79.056200</td>\n",
       "      <td>76.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>0.384190</td>\n",
       "      <td>0.851039</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.855011</td>\n",
       "      <td>0.844184</td>\n",
       "      <td>79.060000</td>\n",
       "      <td>76.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.470594</td>\n",
       "      <td>0.841142</td>\n",
       "      <td>0.833594</td>\n",
       "      <td>0.861561</td>\n",
       "      <td>0.827911</td>\n",
       "      <td>78.938900</td>\n",
       "      <td>76.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.343260</td>\n",
       "      <td>0.860607</td>\n",
       "      <td>0.857343</td>\n",
       "      <td>0.864475</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>79.016700</td>\n",
       "      <td>76.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>0.451207</td>\n",
       "      <td>0.841142</td>\n",
       "      <td>0.839729</td>\n",
       "      <td>0.839123</td>\n",
       "      <td>0.840546</td>\n",
       "      <td>79.024900</td>\n",
       "      <td>76.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.490988</td>\n",
       "      <td>0.814253</td>\n",
       "      <td>0.803819</td>\n",
       "      <td>0.838543</td>\n",
       "      <td>0.798851</td>\n",
       "      <td>78.983200</td>\n",
       "      <td>76.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.471874</td>\n",
       "      <td>0.828769</td>\n",
       "      <td>0.825947</td>\n",
       "      <td>0.828277</td>\n",
       "      <td>0.824484</td>\n",
       "      <td>78.994200</td>\n",
       "      <td>76.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+INV\n",
      "{'eval_loss': 0.25182414054870605, 'eval_accuracy': 0.9257609502598366, 'eval_f1': 0.9247647432059267, 'eval_precision': 0.9241842167590271, 'eval_recall': 0.9254199608634388, 'eval_runtime': 17.0465, 'eval_samples_per_second': 395.095, 'epoch': 1.94, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+INV'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abf266bb1fc49358ebb421e2b1eacf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3faeb7e8c84422951a8a059c1c3cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='134000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [134000/143957 9:12:08 < 41:01, 4.04 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.583600</td>\n",
       "      <td>0.509834</td>\n",
       "      <td>0.792949</td>\n",
       "      <td>39.577700</td>\n",
       "      <td>153.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.455351</td>\n",
       "      <td>0.818984</td>\n",
       "      <td>39.581000</td>\n",
       "      <td>153.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.491604</td>\n",
       "      <td>0.819063</td>\n",
       "      <td>39.558800</td>\n",
       "      <td>153.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.458140</td>\n",
       "      <td>0.786365</td>\n",
       "      <td>39.537700</td>\n",
       "      <td>153.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.491376</td>\n",
       "      <td>0.832549</td>\n",
       "      <td>39.574600</td>\n",
       "      <td>153.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.465200</td>\n",
       "      <td>0.443572</td>\n",
       "      <td>0.816951</td>\n",
       "      <td>39.564700</td>\n",
       "      <td>153.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.495706</td>\n",
       "      <td>0.832122</td>\n",
       "      <td>39.612500</td>\n",
       "      <td>153.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.469546</td>\n",
       "      <td>0.842631</td>\n",
       "      <td>39.609000</td>\n",
       "      <td>153.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.458105</td>\n",
       "      <td>0.849021</td>\n",
       "      <td>39.600000</td>\n",
       "      <td>153.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.481938</td>\n",
       "      <td>0.849602</td>\n",
       "      <td>39.553800</td>\n",
       "      <td>153.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.442094</td>\n",
       "      <td>0.850124</td>\n",
       "      <td>39.600100</td>\n",
       "      <td>153.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.447800</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.838708</td>\n",
       "      <td>39.581500</td>\n",
       "      <td>153.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.442700</td>\n",
       "      <td>0.444702</td>\n",
       "      <td>0.800111</td>\n",
       "      <td>39.582000</td>\n",
       "      <td>153.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.464782</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>39.565200</td>\n",
       "      <td>153.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.480671</td>\n",
       "      <td>0.809256</td>\n",
       "      <td>39.576500</td>\n",
       "      <td>153.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.491078</td>\n",
       "      <td>0.815063</td>\n",
       "      <td>39.609600</td>\n",
       "      <td>153.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.472052</td>\n",
       "      <td>0.845404</td>\n",
       "      <td>39.561600</td>\n",
       "      <td>153.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.418200</td>\n",
       "      <td>0.469938</td>\n",
       "      <td>0.858996</td>\n",
       "      <td>39.556200</td>\n",
       "      <td>153.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.417900</td>\n",
       "      <td>0.468231</td>\n",
       "      <td>0.850274</td>\n",
       "      <td>39.562000</td>\n",
       "      <td>153.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.443174</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>39.569200</td>\n",
       "      <td>153.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.463567</td>\n",
       "      <td>0.860308</td>\n",
       "      <td>39.535400</td>\n",
       "      <td>153.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.459527</td>\n",
       "      <td>0.859194</td>\n",
       "      <td>39.570300</td>\n",
       "      <td>153.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>0.490955</td>\n",
       "      <td>0.848367</td>\n",
       "      <td>39.555100</td>\n",
       "      <td>153.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.467476</td>\n",
       "      <td>0.862404</td>\n",
       "      <td>39.573700</td>\n",
       "      <td>153.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.476434</td>\n",
       "      <td>0.854558</td>\n",
       "      <td>39.579600</td>\n",
       "      <td>153.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.467553</td>\n",
       "      <td>0.858505</td>\n",
       "      <td>39.558200</td>\n",
       "      <td>153.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.461529</td>\n",
       "      <td>0.861998</td>\n",
       "      <td>39.532100</td>\n",
       "      <td>153.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.468951</td>\n",
       "      <td>0.865409</td>\n",
       "      <td>39.561500</td>\n",
       "      <td>153.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>0.464483</td>\n",
       "      <td>0.866003</td>\n",
       "      <td>39.594200</td>\n",
       "      <td>153.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.464699</td>\n",
       "      <td>0.866325</td>\n",
       "      <td>39.566400</td>\n",
       "      <td>153.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.491403</td>\n",
       "      <td>0.866648</td>\n",
       "      <td>39.552000</td>\n",
       "      <td>153.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.471144</td>\n",
       "      <td>0.867308</td>\n",
       "      <td>39.563100</td>\n",
       "      <td>153.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.457498</td>\n",
       "      <td>0.869059</td>\n",
       "      <td>39.570900</td>\n",
       "      <td>153.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.434295</td>\n",
       "      <td>0.875110</td>\n",
       "      <td>39.540800</td>\n",
       "      <td>153.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.438727</td>\n",
       "      <td>0.872235</td>\n",
       "      <td>39.564800</td>\n",
       "      <td>153.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.434459</td>\n",
       "      <td>0.871148</td>\n",
       "      <td>39.563500</td>\n",
       "      <td>153.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.471977</td>\n",
       "      <td>0.871965</td>\n",
       "      <td>39.568700</td>\n",
       "      <td>153.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.447771</td>\n",
       "      <td>0.875278</td>\n",
       "      <td>39.573600</td>\n",
       "      <td>153.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.454384</td>\n",
       "      <td>0.870684</td>\n",
       "      <td>39.541600</td>\n",
       "      <td>153.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.451178</td>\n",
       "      <td>0.869421</td>\n",
       "      <td>39.543900</td>\n",
       "      <td>153.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.451002</td>\n",
       "      <td>0.877542</td>\n",
       "      <td>39.551100</td>\n",
       "      <td>153.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.460720</td>\n",
       "      <td>0.875184</td>\n",
       "      <td>39.549800</td>\n",
       "      <td>153.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>0.458505</td>\n",
       "      <td>0.875607</td>\n",
       "      <td>39.580700</td>\n",
       "      <td>153.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.442042</td>\n",
       "      <td>0.874142</td>\n",
       "      <td>39.553100</td>\n",
       "      <td>153.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>0.874283</td>\n",
       "      <td>39.543300</td>\n",
       "      <td>153.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.455611</td>\n",
       "      <td>0.871515</td>\n",
       "      <td>39.524700</td>\n",
       "      <td>153.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.442379</td>\n",
       "      <td>0.875864</td>\n",
       "      <td>39.485600</td>\n",
       "      <td>153.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.336200</td>\n",
       "      <td>0.454454</td>\n",
       "      <td>0.875108</td>\n",
       "      <td>39.436200</td>\n",
       "      <td>153.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.454334</td>\n",
       "      <td>0.879589</td>\n",
       "      <td>39.489700</td>\n",
       "      <td>153.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>0.460071</td>\n",
       "      <td>0.876059</td>\n",
       "      <td>39.513900</td>\n",
       "      <td>153.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.448915</td>\n",
       "      <td>0.877366</td>\n",
       "      <td>39.513500</td>\n",
       "      <td>153.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.469186</td>\n",
       "      <td>0.876747</td>\n",
       "      <td>39.503900</td>\n",
       "      <td>153.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.451990</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>39.545400</td>\n",
       "      <td>153.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.469785</td>\n",
       "      <td>0.874910</td>\n",
       "      <td>39.558500</td>\n",
       "      <td>153.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.459007</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>39.543700</td>\n",
       "      <td>153.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.460698</td>\n",
       "      <td>0.879254</td>\n",
       "      <td>39.548300</td>\n",
       "      <td>153.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.333900</td>\n",
       "      <td>0.447637</td>\n",
       "      <td>0.880877</td>\n",
       "      <td>39.570200</td>\n",
       "      <td>153.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.470067</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>39.554100</td>\n",
       "      <td>153.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>0.469284</td>\n",
       "      <td>0.879921</td>\n",
       "      <td>39.584800</td>\n",
       "      <td>153.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.438893</td>\n",
       "      <td>0.879934</td>\n",
       "      <td>39.574900</td>\n",
       "      <td>153.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.446915</td>\n",
       "      <td>0.880708</td>\n",
       "      <td>39.557000</td>\n",
       "      <td>153.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.483408</td>\n",
       "      <td>0.877308</td>\n",
       "      <td>39.585000</td>\n",
       "      <td>153.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.464346</td>\n",
       "      <td>0.878293</td>\n",
       "      <td>39.604400</td>\n",
       "      <td>153.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.460194</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>39.571300</td>\n",
       "      <td>153.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.475679</td>\n",
       "      <td>0.876565</td>\n",
       "      <td>39.566300</td>\n",
       "      <td>153.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.473719</td>\n",
       "      <td>0.876806</td>\n",
       "      <td>39.580700</td>\n",
       "      <td>153.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.465394</td>\n",
       "      <td>0.878903</td>\n",
       "      <td>39.585800</td>\n",
       "      <td>153.136000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+SIB\n",
      "{'eval_loss': 3.5992980003356934, 'eval_accuracy': 0.9431328878990349, 'eval_f1': 0.9422386560646349, 'eval_precision': 0.9425967851442318, 'eval_recall': 0.94189968589079, 'eval_runtime': 17.0787, 'eval_samples_per_second': 394.35, 'epoch': 9.31, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+SIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6965e0266a43a88ca6a77547102b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9995165bffdb42aeb2780bb6d10d3c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='60000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 60000/143957 5:33:12 < 7:46:16, 3.00 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.567900</td>\n",
       "      <td>0.454410</td>\n",
       "      <td>0.810525</td>\n",
       "      <td>79.917800</td>\n",
       "      <td>75.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.434950</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>79.695100</td>\n",
       "      <td>76.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.408567</td>\n",
       "      <td>0.854189</td>\n",
       "      <td>79.667900</td>\n",
       "      <td>76.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.441900</td>\n",
       "      <td>0.425516</td>\n",
       "      <td>0.856829</td>\n",
       "      <td>79.649300</td>\n",
       "      <td>76.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.544261</td>\n",
       "      <td>0.835693</td>\n",
       "      <td>79.659100</td>\n",
       "      <td>76.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.405728</td>\n",
       "      <td>0.858344</td>\n",
       "      <td>79.638900</td>\n",
       "      <td>76.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>0.444437</td>\n",
       "      <td>0.852540</td>\n",
       "      <td>79.702200</td>\n",
       "      <td>76.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.431702</td>\n",
       "      <td>0.858422</td>\n",
       "      <td>79.707100</td>\n",
       "      <td>76.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.433078</td>\n",
       "      <td>0.857126</td>\n",
       "      <td>79.724100</td>\n",
       "      <td>76.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.417900</td>\n",
       "      <td>0.422203</td>\n",
       "      <td>0.865341</td>\n",
       "      <td>79.784800</td>\n",
       "      <td>75.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.450256</td>\n",
       "      <td>0.846028</td>\n",
       "      <td>79.748100</td>\n",
       "      <td>76.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>0.405944</td>\n",
       "      <td>0.870044</td>\n",
       "      <td>79.783400</td>\n",
       "      <td>75.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.403400</td>\n",
       "      <td>0.438661</td>\n",
       "      <td>0.868573</td>\n",
       "      <td>79.679100</td>\n",
       "      <td>76.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.423471</td>\n",
       "      <td>0.858684</td>\n",
       "      <td>79.734200</td>\n",
       "      <td>76.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.412159</td>\n",
       "      <td>0.871095</td>\n",
       "      <td>79.773800</td>\n",
       "      <td>75.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.424232</td>\n",
       "      <td>0.864771</td>\n",
       "      <td>79.766300</td>\n",
       "      <td>75.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.440522</td>\n",
       "      <td>0.866726</td>\n",
       "      <td>79.783500</td>\n",
       "      <td>75.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>0.446571</td>\n",
       "      <td>0.856264</td>\n",
       "      <td>79.807300</td>\n",
       "      <td>75.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.456925</td>\n",
       "      <td>0.828481</td>\n",
       "      <td>79.787000</td>\n",
       "      <td>75.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.409321</td>\n",
       "      <td>0.873334</td>\n",
       "      <td>79.771800</td>\n",
       "      <td>75.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.442882</td>\n",
       "      <td>0.848984</td>\n",
       "      <td>79.692600</td>\n",
       "      <td>76.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.458615</td>\n",
       "      <td>0.849652</td>\n",
       "      <td>79.737100</td>\n",
       "      <td>76.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>0.865628</td>\n",
       "      <td>79.747400</td>\n",
       "      <td>76.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.371900</td>\n",
       "      <td>0.421847</td>\n",
       "      <td>0.868823</td>\n",
       "      <td>79.821400</td>\n",
       "      <td>75.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.413434</td>\n",
       "      <td>0.869591</td>\n",
       "      <td>79.827300</td>\n",
       "      <td>75.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.422248</td>\n",
       "      <td>0.872269</td>\n",
       "      <td>79.595100</td>\n",
       "      <td>76.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.417495</td>\n",
       "      <td>0.861229</td>\n",
       "      <td>79.471400</td>\n",
       "      <td>76.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.418819</td>\n",
       "      <td>0.868645</td>\n",
       "      <td>79.443300</td>\n",
       "      <td>76.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.413969</td>\n",
       "      <td>0.869229</td>\n",
       "      <td>79.611800</td>\n",
       "      <td>76.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.413192</td>\n",
       "      <td>0.870510</td>\n",
       "      <td>79.664900</td>\n",
       "      <td>76.094000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+INVSIB\n",
      "{'eval_loss': 2.6374518871307373, 'eval_accuracy': 0.9334818114328136, 'eval_f1': 0.9325562170110473, 'eval_precision': 0.9321457550488259, 'eval_recall': 0.9330002083560067, 'eval_runtime': 16.9467, 'eval_samples_per_second': 397.422, 'epoch': 4.17, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+INVSIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4f14405b9d4735b31e0c090cf31da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43aa81c000447dcbfe21b4b8e680b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='143957' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [143957/143957 6:52:57, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.379431</td>\n",
       "      <td>0.848400</td>\n",
       "      <td>29.855000</td>\n",
       "      <td>203.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>0.330609</td>\n",
       "      <td>0.886176</td>\n",
       "      <td>29.849200</td>\n",
       "      <td>203.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.310528</td>\n",
       "      <td>0.901353</td>\n",
       "      <td>29.840200</td>\n",
       "      <td>203.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.316083</td>\n",
       "      <td>0.909271</td>\n",
       "      <td>29.845000</td>\n",
       "      <td>203.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>0.302671</td>\n",
       "      <td>0.885186</td>\n",
       "      <td>29.909100</td>\n",
       "      <td>202.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.333733</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>29.920200</td>\n",
       "      <td>202.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.336578</td>\n",
       "      <td>0.920323</td>\n",
       "      <td>29.884200</td>\n",
       "      <td>202.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.295400</td>\n",
       "      <td>0.312856</td>\n",
       "      <td>0.920158</td>\n",
       "      <td>29.904100</td>\n",
       "      <td>202.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.307231</td>\n",
       "      <td>0.914715</td>\n",
       "      <td>29.881700</td>\n",
       "      <td>202.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.292981</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>29.914200</td>\n",
       "      <td>202.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.277100</td>\n",
       "      <td>0.275444</td>\n",
       "      <td>0.923952</td>\n",
       "      <td>29.911800</td>\n",
       "      <td>202.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.291091</td>\n",
       "      <td>0.929726</td>\n",
       "      <td>29.912100</td>\n",
       "      <td>202.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>29.889100</td>\n",
       "      <td>202.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.272079</td>\n",
       "      <td>0.936490</td>\n",
       "      <td>29.869800</td>\n",
       "      <td>202.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>0.283122</td>\n",
       "      <td>0.939789</td>\n",
       "      <td>29.889100</td>\n",
       "      <td>202.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.289016</td>\n",
       "      <td>0.937644</td>\n",
       "      <td>29.863900</td>\n",
       "      <td>202.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>0.273984</td>\n",
       "      <td>0.934180</td>\n",
       "      <td>29.881200</td>\n",
       "      <td>202.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.305262</td>\n",
       "      <td>0.932860</td>\n",
       "      <td>29.881000</td>\n",
       "      <td>202.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.291597</td>\n",
       "      <td>0.934345</td>\n",
       "      <td>29.892000</td>\n",
       "      <td>202.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.267618</td>\n",
       "      <td>0.935005</td>\n",
       "      <td>29.922100</td>\n",
       "      <td>202.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.272364</td>\n",
       "      <td>0.948202</td>\n",
       "      <td>29.875500</td>\n",
       "      <td>202.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.272642</td>\n",
       "      <td>0.947047</td>\n",
       "      <td>29.915900</td>\n",
       "      <td>202.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.275257</td>\n",
       "      <td>0.946222</td>\n",
       "      <td>29.888300</td>\n",
       "      <td>202.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.276149</td>\n",
       "      <td>0.945068</td>\n",
       "      <td>29.888200</td>\n",
       "      <td>202.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.268818</td>\n",
       "      <td>0.943253</td>\n",
       "      <td>29.912800</td>\n",
       "      <td>202.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.267010</td>\n",
       "      <td>0.945398</td>\n",
       "      <td>29.875200</td>\n",
       "      <td>202.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.256639</td>\n",
       "      <td>0.947542</td>\n",
       "      <td>29.892700</td>\n",
       "      <td>202.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.258394</td>\n",
       "      <td>0.947872</td>\n",
       "      <td>29.863900</td>\n",
       "      <td>202.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.274024</td>\n",
       "      <td>0.949522</td>\n",
       "      <td>29.887800</td>\n",
       "      <td>202.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0.948697</td>\n",
       "      <td>29.913600</td>\n",
       "      <td>202.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.272162</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>29.948900</td>\n",
       "      <td>202.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.267040</td>\n",
       "      <td>0.953481</td>\n",
       "      <td>29.904700</td>\n",
       "      <td>202.711000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.247956</td>\n",
       "      <td>0.952161</td>\n",
       "      <td>29.890000</td>\n",
       "      <td>202.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.249971</td>\n",
       "      <td>0.954470</td>\n",
       "      <td>29.887900</td>\n",
       "      <td>202.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.208700</td>\n",
       "      <td>0.237194</td>\n",
       "      <td>0.954306</td>\n",
       "      <td>29.915500</td>\n",
       "      <td>202.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>0.261013</td>\n",
       "      <td>0.952656</td>\n",
       "      <td>29.873500</td>\n",
       "      <td>202.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.958430</td>\n",
       "      <td>29.822900</td>\n",
       "      <td>203.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.256312</td>\n",
       "      <td>0.957440</td>\n",
       "      <td>29.857400</td>\n",
       "      <td>203.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.266779</td>\n",
       "      <td>0.954306</td>\n",
       "      <td>29.822200</td>\n",
       "      <td>203.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.242290</td>\n",
       "      <td>0.956450</td>\n",
       "      <td>29.829100</td>\n",
       "      <td>203.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.250481</td>\n",
       "      <td>0.955460</td>\n",
       "      <td>29.809500</td>\n",
       "      <td>203.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.257014</td>\n",
       "      <td>0.959914</td>\n",
       "      <td>29.852500</td>\n",
       "      <td>203.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.251583</td>\n",
       "      <td>0.960079</td>\n",
       "      <td>29.856400</td>\n",
       "      <td>203.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.262007</td>\n",
       "      <td>0.958595</td>\n",
       "      <td>29.882400</td>\n",
       "      <td>202.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.256635</td>\n",
       "      <td>0.958100</td>\n",
       "      <td>29.888200</td>\n",
       "      <td>202.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.254053</td>\n",
       "      <td>0.958924</td>\n",
       "      <td>29.873400</td>\n",
       "      <td>202.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.962059</td>\n",
       "      <td>29.878300</td>\n",
       "      <td>202.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.257068</td>\n",
       "      <td>0.963213</td>\n",
       "      <td>29.883800</td>\n",
       "      <td>202.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.256165</td>\n",
       "      <td>0.962389</td>\n",
       "      <td>29.874200</td>\n",
       "      <td>202.918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.251662</td>\n",
       "      <td>0.965193</td>\n",
       "      <td>29.893700</td>\n",
       "      <td>202.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.171100</td>\n",
       "      <td>0.236832</td>\n",
       "      <td>0.964533</td>\n",
       "      <td>29.883600</td>\n",
       "      <td>202.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.256313</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>29.869500</td>\n",
       "      <td>202.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.250756</td>\n",
       "      <td>0.962884</td>\n",
       "      <td>29.849500</td>\n",
       "      <td>203.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.257745</td>\n",
       "      <td>0.965523</td>\n",
       "      <td>29.865600</td>\n",
       "      <td>202.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.261005</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>29.891600</td>\n",
       "      <td>202.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.251713</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>29.947200</td>\n",
       "      <td>202.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.240426</td>\n",
       "      <td>0.967997</td>\n",
       "      <td>29.927800</td>\n",
       "      <td>202.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.260289</td>\n",
       "      <td>0.967832</td>\n",
       "      <td>29.899100</td>\n",
       "      <td>202.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.246089</td>\n",
       "      <td>0.968327</td>\n",
       "      <td>29.941800</td>\n",
       "      <td>202.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.251081</td>\n",
       "      <td>0.966348</td>\n",
       "      <td>29.911800</td>\n",
       "      <td>202.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.245530</td>\n",
       "      <td>0.968822</td>\n",
       "      <td>29.889500</td>\n",
       "      <td>202.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250217</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>29.892300</td>\n",
       "      <td>202.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.155300</td>\n",
       "      <td>0.253991</td>\n",
       "      <td>0.967502</td>\n",
       "      <td>29.948500</td>\n",
       "      <td>202.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>0.258278</td>\n",
       "      <td>0.968327</td>\n",
       "      <td>29.858000</td>\n",
       "      <td>203.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.262606</td>\n",
       "      <td>0.967997</td>\n",
       "      <td>29.887000</td>\n",
       "      <td>202.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.258946</td>\n",
       "      <td>0.967502</td>\n",
       "      <td>29.909400</td>\n",
       "      <td>202.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.259015</td>\n",
       "      <td>0.968822</td>\n",
       "      <td>29.906300</td>\n",
       "      <td>202.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.253864</td>\n",
       "      <td>0.969152</td>\n",
       "      <td>29.925800</td>\n",
       "      <td>202.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.258761</td>\n",
       "      <td>0.967997</td>\n",
       "      <td>29.923400</td>\n",
       "      <td>202.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.256396</td>\n",
       "      <td>0.969152</td>\n",
       "      <td>29.911500</td>\n",
       "      <td>202.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.257095</td>\n",
       "      <td>0.968822</td>\n",
       "      <td>29.905700</td>\n",
       "      <td>202.704000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+TextMix\n",
      "{'eval_loss': 5.39630651473999, 'eval_accuracy': 0.9478841870824053, 'eval_f1': 0.9471608629562017, 'eval_precision': 0.9467223042155277, 'eval_recall': 0.9476359648243509, 'eval_runtime': 16.984, 'eval_samples_per_second': 396.55, 'epoch': 10.0, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+TextMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c58adee0b247498717ed41df1bb082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d037ee16674845bc88188ef0d6f5cd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='215936' max='215936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215936/215936 10:46:57, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.343714</td>\n",
       "      <td>0.717633</td>\n",
       "      <td>45.706100</td>\n",
       "      <td>198.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.309481</td>\n",
       "      <td>0.748030</td>\n",
       "      <td>45.657300</td>\n",
       "      <td>199.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.278553</td>\n",
       "      <td>0.774221</td>\n",
       "      <td>45.635500</td>\n",
       "      <td>199.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.254339</td>\n",
       "      <td>0.782258</td>\n",
       "      <td>45.599600</td>\n",
       "      <td>199.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.270143</td>\n",
       "      <td>0.782673</td>\n",
       "      <td>45.600100</td>\n",
       "      <td>199.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.263715</td>\n",
       "      <td>0.784243</td>\n",
       "      <td>45.604400</td>\n",
       "      <td>199.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.250669</td>\n",
       "      <td>0.778033</td>\n",
       "      <td>45.663300</td>\n",
       "      <td>199.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.273200</td>\n",
       "      <td>0.251409</td>\n",
       "      <td>0.784808</td>\n",
       "      <td>45.624400</td>\n",
       "      <td>199.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.267568</td>\n",
       "      <td>0.784437</td>\n",
       "      <td>45.647300</td>\n",
       "      <td>199.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.255650</td>\n",
       "      <td>0.791285</td>\n",
       "      <td>45.663000</td>\n",
       "      <td>199.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.237379</td>\n",
       "      <td>0.798711</td>\n",
       "      <td>45.664300</td>\n",
       "      <td>199.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.261574</td>\n",
       "      <td>0.782576</td>\n",
       "      <td>45.725800</td>\n",
       "      <td>198.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.247272</td>\n",
       "      <td>0.791523</td>\n",
       "      <td>45.755300</td>\n",
       "      <td>198.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.245711</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>45.763900</td>\n",
       "      <td>198.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.246967</td>\n",
       "      <td>0.800413</td>\n",
       "      <td>45.714100</td>\n",
       "      <td>198.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.223250</td>\n",
       "      <td>0.799006</td>\n",
       "      <td>45.739300</td>\n",
       "      <td>198.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.787618</td>\n",
       "      <td>45.753600</td>\n",
       "      <td>198.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.243812</td>\n",
       "      <td>0.797750</td>\n",
       "      <td>45.764400</td>\n",
       "      <td>198.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.237469</td>\n",
       "      <td>0.795265</td>\n",
       "      <td>45.770800</td>\n",
       "      <td>198.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.231082</td>\n",
       "      <td>0.801214</td>\n",
       "      <td>45.754900</td>\n",
       "      <td>198.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.247257</td>\n",
       "      <td>0.794958</td>\n",
       "      <td>45.759700</td>\n",
       "      <td>198.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.249303</td>\n",
       "      <td>0.801560</td>\n",
       "      <td>45.753000</td>\n",
       "      <td>198.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242207</td>\n",
       "      <td>0.800418</td>\n",
       "      <td>45.750600</td>\n",
       "      <td>198.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.231414</td>\n",
       "      <td>0.797557</td>\n",
       "      <td>45.733100</td>\n",
       "      <td>198.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>0.797486</td>\n",
       "      <td>45.735300</td>\n",
       "      <td>198.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.227577</td>\n",
       "      <td>0.807587</td>\n",
       "      <td>45.744900</td>\n",
       "      <td>198.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.229682</td>\n",
       "      <td>0.805105</td>\n",
       "      <td>45.757100</td>\n",
       "      <td>198.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.224215</td>\n",
       "      <td>0.808005</td>\n",
       "      <td>45.756000</td>\n",
       "      <td>198.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.235661</td>\n",
       "      <td>0.804563</td>\n",
       "      <td>45.762600</td>\n",
       "      <td>198.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0.223769</td>\n",
       "      <td>0.806852</td>\n",
       "      <td>45.743200</td>\n",
       "      <td>198.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.210900</td>\n",
       "      <td>0.259529</td>\n",
       "      <td>0.803190</td>\n",
       "      <td>45.741300</td>\n",
       "      <td>198.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.231024</td>\n",
       "      <td>0.803282</td>\n",
       "      <td>45.697700</td>\n",
       "      <td>198.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.222143</td>\n",
       "      <td>0.807381</td>\n",
       "      <td>45.695800</td>\n",
       "      <td>198.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.230257</td>\n",
       "      <td>0.808375</td>\n",
       "      <td>45.678700</td>\n",
       "      <td>199.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.221613</td>\n",
       "      <td>0.809412</td>\n",
       "      <td>45.690500</td>\n",
       "      <td>199.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.228727</td>\n",
       "      <td>0.805835</td>\n",
       "      <td>45.674900</td>\n",
       "      <td>199.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.224266</td>\n",
       "      <td>0.806862</td>\n",
       "      <td>45.687400</td>\n",
       "      <td>199.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.217162</td>\n",
       "      <td>0.809734</td>\n",
       "      <td>45.703700</td>\n",
       "      <td>198.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.236524</td>\n",
       "      <td>0.807007</td>\n",
       "      <td>45.698700</td>\n",
       "      <td>198.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.217102</td>\n",
       "      <td>0.812674</td>\n",
       "      <td>45.714400</td>\n",
       "      <td>198.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.221722</td>\n",
       "      <td>0.808632</td>\n",
       "      <td>45.719000</td>\n",
       "      <td>198.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.195800</td>\n",
       "      <td>0.210735</td>\n",
       "      <td>0.812657</td>\n",
       "      <td>45.731600</td>\n",
       "      <td>198.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.220803</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>45.741800</td>\n",
       "      <td>198.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.211788</td>\n",
       "      <td>0.815159</td>\n",
       "      <td>45.728900</td>\n",
       "      <td>198.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.216492</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>45.736700</td>\n",
       "      <td>198.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.221585</td>\n",
       "      <td>0.811818</td>\n",
       "      <td>45.740900</td>\n",
       "      <td>198.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.219433</td>\n",
       "      <td>0.814675</td>\n",
       "      <td>45.745300</td>\n",
       "      <td>198.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.213266</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>45.735500</td>\n",
       "      <td>198.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.211660</td>\n",
       "      <td>0.815314</td>\n",
       "      <td>45.740000</td>\n",
       "      <td>198.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.214648</td>\n",
       "      <td>0.816426</td>\n",
       "      <td>45.742800</td>\n",
       "      <td>198.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.213421</td>\n",
       "      <td>0.816077</td>\n",
       "      <td>45.745500</td>\n",
       "      <td>198.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.209305</td>\n",
       "      <td>0.814905</td>\n",
       "      <td>45.697000</td>\n",
       "      <td>198.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.212341</td>\n",
       "      <td>0.816376</td>\n",
       "      <td>45.729000</td>\n",
       "      <td>198.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.211288</td>\n",
       "      <td>0.816397</td>\n",
       "      <td>45.705500</td>\n",
       "      <td>198.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.212541</td>\n",
       "      <td>0.812633</td>\n",
       "      <td>45.720800</td>\n",
       "      <td>198.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.208538</td>\n",
       "      <td>0.817846</td>\n",
       "      <td>45.724800</td>\n",
       "      <td>198.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.211055</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>45.716700</td>\n",
       "      <td>198.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.207506</td>\n",
       "      <td>0.819549</td>\n",
       "      <td>45.745400</td>\n",
       "      <td>198.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.201771</td>\n",
       "      <td>0.818031</td>\n",
       "      <td>45.745400</td>\n",
       "      <td>198.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.211912</td>\n",
       "      <td>0.811532</td>\n",
       "      <td>45.733500</td>\n",
       "      <td>198.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>0.213626</td>\n",
       "      <td>0.815490</td>\n",
       "      <td>45.742100</td>\n",
       "      <td>198.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.199005</td>\n",
       "      <td>0.817671</td>\n",
       "      <td>45.739200</td>\n",
       "      <td>198.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.197427</td>\n",
       "      <td>0.818032</td>\n",
       "      <td>45.747600</td>\n",
       "      <td>198.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.202227</td>\n",
       "      <td>0.817883</td>\n",
       "      <td>45.743900</td>\n",
       "      <td>198.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.202966</td>\n",
       "      <td>0.819371</td>\n",
       "      <td>45.733500</td>\n",
       "      <td>198.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.204995</td>\n",
       "      <td>0.819484</td>\n",
       "      <td>45.740800</td>\n",
       "      <td>198.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.209521</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>45.745000</td>\n",
       "      <td>198.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>45.750200</td>\n",
       "      <td>198.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.208525</td>\n",
       "      <td>0.821509</td>\n",
       "      <td>45.724600</td>\n",
       "      <td>198.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.160900</td>\n",
       "      <td>0.205323</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>45.738500</td>\n",
       "      <td>198.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.201648</td>\n",
       "      <td>0.821654</td>\n",
       "      <td>45.725700</td>\n",
       "      <td>198.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144000</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.195503</td>\n",
       "      <td>0.823363</td>\n",
       "      <td>45.735200</td>\n",
       "      <td>198.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146000</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.823171</td>\n",
       "      <td>45.735700</td>\n",
       "      <td>198.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148000</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.194592</td>\n",
       "      <td>0.822088</td>\n",
       "      <td>45.724300</td>\n",
       "      <td>198.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.194268</td>\n",
       "      <td>0.822978</td>\n",
       "      <td>45.707600</td>\n",
       "      <td>198.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152000</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.199307</td>\n",
       "      <td>0.823779</td>\n",
       "      <td>45.704400</td>\n",
       "      <td>198.953000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.200197</td>\n",
       "      <td>0.823497</td>\n",
       "      <td>45.712600</td>\n",
       "      <td>198.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156000</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.198316</td>\n",
       "      <td>0.823126</td>\n",
       "      <td>45.718400</td>\n",
       "      <td>198.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>0.822975</td>\n",
       "      <td>45.729600</td>\n",
       "      <td>198.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.192691</td>\n",
       "      <td>0.824211</td>\n",
       "      <td>45.726400</td>\n",
       "      <td>198.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162000</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.193605</td>\n",
       "      <td>0.825398</td>\n",
       "      <td>45.732100</td>\n",
       "      <td>198.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164000</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.191280</td>\n",
       "      <td>0.825958</td>\n",
       "      <td>45.712700</td>\n",
       "      <td>198.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166000</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.192426</td>\n",
       "      <td>0.825743</td>\n",
       "      <td>45.710000</td>\n",
       "      <td>198.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168000</td>\n",
       "      <td>0.152400</td>\n",
       "      <td>0.193025</td>\n",
       "      <td>0.824740</td>\n",
       "      <td>45.723700</td>\n",
       "      <td>198.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.199541</td>\n",
       "      <td>0.825310</td>\n",
       "      <td>45.686300</td>\n",
       "      <td>199.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172000</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.197316</td>\n",
       "      <td>0.825328</td>\n",
       "      <td>45.720400</td>\n",
       "      <td>198.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174000</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.196367</td>\n",
       "      <td>0.826591</td>\n",
       "      <td>45.692300</td>\n",
       "      <td>199.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176000</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.196966</td>\n",
       "      <td>0.824670</td>\n",
       "      <td>45.702400</td>\n",
       "      <td>198.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178000</td>\n",
       "      <td>0.149700</td>\n",
       "      <td>0.192733</td>\n",
       "      <td>0.825884</td>\n",
       "      <td>45.703600</td>\n",
       "      <td>198.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.825565</td>\n",
       "      <td>45.696000</td>\n",
       "      <td>198.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182000</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.193218</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>45.707500</td>\n",
       "      <td>198.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184000</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>0.825775</td>\n",
       "      <td>45.727500</td>\n",
       "      <td>198.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186000</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.193203</td>\n",
       "      <td>0.826129</td>\n",
       "      <td>45.700500</td>\n",
       "      <td>198.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188000</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.189085</td>\n",
       "      <td>0.826429</td>\n",
       "      <td>45.699800</td>\n",
       "      <td>198.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.186933</td>\n",
       "      <td>0.825844</td>\n",
       "      <td>45.695700</td>\n",
       "      <td>198.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192000</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.187980</td>\n",
       "      <td>0.827123</td>\n",
       "      <td>45.691000</td>\n",
       "      <td>199.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194000</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.188232</td>\n",
       "      <td>0.826958</td>\n",
       "      <td>45.702000</td>\n",
       "      <td>198.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196000</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.189156</td>\n",
       "      <td>0.827538</td>\n",
       "      <td>45.678700</td>\n",
       "      <td>199.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198000</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>0.189843</td>\n",
       "      <td>0.827193</td>\n",
       "      <td>45.685900</td>\n",
       "      <td>199.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.186115</td>\n",
       "      <td>0.827958</td>\n",
       "      <td>45.708600</td>\n",
       "      <td>198.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202000</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.188991</td>\n",
       "      <td>0.827373</td>\n",
       "      <td>45.685400</td>\n",
       "      <td>199.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204000</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.190302</td>\n",
       "      <td>0.827381</td>\n",
       "      <td>45.674300</td>\n",
       "      <td>199.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206000</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.190730</td>\n",
       "      <td>0.827211</td>\n",
       "      <td>45.701600</td>\n",
       "      <td>198.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208000</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.187868</td>\n",
       "      <td>0.826846</td>\n",
       "      <td>45.686700</td>\n",
       "      <td>199.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.189141</td>\n",
       "      <td>0.827511</td>\n",
       "      <td>45.694800</td>\n",
       "      <td>198.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212000</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.188869</td>\n",
       "      <td>0.827669</td>\n",
       "      <td>45.689600</td>\n",
       "      <td>199.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214000</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.189297</td>\n",
       "      <td>0.827468</td>\n",
       "      <td>45.693800</td>\n",
       "      <td>198.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+SentMix\n",
      "{'eval_loss': 5.498501300811768, 'eval_accuracy': 0.9499628804751299, 'eval_f1': 0.9492755360871598, 'eval_precision': 0.9487796560710117, 'eval_recall': 0.9498188251442023, 'eval_runtime': 16.9856, 'eval_samples_per_second': 396.512, 'epoch': 10.0, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+SentMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841614c1d3bb4207b75d42b0f4fc6ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c7b065b5244247be1a7b45c744f141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-58c5c95f3f3c7bcb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='220000' max='287916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220000/287916 12:18:37 < 3:48:01, 4.96 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.431100</td>\n",
       "      <td>0.308022</td>\n",
       "      <td>0.583661</td>\n",
       "      <td>54.305400</td>\n",
       "      <td>223.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.281898</td>\n",
       "      <td>0.604936</td>\n",
       "      <td>54.310000</td>\n",
       "      <td>223.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.253030</td>\n",
       "      <td>0.625251</td>\n",
       "      <td>54.357900</td>\n",
       "      <td>223.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>0.625218</td>\n",
       "      <td>54.314700</td>\n",
       "      <td>223.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.241769</td>\n",
       "      <td>0.637543</td>\n",
       "      <td>54.329700</td>\n",
       "      <td>223.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.250115</td>\n",
       "      <td>0.641227</td>\n",
       "      <td>54.314400</td>\n",
       "      <td>223.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.225766</td>\n",
       "      <td>0.648061</td>\n",
       "      <td>54.306200</td>\n",
       "      <td>223.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.236058</td>\n",
       "      <td>0.645486</td>\n",
       "      <td>54.317900</td>\n",
       "      <td>223.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.236771</td>\n",
       "      <td>0.650597</td>\n",
       "      <td>54.313300</td>\n",
       "      <td>223.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.218487</td>\n",
       "      <td>0.650493</td>\n",
       "      <td>54.322400</td>\n",
       "      <td>223.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.225931</td>\n",
       "      <td>0.654224</td>\n",
       "      <td>54.329300</td>\n",
       "      <td>223.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.225332</td>\n",
       "      <td>0.652436</td>\n",
       "      <td>54.338400</td>\n",
       "      <td>223.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.228341</td>\n",
       "      <td>0.649738</td>\n",
       "      <td>54.358300</td>\n",
       "      <td>223.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.214786</td>\n",
       "      <td>0.654346</td>\n",
       "      <td>54.348800</td>\n",
       "      <td>223.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.212850</td>\n",
       "      <td>0.653703</td>\n",
       "      <td>54.358200</td>\n",
       "      <td>223.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.222169</td>\n",
       "      <td>0.660819</td>\n",
       "      <td>54.346300</td>\n",
       "      <td>223.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.219938</td>\n",
       "      <td>0.653914</td>\n",
       "      <td>54.346100</td>\n",
       "      <td>223.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.218602</td>\n",
       "      <td>0.662381</td>\n",
       "      <td>54.324100</td>\n",
       "      <td>223.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.209579</td>\n",
       "      <td>0.662739</td>\n",
       "      <td>54.329000</td>\n",
       "      <td>223.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.214778</td>\n",
       "      <td>0.662557</td>\n",
       "      <td>54.332600</td>\n",
       "      <td>223.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.210900</td>\n",
       "      <td>0.215896</td>\n",
       "      <td>0.652241</td>\n",
       "      <td>54.318000</td>\n",
       "      <td>223.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.206300</td>\n",
       "      <td>0.236147</td>\n",
       "      <td>0.656887</td>\n",
       "      <td>54.313200</td>\n",
       "      <td>223.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.214706</td>\n",
       "      <td>0.660731</td>\n",
       "      <td>54.340000</td>\n",
       "      <td>223.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.211449</td>\n",
       "      <td>0.663355</td>\n",
       "      <td>54.296000</td>\n",
       "      <td>223.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.211609</td>\n",
       "      <td>0.663426</td>\n",
       "      <td>54.300600</td>\n",
       "      <td>223.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.202887</td>\n",
       "      <td>0.665840</td>\n",
       "      <td>54.299500</td>\n",
       "      <td>223.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>0.664331</td>\n",
       "      <td>54.324000</td>\n",
       "      <td>223.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>0.201061</td>\n",
       "      <td>0.665486</td>\n",
       "      <td>54.358700</td>\n",
       "      <td>223.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.201312</td>\n",
       "      <td>0.662507</td>\n",
       "      <td>54.370100</td>\n",
       "      <td>222.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.197045</td>\n",
       "      <td>0.665996</td>\n",
       "      <td>54.357500</td>\n",
       "      <td>223.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.205810</td>\n",
       "      <td>0.663846</td>\n",
       "      <td>54.317200</td>\n",
       "      <td>223.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.666092</td>\n",
       "      <td>54.363700</td>\n",
       "      <td>222.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.202658</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>54.320000</td>\n",
       "      <td>223.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.211283</td>\n",
       "      <td>0.654757</td>\n",
       "      <td>54.330100</td>\n",
       "      <td>223.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.202366</td>\n",
       "      <td>0.667254</td>\n",
       "      <td>54.311200</td>\n",
       "      <td>223.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.202493</td>\n",
       "      <td>0.664825</td>\n",
       "      <td>54.324100</td>\n",
       "      <td>223.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.204846</td>\n",
       "      <td>0.665274</td>\n",
       "      <td>54.292700</td>\n",
       "      <td>223.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.201946</td>\n",
       "      <td>0.661842</td>\n",
       "      <td>54.322900</td>\n",
       "      <td>223.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.211864</td>\n",
       "      <td>0.665350</td>\n",
       "      <td>54.315100</td>\n",
       "      <td>223.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.201270</td>\n",
       "      <td>0.659552</td>\n",
       "      <td>54.280700</td>\n",
       "      <td>223.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.210051</td>\n",
       "      <td>0.663035</td>\n",
       "      <td>54.229000</td>\n",
       "      <td>223.552000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.192565</td>\n",
       "      <td>0.668294</td>\n",
       "      <td>54.224300</td>\n",
       "      <td>223.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.187992</td>\n",
       "      <td>0.669486</td>\n",
       "      <td>54.147200</td>\n",
       "      <td>223.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.197193</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>54.182400</td>\n",
       "      <td>223.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.197848</td>\n",
       "      <td>0.672105</td>\n",
       "      <td>54.162600</td>\n",
       "      <td>223.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.200480</td>\n",
       "      <td>0.672439</td>\n",
       "      <td>54.212200</td>\n",
       "      <td>223.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.192655</td>\n",
       "      <td>0.670972</td>\n",
       "      <td>54.255800</td>\n",
       "      <td>223.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.196122</td>\n",
       "      <td>0.670407</td>\n",
       "      <td>54.252100</td>\n",
       "      <td>223.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.197999</td>\n",
       "      <td>0.671847</td>\n",
       "      <td>54.286700</td>\n",
       "      <td>223.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.199578</td>\n",
       "      <td>0.671895</td>\n",
       "      <td>54.271200</td>\n",
       "      <td>223.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.199666</td>\n",
       "      <td>0.673138</td>\n",
       "      <td>54.258800</td>\n",
       "      <td>223.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.197730</td>\n",
       "      <td>0.672776</td>\n",
       "      <td>54.250300</td>\n",
       "      <td>223.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.189953</td>\n",
       "      <td>0.674304</td>\n",
       "      <td>54.262600</td>\n",
       "      <td>223.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.189367</td>\n",
       "      <td>0.671246</td>\n",
       "      <td>54.222800</td>\n",
       "      <td>223.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.199829</td>\n",
       "      <td>0.670676</td>\n",
       "      <td>54.259900</td>\n",
       "      <td>223.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.193910</td>\n",
       "      <td>0.671238</td>\n",
       "      <td>54.229600</td>\n",
       "      <td>223.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.189310</td>\n",
       "      <td>0.672590</td>\n",
       "      <td>54.261800</td>\n",
       "      <td>223.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.188381</td>\n",
       "      <td>0.673740</td>\n",
       "      <td>54.236400</td>\n",
       "      <td>223.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>54.258200</td>\n",
       "      <td>223.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.176769</td>\n",
       "      <td>0.675186</td>\n",
       "      <td>54.241200</td>\n",
       "      <td>223.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.196337</td>\n",
       "      <td>0.673496</td>\n",
       "      <td>54.243100</td>\n",
       "      <td>223.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.186877</td>\n",
       "      <td>0.676133</td>\n",
       "      <td>54.252000</td>\n",
       "      <td>223.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>0.194889</td>\n",
       "      <td>0.674110</td>\n",
       "      <td>54.264100</td>\n",
       "      <td>223.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.197038</td>\n",
       "      <td>0.674505</td>\n",
       "      <td>54.245400</td>\n",
       "      <td>223.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>0.194150</td>\n",
       "      <td>0.674721</td>\n",
       "      <td>54.205600</td>\n",
       "      <td>223.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.182895</td>\n",
       "      <td>0.677723</td>\n",
       "      <td>54.223300</td>\n",
       "      <td>223.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>0.678059</td>\n",
       "      <td>54.158700</td>\n",
       "      <td>223.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.183034</td>\n",
       "      <td>0.677922</td>\n",
       "      <td>54.156000</td>\n",
       "      <td>223.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.188918</td>\n",
       "      <td>0.677144</td>\n",
       "      <td>54.113200</td>\n",
       "      <td>224.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.176618</td>\n",
       "      <td>0.679701</td>\n",
       "      <td>54.184400</td>\n",
       "      <td>223.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.180731</td>\n",
       "      <td>0.678385</td>\n",
       "      <td>54.225600</td>\n",
       "      <td>223.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144000</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.188054</td>\n",
       "      <td>0.678052</td>\n",
       "      <td>54.202900</td>\n",
       "      <td>223.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146000</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0.679870</td>\n",
       "      <td>54.194300</td>\n",
       "      <td>223.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148000</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.190798</td>\n",
       "      <td>0.677512</td>\n",
       "      <td>54.192000</td>\n",
       "      <td>223.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.184085</td>\n",
       "      <td>0.678852</td>\n",
       "      <td>54.200600</td>\n",
       "      <td>223.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152000</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.186716</td>\n",
       "      <td>0.677274</td>\n",
       "      <td>54.205200</td>\n",
       "      <td>223.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.182069</td>\n",
       "      <td>0.678658</td>\n",
       "      <td>54.203000</td>\n",
       "      <td>223.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156000</td>\n",
       "      <td>0.150600</td>\n",
       "      <td>0.178839</td>\n",
       "      <td>0.678303</td>\n",
       "      <td>54.194000</td>\n",
       "      <td>223.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158000</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.181586</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>54.224200</td>\n",
       "      <td>223.572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>0.186258</td>\n",
       "      <td>0.678622</td>\n",
       "      <td>54.206800</td>\n",
       "      <td>223.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162000</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.175256</td>\n",
       "      <td>0.680420</td>\n",
       "      <td>54.265900</td>\n",
       "      <td>223.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164000</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.185132</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>54.235600</td>\n",
       "      <td>223.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166000</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.174459</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>54.248500</td>\n",
       "      <td>223.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168000</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.173455</td>\n",
       "      <td>0.681391</td>\n",
       "      <td>54.255500</td>\n",
       "      <td>223.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.177340</td>\n",
       "      <td>0.678410</td>\n",
       "      <td>54.256000</td>\n",
       "      <td>223.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172000</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.178134</td>\n",
       "      <td>0.679127</td>\n",
       "      <td>54.260400</td>\n",
       "      <td>223.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174000</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.187043</td>\n",
       "      <td>0.680056</td>\n",
       "      <td>54.226600</td>\n",
       "      <td>223.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176000</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.184368</td>\n",
       "      <td>0.681783</td>\n",
       "      <td>54.201900</td>\n",
       "      <td>223.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.176234</td>\n",
       "      <td>0.682793</td>\n",
       "      <td>54.208900</td>\n",
       "      <td>223.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.180846</td>\n",
       "      <td>0.682334</td>\n",
       "      <td>54.150600</td>\n",
       "      <td>223.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182000</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.177708</td>\n",
       "      <td>0.681519</td>\n",
       "      <td>54.163000</td>\n",
       "      <td>223.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184000</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.173515</td>\n",
       "      <td>0.684011</td>\n",
       "      <td>54.185100</td>\n",
       "      <td>223.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186000</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.178694</td>\n",
       "      <td>0.682278</td>\n",
       "      <td>54.226200</td>\n",
       "      <td>223.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188000</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>0.178874</td>\n",
       "      <td>0.682768</td>\n",
       "      <td>54.209900</td>\n",
       "      <td>223.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.171398</td>\n",
       "      <td>0.681387</td>\n",
       "      <td>54.218200</td>\n",
       "      <td>223.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192000</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.183399</td>\n",
       "      <td>0.682308</td>\n",
       "      <td>54.203500</td>\n",
       "      <td>223.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194000</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>0.179293</td>\n",
       "      <td>0.683049</td>\n",
       "      <td>54.204800</td>\n",
       "      <td>223.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196000</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.178415</td>\n",
       "      <td>0.682191</td>\n",
       "      <td>54.211100</td>\n",
       "      <td>223.626000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198000</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.177378</td>\n",
       "      <td>0.682967</td>\n",
       "      <td>54.256700</td>\n",
       "      <td>223.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.177737</td>\n",
       "      <td>0.684531</td>\n",
       "      <td>54.219700</td>\n",
       "      <td>223.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202000</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.179194</td>\n",
       "      <td>0.684319</td>\n",
       "      <td>54.234800</td>\n",
       "      <td>223.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204000</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.178908</td>\n",
       "      <td>0.682598</td>\n",
       "      <td>54.263400</td>\n",
       "      <td>223.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206000</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.178634</td>\n",
       "      <td>0.683268</td>\n",
       "      <td>54.280200</td>\n",
       "      <td>223.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208000</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.175960</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>54.235800</td>\n",
       "      <td>223.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.175426</td>\n",
       "      <td>0.684153</td>\n",
       "      <td>54.213300</td>\n",
       "      <td>223.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212000</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.174201</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>54.218000</td>\n",
       "      <td>223.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214000</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.180179</td>\n",
       "      <td>0.683155</td>\n",
       "      <td>54.213300</td>\n",
       "      <td>223.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216000</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.172011</td>\n",
       "      <td>0.683890</td>\n",
       "      <td>54.177100</td>\n",
       "      <td>223.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218000</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.174284</td>\n",
       "      <td>0.683117</td>\n",
       "      <td>54.212800</td>\n",
       "      <td>223.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.177006</td>\n",
       "      <td>0.683142</td>\n",
       "      <td>54.219500</td>\n",
       "      <td>223.591000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-sst2-ORIG+WordMix\n",
      "{'eval_loss': 4.707504749298096, 'eval_accuracy': 0.9452115812917594, 'eval_f1': 0.9444115030632203, 'eval_precision': 0.9442686863576941, 'eval_recall': 0.9445578359758507, 'eval_runtime': 16.9568, 'eval_samples_per_second': 397.186, 'epoch': 7.64, 'run': 'pretrained/bert-base-uncased-sst2-ORIG+WordMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faea961010fc4a2c8d2259e174ab1707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2626f9c6780c4e9c80b504aec8fff7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55d91dbda204fba9463da96be553260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24000' max='71978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24000/71978 48:09 < 1:36:16, 8.31 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.392995</td>\n",
       "      <td>0.903992</td>\n",
       "      <td>0.902964</td>\n",
       "      <td>0.902247</td>\n",
       "      <td>0.903852</td>\n",
       "      <td>7.356500</td>\n",
       "      <td>412.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.396985</td>\n",
       "      <td>0.907291</td>\n",
       "      <td>0.906836</td>\n",
       "      <td>0.906055</td>\n",
       "      <td>0.910952</td>\n",
       "      <td>7.353300</td>\n",
       "      <td>412.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.610443</td>\n",
       "      <td>0.860112</td>\n",
       "      <td>0.860079</td>\n",
       "      <td>0.867134</td>\n",
       "      <td>0.869371</td>\n",
       "      <td>7.355100</td>\n",
       "      <td>412.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.354920</td>\n",
       "      <td>0.905312</td>\n",
       "      <td>0.904599</td>\n",
       "      <td>0.903386</td>\n",
       "      <td>0.907068</td>\n",
       "      <td>7.353500</td>\n",
       "      <td>412.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.374456</td>\n",
       "      <td>0.870010</td>\n",
       "      <td>0.869829</td>\n",
       "      <td>0.872681</td>\n",
       "      <td>0.876915</td>\n",
       "      <td>7.362200</td>\n",
       "      <td>411.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.681548</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.371700</td>\n",
       "      <td>411.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.688401</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.352300</td>\n",
       "      <td>412.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.688703</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.376000</td>\n",
       "      <td>410.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.687287</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.351200</td>\n",
       "      <td>412.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.686938</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.360700</td>\n",
       "      <td>411.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.687212</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.372300</td>\n",
       "      <td>411.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.686813</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.358400</td>\n",
       "      <td>411.910000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+ORIG\n",
      "{'eval_loss': 0.3848177194595337, 'eval_accuracy': 0.910913140311804, 'eval_f1': 0.910330272180576, 'eval_precision': 0.9091432971976775, 'eval_recall': 0.9145914450169262, 'eval_runtime': 16.5429, 'eval_samples_per_second': 407.124, 'epoch': 3.33, 'run': 'pretrained/roberta-base-sst2-ORIG+ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb454fcc9ad5406daf49176b64c13250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0ea0f111d54391a45d3a7094223f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b89985fedfbb9e0f.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='26000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 26000/143957 2:26:57 < 11:06:46, 2.95 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.350331</td>\n",
       "      <td>0.846255</td>\n",
       "      <td>0.842631</td>\n",
       "      <td>0.849628</td>\n",
       "      <td>0.839574</td>\n",
       "      <td>78.929500</td>\n",
       "      <td>76.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.370621</td>\n",
       "      <td>0.855163</td>\n",
       "      <td>0.852245</td>\n",
       "      <td>0.857002</td>\n",
       "      <td>0.849771</td>\n",
       "      <td>78.877700</td>\n",
       "      <td>76.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.363835</td>\n",
       "      <td>0.856813</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.868051</td>\n",
       "      <td>0.846994</td>\n",
       "      <td>78.980600</td>\n",
       "      <td>76.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.381902</td>\n",
       "      <td>0.852359</td>\n",
       "      <td>0.847801</td>\n",
       "      <td>0.860687</td>\n",
       "      <td>0.843488</td>\n",
       "      <td>78.997800</td>\n",
       "      <td>76.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.444136</td>\n",
       "      <td>0.854009</td>\n",
       "      <td>0.849729</td>\n",
       "      <td>0.861357</td>\n",
       "      <td>0.845611</td>\n",
       "      <td>78.980100</td>\n",
       "      <td>76.754000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.434728</td>\n",
       "      <td>0.830254</td>\n",
       "      <td>0.823581</td>\n",
       "      <td>0.843033</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>79.052200</td>\n",
       "      <td>76.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.427461</td>\n",
       "      <td>0.828769</td>\n",
       "      <td>0.823348</td>\n",
       "      <td>0.836146</td>\n",
       "      <td>0.819409</td>\n",
       "      <td>79.029700</td>\n",
       "      <td>76.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.494200</td>\n",
       "      <td>0.575824</td>\n",
       "      <td>0.781590</td>\n",
       "      <td>0.774861</td>\n",
       "      <td>0.785518</td>\n",
       "      <td>0.771949</td>\n",
       "      <td>79.005900</td>\n",
       "      <td>76.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.689445</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.766500</td>\n",
       "      <td>76.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.687633</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.705100</td>\n",
       "      <td>77.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.687924</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.699500</td>\n",
       "      <td>77.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.687655</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.662500</td>\n",
       "      <td>77.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.688231</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>78.862900</td>\n",
       "      <td>76.868000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+INV\n",
      "{'eval_loss': 0.2837463915348053, 'eval_accuracy': 0.9086859688195991, 'eval_f1': 0.9061458273404981, 'eval_precision': 0.9139480235294204, 'eval_recall': 0.9020025983640831, 'eval_runtime': 16.495, 'eval_samples_per_second': 408.305, 'epoch': 1.81, 'run': 'pretrained/roberta-base-sst2-ORIG+INV'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca855def5c1240bc96614a69c883be9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b45f59cd2c4442cba5f49ea8c7b7986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b89985fedfbb9e0f.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='32000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 32000/143957 2:06:56 < 7:24:10, 4.20 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.499616</td>\n",
       "      <td>0.815664</td>\n",
       "      <td>36.486800</td>\n",
       "      <td>166.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.523229</td>\n",
       "      <td>0.773213</td>\n",
       "      <td>36.493000</td>\n",
       "      <td>166.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.477794</td>\n",
       "      <td>0.815535</td>\n",
       "      <td>36.632500</td>\n",
       "      <td>165.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.487641</td>\n",
       "      <td>0.808998</td>\n",
       "      <td>36.635500</td>\n",
       "      <td>165.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.565346</td>\n",
       "      <td>0.818425</td>\n",
       "      <td>36.631600</td>\n",
       "      <td>165.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.479479</td>\n",
       "      <td>0.832698</td>\n",
       "      <td>36.641700</td>\n",
       "      <td>165.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.531700</td>\n",
       "      <td>0.526290</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>36.670300</td>\n",
       "      <td>165.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.516200</td>\n",
       "      <td>0.531673</td>\n",
       "      <td>0.806469</td>\n",
       "      <td>36.659800</td>\n",
       "      <td>165.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>0.472271</td>\n",
       "      <td>0.814430</td>\n",
       "      <td>36.674100</td>\n",
       "      <td>165.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.550031</td>\n",
       "      <td>0.768398</td>\n",
       "      <td>36.624800</td>\n",
       "      <td>165.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.507978</td>\n",
       "      <td>0.815092</td>\n",
       "      <td>36.619900</td>\n",
       "      <td>165.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.552472</td>\n",
       "      <td>0.705170</td>\n",
       "      <td>36.647200</td>\n",
       "      <td>165.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.559400</td>\n",
       "      <td>0.580721</td>\n",
       "      <td>0.683736</td>\n",
       "      <td>36.639600</td>\n",
       "      <td>165.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.653442</td>\n",
       "      <td>0.697243</td>\n",
       "      <td>36.647300</td>\n",
       "      <td>165.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.651400</td>\n",
       "      <td>0.673438</td>\n",
       "      <td>0.665005</td>\n",
       "      <td>36.627500</td>\n",
       "      <td>165.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>0.694744</td>\n",
       "      <td>0.550897</td>\n",
       "      <td>36.619500</td>\n",
       "      <td>165.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+SIB\n",
      "{'eval_loss': 1.9173798561096191, 'eval_accuracy': 0.9121009651076466, 'eval_f1': 0.910556565044754, 'eval_precision': 0.9117629220685963, 'eval_recall': 0.9095451216054439, 'eval_runtime': 16.5944, 'eval_samples_per_second': 405.859, 'epoch': 2.22, 'run': 'pretrained/roberta-base-sst2-ORIG+SIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac131ab9fbe4538afd2b0a44a17fcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca248f0aeac841e98cd457b9df4f0b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b89985fedfbb9e0f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='34000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 34000/143957 3:12:11 < 10:21:34, 2.95 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>0.826125</td>\n",
       "      <td>79.532000</td>\n",
       "      <td>76.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.447259</td>\n",
       "      <td>0.843316</td>\n",
       "      <td>79.535300</td>\n",
       "      <td>76.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>0.432479</td>\n",
       "      <td>0.834872</td>\n",
       "      <td>79.273500</td>\n",
       "      <td>76.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.439096</td>\n",
       "      <td>0.840223</td>\n",
       "      <td>79.219800</td>\n",
       "      <td>76.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.620165</td>\n",
       "      <td>0.795299</td>\n",
       "      <td>79.240000</td>\n",
       "      <td>76.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.486800</td>\n",
       "      <td>0.471553</td>\n",
       "      <td>0.823666</td>\n",
       "      <td>79.334300</td>\n",
       "      <td>76.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.444277</td>\n",
       "      <td>0.844916</td>\n",
       "      <td>79.439400</td>\n",
       "      <td>76.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.500896</td>\n",
       "      <td>0.801584</td>\n",
       "      <td>79.457100</td>\n",
       "      <td>76.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.502388</td>\n",
       "      <td>0.821818</td>\n",
       "      <td>79.490500</td>\n",
       "      <td>76.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>0.515537</td>\n",
       "      <td>0.808649</td>\n",
       "      <td>79.476000</td>\n",
       "      <td>76.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.528900</td>\n",
       "      <td>0.532293</td>\n",
       "      <td>0.802180</td>\n",
       "      <td>79.443600</td>\n",
       "      <td>76.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.581400</td>\n",
       "      <td>0.535956</td>\n",
       "      <td>0.768467</td>\n",
       "      <td>79.514700</td>\n",
       "      <td>76.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>0.694701</td>\n",
       "      <td>0.450971</td>\n",
       "      <td>79.472500</td>\n",
       "      <td>76.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.694526</td>\n",
       "      <td>0.450971</td>\n",
       "      <td>79.479900</td>\n",
       "      <td>76.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.690186</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>79.455800</td>\n",
       "      <td>76.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.690095</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>79.442400</td>\n",
       "      <td>76.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.692254</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>79.395200</td>\n",
       "      <td>76.352000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+INVSIB\n",
      "{'eval_loss': 2.224684476852417, 'eval_accuracy': 0.9162583518930958, 'eval_f1': 0.9151228430011014, 'eval_precision': 0.9146038762143631, 'eval_recall': 0.9157023190524742, 'eval_runtime': 16.5837, 'eval_samples_per_second': 406.122, 'epoch': 2.36, 'run': 'pretrained/roberta-base-sst2-ORIG+INVSIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1576136c3be8435a9d3a2894a0401830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f5c39b6dbf4eb181174e7d0cce4b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b89985fedfbb9e0f.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='143957' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [143957/143957 6:54:39, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.388339</td>\n",
       "      <td>0.873144</td>\n",
       "      <td>25.085500</td>\n",
       "      <td>241.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>0.347085</td>\n",
       "      <td>0.904322</td>\n",
       "      <td>25.086700</td>\n",
       "      <td>241.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.379388</td>\n",
       "      <td>0.914550</td>\n",
       "      <td>25.081000</td>\n",
       "      <td>241.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.352828</td>\n",
       "      <td>0.914220</td>\n",
       "      <td>25.078600</td>\n",
       "      <td>241.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.373590</td>\n",
       "      <td>0.899373</td>\n",
       "      <td>25.041900</td>\n",
       "      <td>242.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>0.442638</td>\n",
       "      <td>0.885846</td>\n",
       "      <td>25.024700</td>\n",
       "      <td>242.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.896734</td>\n",
       "      <td>24.990800</td>\n",
       "      <td>242.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.346300</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.850544</td>\n",
       "      <td>24.955500</td>\n",
       "      <td>242.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.328496</td>\n",
       "      <td>0.918674</td>\n",
       "      <td>24.989500</td>\n",
       "      <td>242.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.344003</td>\n",
       "      <td>0.919169</td>\n",
       "      <td>25.075600</td>\n",
       "      <td>241.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.325100</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0.922633</td>\n",
       "      <td>24.923700</td>\n",
       "      <td>243.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.333900</td>\n",
       "      <td>0.333069</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>24.804700</td>\n",
       "      <td>244.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.402601</td>\n",
       "      <td>0.896404</td>\n",
       "      <td>24.767700</td>\n",
       "      <td>244.754000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>0.312443</td>\n",
       "      <td>0.927912</td>\n",
       "      <td>24.745500</td>\n",
       "      <td>244.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.339504</td>\n",
       "      <td>0.921643</td>\n",
       "      <td>24.753200</td>\n",
       "      <td>244.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.309644</td>\n",
       "      <td>0.911745</td>\n",
       "      <td>24.928400</td>\n",
       "      <td>243.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>0.325346</td>\n",
       "      <td>0.922138</td>\n",
       "      <td>24.941600</td>\n",
       "      <td>243.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.345209</td>\n",
       "      <td>0.904322</td>\n",
       "      <td>24.860700</td>\n",
       "      <td>243.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>0.307487</td>\n",
       "      <td>0.915539</td>\n",
       "      <td>24.869200</td>\n",
       "      <td>243.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.314800</td>\n",
       "      <td>0.351933</td>\n",
       "      <td>0.898218</td>\n",
       "      <td>24.880500</td>\n",
       "      <td>243.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.332300</td>\n",
       "      <td>0.325788</td>\n",
       "      <td>0.930386</td>\n",
       "      <td>24.962800</td>\n",
       "      <td>242.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.317306</td>\n",
       "      <td>0.924777</td>\n",
       "      <td>24.977300</td>\n",
       "      <td>242.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.345540</td>\n",
       "      <td>0.921478</td>\n",
       "      <td>25.017400</td>\n",
       "      <td>242.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.328133</td>\n",
       "      <td>0.926757</td>\n",
       "      <td>25.020300</td>\n",
       "      <td>242.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.324402</td>\n",
       "      <td>0.915704</td>\n",
       "      <td>24.926100</td>\n",
       "      <td>243.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.324024</td>\n",
       "      <td>0.892940</td>\n",
       "      <td>24.973600</td>\n",
       "      <td>242.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>0.311779</td>\n",
       "      <td>0.917189</td>\n",
       "      <td>24.997600</td>\n",
       "      <td>242.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.301348</td>\n",
       "      <td>0.933685</td>\n",
       "      <td>25.039100</td>\n",
       "      <td>242.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.296959</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>25.038300</td>\n",
       "      <td>242.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>24.993800</td>\n",
       "      <td>242.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.298339</td>\n",
       "      <td>0.933520</td>\n",
       "      <td>25.042500</td>\n",
       "      <td>242.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.292972</td>\n",
       "      <td>0.934015</td>\n",
       "      <td>24.965100</td>\n",
       "      <td>242.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.315278</td>\n",
       "      <td>0.933520</td>\n",
       "      <td>25.077700</td>\n",
       "      <td>241.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.313473</td>\n",
       "      <td>0.933190</td>\n",
       "      <td>25.028300</td>\n",
       "      <td>242.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.300375</td>\n",
       "      <td>0.939294</td>\n",
       "      <td>25.031000</td>\n",
       "      <td>242.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>0.288616</td>\n",
       "      <td>0.941933</td>\n",
       "      <td>25.006400</td>\n",
       "      <td>242.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.297214</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>25.083500</td>\n",
       "      <td>241.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.300858</td>\n",
       "      <td>0.941933</td>\n",
       "      <td>25.029000</td>\n",
       "      <td>242.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.292007</td>\n",
       "      <td>0.942098</td>\n",
       "      <td>25.031200</td>\n",
       "      <td>242.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.307824</td>\n",
       "      <td>0.935170</td>\n",
       "      <td>25.025900</td>\n",
       "      <td>242.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.288973</td>\n",
       "      <td>0.951666</td>\n",
       "      <td>25.104200</td>\n",
       "      <td>241.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.290427</td>\n",
       "      <td>0.946387</td>\n",
       "      <td>25.135800</td>\n",
       "      <td>241.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.276330</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>25.085000</td>\n",
       "      <td>241.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.281532</td>\n",
       "      <td>0.946717</td>\n",
       "      <td>25.007000</td>\n",
       "      <td>242.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.224200</td>\n",
       "      <td>0.284642</td>\n",
       "      <td>0.949687</td>\n",
       "      <td>25.053400</td>\n",
       "      <td>241.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.274834</td>\n",
       "      <td>0.953151</td>\n",
       "      <td>25.047900</td>\n",
       "      <td>242.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.273321</td>\n",
       "      <td>0.950511</td>\n",
       "      <td>25.071400</td>\n",
       "      <td>241.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.276787</td>\n",
       "      <td>0.954141</td>\n",
       "      <td>25.020900</td>\n",
       "      <td>242.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.280393</td>\n",
       "      <td>0.953481</td>\n",
       "      <td>25.056300</td>\n",
       "      <td>241.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.280637</td>\n",
       "      <td>0.950676</td>\n",
       "      <td>25.156600</td>\n",
       "      <td>240.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.262527</td>\n",
       "      <td>0.956450</td>\n",
       "      <td>24.986800</td>\n",
       "      <td>242.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.275520</td>\n",
       "      <td>0.955460</td>\n",
       "      <td>25.046200</td>\n",
       "      <td>242.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.271775</td>\n",
       "      <td>0.957275</td>\n",
       "      <td>25.011700</td>\n",
       "      <td>242.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.270557</td>\n",
       "      <td>0.957275</td>\n",
       "      <td>25.084100</td>\n",
       "      <td>241.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.277348</td>\n",
       "      <td>0.957770</td>\n",
       "      <td>25.076900</td>\n",
       "      <td>241.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.270138</td>\n",
       "      <td>0.955955</td>\n",
       "      <td>25.074300</td>\n",
       "      <td>241.762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.261296</td>\n",
       "      <td>0.961894</td>\n",
       "      <td>25.024300</td>\n",
       "      <td>242.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.276269</td>\n",
       "      <td>0.958759</td>\n",
       "      <td>25.025600</td>\n",
       "      <td>242.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.273587</td>\n",
       "      <td>0.959254</td>\n",
       "      <td>25.047000</td>\n",
       "      <td>242.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.254638</td>\n",
       "      <td>0.960244</td>\n",
       "      <td>25.070400</td>\n",
       "      <td>241.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.259648</td>\n",
       "      <td>0.954635</td>\n",
       "      <td>25.115000</td>\n",
       "      <td>241.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.260021</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>24.852500</td>\n",
       "      <td>243.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.257221</td>\n",
       "      <td>0.964698</td>\n",
       "      <td>24.806800</td>\n",
       "      <td>244.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.963048</td>\n",
       "      <td>24.839600</td>\n",
       "      <td>244.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.270457</td>\n",
       "      <td>0.963543</td>\n",
       "      <td>24.738500</td>\n",
       "      <td>245.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.263013</td>\n",
       "      <td>0.963048</td>\n",
       "      <td>24.686600</td>\n",
       "      <td>245.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>24.697100</td>\n",
       "      <td>245.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.266996</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>24.755200</td>\n",
       "      <td>244.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.269170</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>24.748200</td>\n",
       "      <td>244.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.268156</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>24.800200</td>\n",
       "      <td>244.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.964533</td>\n",
       "      <td>24.774400</td>\n",
       "      <td>244.688000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+TextMix\n",
      "{'eval_loss': 3.7596583366394043, 'eval_accuracy': 0.9478841870824053, 'eval_f1': 0.9470961333137561, 'eval_precision': 0.9471789245912419, 'eval_recall': 0.9470144320544618, 'eval_runtime': 16.5743, 'eval_samples_per_second': 406.353, 'epoch': 10.0, 'run': 'pretrained/roberta-base-sst2-ORIG+TextMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6636dc893e467788975ab19fe05199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0595c4223cbd4c85a35ea9ca2eb30260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b89985fedfbb9e0f.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='58000' max='215936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 58000/215936 2:55:40 < 7:58:22, 5.50 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.323766</td>\n",
       "      <td>0.740683</td>\n",
       "      <td>42.181600</td>\n",
       "      <td>215.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.349340</td>\n",
       "      <td>0.736903</td>\n",
       "      <td>42.133600</td>\n",
       "      <td>215.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.292594</td>\n",
       "      <td>0.782381</td>\n",
       "      <td>42.126600</td>\n",
       "      <td>215.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.271406</td>\n",
       "      <td>0.787195</td>\n",
       "      <td>42.117900</td>\n",
       "      <td>215.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.283517</td>\n",
       "      <td>0.782676</td>\n",
       "      <td>42.133400</td>\n",
       "      <td>215.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.291495</td>\n",
       "      <td>0.776922</td>\n",
       "      <td>42.104900</td>\n",
       "      <td>215.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.258915</td>\n",
       "      <td>0.785981</td>\n",
       "      <td>42.110800</td>\n",
       "      <td>215.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.275139</td>\n",
       "      <td>0.776525</td>\n",
       "      <td>42.130700</td>\n",
       "      <td>215.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.281267</td>\n",
       "      <td>0.789144</td>\n",
       "      <td>42.116100</td>\n",
       "      <td>215.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.281268</td>\n",
       "      <td>0.790901</td>\n",
       "      <td>42.132900</td>\n",
       "      <td>215.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.286314</td>\n",
       "      <td>0.780857</td>\n",
       "      <td>42.103600</td>\n",
       "      <td>215.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.259154</td>\n",
       "      <td>0.787215</td>\n",
       "      <td>42.092900</td>\n",
       "      <td>216.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.286900</td>\n",
       "      <td>0.273446</td>\n",
       "      <td>0.788371</td>\n",
       "      <td>42.143400</td>\n",
       "      <td>215.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.281700</td>\n",
       "      <td>0.272624</td>\n",
       "      <td>0.765336</td>\n",
       "      <td>42.176100</td>\n",
       "      <td>215.596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.281289</td>\n",
       "      <td>0.787847</td>\n",
       "      <td>42.145400</td>\n",
       "      <td>215.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>0.250933</td>\n",
       "      <td>0.793937</td>\n",
       "      <td>42.140900</td>\n",
       "      <td>215.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.274500</td>\n",
       "      <td>0.259176</td>\n",
       "      <td>0.787847</td>\n",
       "      <td>42.185000</td>\n",
       "      <td>215.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.256063</td>\n",
       "      <td>0.794002</td>\n",
       "      <td>42.181900</td>\n",
       "      <td>215.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.253112</td>\n",
       "      <td>0.799574</td>\n",
       "      <td>42.068900</td>\n",
       "      <td>216.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>0.789977</td>\n",
       "      <td>42.001900</td>\n",
       "      <td>216.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.302579</td>\n",
       "      <td>0.776558</td>\n",
       "      <td>41.999700</td>\n",
       "      <td>216.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.267959</td>\n",
       "      <td>0.781644</td>\n",
       "      <td>41.939700</td>\n",
       "      <td>216.811000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.276050</td>\n",
       "      <td>0.766464</td>\n",
       "      <td>41.930800</td>\n",
       "      <td>216.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.267549</td>\n",
       "      <td>0.790415</td>\n",
       "      <td>42.046700</td>\n",
       "      <td>216.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.272212</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>42.074700</td>\n",
       "      <td>216.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>0.332914</td>\n",
       "      <td>0.761297</td>\n",
       "      <td>42.060200</td>\n",
       "      <td>216.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.284716</td>\n",
       "      <td>0.786187</td>\n",
       "      <td>42.101100</td>\n",
       "      <td>215.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>0.315811</td>\n",
       "      <td>0.771472</td>\n",
       "      <td>42.106500</td>\n",
       "      <td>215.953000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.283290</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>42.127800</td>\n",
       "      <td>215.843000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+SentMix\n",
      "{'eval_loss': 1.9896941184997559, 'eval_accuracy': 0.9358574610244988, 'eval_f1': 0.9350498827758339, 'eval_precision': 0.9341799024303312, 'eval_recall': 0.9361059927053919, 'eval_runtime': 16.5316, 'eval_samples_per_second': 407.401, 'epoch': 2.69, 'run': 'pretrained/roberta-base-sst2-ORIG+SentMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ae017aa5ba4ece8d9ed597a626192e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d085e8588b274d3c97bbdf283b19516b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-b89985fedfbb9e0f.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='30000' max='287916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 30000/287916 1:38:06 < 14:03:30, 5.10 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.281070</td>\n",
       "      <td>0.602371</td>\n",
       "      <td>52.832400</td>\n",
       "      <td>229.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.273747</td>\n",
       "      <td>0.618054</td>\n",
       "      <td>52.777200</td>\n",
       "      <td>229.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.246531</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>52.811900</td>\n",
       "      <td>229.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.260096</td>\n",
       "      <td>0.639924</td>\n",
       "      <td>52.842400</td>\n",
       "      <td>229.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.252496</td>\n",
       "      <td>0.644632</td>\n",
       "      <td>52.810900</td>\n",
       "      <td>229.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.280762</td>\n",
       "      <td>0.618442</td>\n",
       "      <td>52.827100</td>\n",
       "      <td>229.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.267600</td>\n",
       "      <td>0.241989</td>\n",
       "      <td>0.641800</td>\n",
       "      <td>52.838100</td>\n",
       "      <td>229.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.634867</td>\n",
       "      <td>53.065400</td>\n",
       "      <td>228.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.251022</td>\n",
       "      <td>0.643711</td>\n",
       "      <td>52.934100</td>\n",
       "      <td>229.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.240891</td>\n",
       "      <td>0.638753</td>\n",
       "      <td>52.695100</td>\n",
       "      <td>230.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.251071</td>\n",
       "      <td>0.644121</td>\n",
       "      <td>52.648900</td>\n",
       "      <td>230.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.235997</td>\n",
       "      <td>0.639163</td>\n",
       "      <td>52.617800</td>\n",
       "      <td>230.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>0.258144</td>\n",
       "      <td>0.643551</td>\n",
       "      <td>52.534800</td>\n",
       "      <td>230.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.232320</td>\n",
       "      <td>0.638602</td>\n",
       "      <td>52.508000</td>\n",
       "      <td>230.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.225006</td>\n",
       "      <td>0.643339</td>\n",
       "      <td>52.531300</td>\n",
       "      <td>230.777000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-sst2-ORIG+WordMix\n",
      "{'eval_loss': 3.0437018871307373, 'eval_accuracy': 0.9293244246473645, 'eval_f1': 0.9282264835871024, 'eval_precision': 0.9284875181185134, 'eval_recall': 0.9279763941952446, 'eval_runtime': 16.5389, 'eval_samples_per_second': 407.221, 'epoch': 1.04, 'run': 'pretrained/roberta-base-sst2-ORIG+WordMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Loading cached split indices for dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-82065d53de91e6a2.arrow and C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-4c7cdb0a6bd6d7fd.arrow\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7addaf27f9b94db2b4dcf64e08627ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9befab480ce54d069ec1c8381d622998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b451d56e6e44900872b28b7b111c3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='26000' max='71978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26000/71978 1:10:18 < 2:04:19, 6.16 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.356708</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>0.902733</td>\n",
       "      <td>0.901624</td>\n",
       "      <td>0.905965</td>\n",
       "      <td>11.889300</td>\n",
       "      <td>254.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.365100</td>\n",
       "      <td>0.335287</td>\n",
       "      <td>0.914880</td>\n",
       "      <td>0.914263</td>\n",
       "      <td>0.913014</td>\n",
       "      <td>0.916946</td>\n",
       "      <td>11.877300</td>\n",
       "      <td>255.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.407290</td>\n",
       "      <td>0.916529</td>\n",
       "      <td>0.915478</td>\n",
       "      <td>0.915386</td>\n",
       "      <td>0.915572</td>\n",
       "      <td>11.923100</td>\n",
       "      <td>254.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.417115</td>\n",
       "      <td>0.893435</td>\n",
       "      <td>0.892762</td>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.895865</td>\n",
       "      <td>11.896200</td>\n",
       "      <td>254.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>0.439453</td>\n",
       "      <td>0.875619</td>\n",
       "      <td>0.873799</td>\n",
       "      <td>0.874542</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>11.902200</td>\n",
       "      <td>254.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>0.838667</td>\n",
       "      <td>0.838627</td>\n",
       "      <td>0.854139</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>11.945100</td>\n",
       "      <td>253.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.840977</td>\n",
       "      <td>0.838938</td>\n",
       "      <td>0.838938</td>\n",
       "      <td>0.838938</td>\n",
       "      <td>11.930100</td>\n",
       "      <td>254.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>0.690142</td>\n",
       "      <td>0.556582</td>\n",
       "      <td>0.358249</td>\n",
       "      <td>0.778218</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>11.889200</td>\n",
       "      <td>254.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>0.688048</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.872300</td>\n",
       "      <td>255.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.702018</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.878300</td>\n",
       "      <td>255.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.687016</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.874300</td>\n",
       "      <td>255.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.692400</td>\n",
       "      <td>0.686884</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.872300</td>\n",
       "      <td>255.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.890200</td>\n",
       "      <td>254.915000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+ORIG\n",
      "{'eval_loss': 0.3966030478477478, 'eval_accuracy': 0.9184855233853007, 'eval_f1': 0.9172037132623617, 'eval_precision': 0.9175418485411704, 'eval_recall': 0.9168842113402947, 'eval_runtime': 26.6179, 'eval_samples_per_second': 253.026, 'epoch': 3.61, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023746487c3949a9bb95efc3ca781c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506586e4b9eb4cf7a09a18f8110f1602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-0617f0b0800fe559.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='28000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 28000/143957 4:29:41 < 18:36:56, 1.73 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.569700</td>\n",
       "      <td>0.387528</td>\n",
       "      <td>0.834708</td>\n",
       "      <td>0.829872</td>\n",
       "      <td>0.840915</td>\n",
       "      <td>0.826113</td>\n",
       "      <td>188.888700</td>\n",
       "      <td>32.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.339949</td>\n",
       "      <td>0.854668</td>\n",
       "      <td>0.851719</td>\n",
       "      <td>0.856567</td>\n",
       "      <td>0.849218</td>\n",
       "      <td>188.727400</td>\n",
       "      <td>32.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.405300</td>\n",
       "      <td>0.356635</td>\n",
       "      <td>0.839327</td>\n",
       "      <td>0.832797</td>\n",
       "      <td>0.853931</td>\n",
       "      <td>0.827704</td>\n",
       "      <td>188.693600</td>\n",
       "      <td>32.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.366489</td>\n",
       "      <td>0.854833</td>\n",
       "      <td>0.852060</td>\n",
       "      <td>0.856134</td>\n",
       "      <td>0.849823</td>\n",
       "      <td>188.684700</td>\n",
       "      <td>32.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.458004</td>\n",
       "      <td>0.838337</td>\n",
       "      <td>0.835157</td>\n",
       "      <td>0.839412</td>\n",
       "      <td>0.832933</td>\n",
       "      <td>188.696700</td>\n",
       "      <td>32.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.471170</td>\n",
       "      <td>0.827285</td>\n",
       "      <td>0.819159</td>\n",
       "      <td>0.845740</td>\n",
       "      <td>0.814005</td>\n",
       "      <td>188.705500</td>\n",
       "      <td>32.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.499205</td>\n",
       "      <td>0.790663</td>\n",
       "      <td>0.779551</td>\n",
       "      <td>0.809228</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>188.650800</td>\n",
       "      <td>32.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.570057</td>\n",
       "      <td>0.736556</td>\n",
       "      <td>0.704413</td>\n",
       "      <td>0.799621</td>\n",
       "      <td>0.709771</td>\n",
       "      <td>188.634500</td>\n",
       "      <td>32.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.583486</td>\n",
       "      <td>0.706203</td>\n",
       "      <td>0.663250</td>\n",
       "      <td>0.777151</td>\n",
       "      <td>0.676176</td>\n",
       "      <td>188.570300</td>\n",
       "      <td>32.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.605800</td>\n",
       "      <td>0.664222</td>\n",
       "      <td>0.663312</td>\n",
       "      <td>0.597644</td>\n",
       "      <td>0.750014</td>\n",
       "      <td>0.627838</td>\n",
       "      <td>188.511500</td>\n",
       "      <td>32.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.687657</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>188.434200</td>\n",
       "      <td>32.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.687899</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>188.554700</td>\n",
       "      <td>32.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>0.687754</td>\n",
       "      <td>0.552458</td>\n",
       "      <td>0.355860</td>\n",
       "      <td>0.276229</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>188.658800</td>\n",
       "      <td>32.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>0.695627</td>\n",
       "      <td>0.448037</td>\n",
       "      <td>0.310175</td>\n",
       "      <td>0.723882</td>\n",
       "      <td>0.500448</td>\n",
       "      <td>188.601500</td>\n",
       "      <td>32.142000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+INV\n",
      "{'eval_loss': 0.2776615619659424, 'eval_accuracy': 0.9095768374164811, 'eval_f1': 0.9085893819342337, 'eval_precision': 0.9073790564335193, 'eval_recall': 0.9103651653816853, 'eval_runtime': 26.4643, 'eval_samples_per_second': 254.494, 'epoch': 1.94, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+INV'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f9f83a7c24d359cbc69cb5c78d583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408bcc89bbc040808c1593f8cb6ab0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-0617f0b0800fe559.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='34000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 34000/143957 3:41:07 < 11:55:08, 2.56 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.515871</td>\n",
       "      <td>0.774126</td>\n",
       "      <td>91.209300</td>\n",
       "      <td>66.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.779670</td>\n",
       "      <td>91.237200</td>\n",
       "      <td>66.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.443831</td>\n",
       "      <td>0.814927</td>\n",
       "      <td>91.287400</td>\n",
       "      <td>66.406000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.496700</td>\n",
       "      <td>0.517605</td>\n",
       "      <td>0.797418</td>\n",
       "      <td>91.267200</td>\n",
       "      <td>66.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.556405</td>\n",
       "      <td>0.818988</td>\n",
       "      <td>91.331400</td>\n",
       "      <td>66.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.516226</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>91.313200</td>\n",
       "      <td>66.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.524600</td>\n",
       "      <td>0.478876</td>\n",
       "      <td>0.829072</td>\n",
       "      <td>91.234100</td>\n",
       "      <td>66.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>0.529117</td>\n",
       "      <td>0.818593</td>\n",
       "      <td>91.216700</td>\n",
       "      <td>66.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.556200</td>\n",
       "      <td>0.546141</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>91.237000</td>\n",
       "      <td>66.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.653192</td>\n",
       "      <td>0.718221</td>\n",
       "      <td>91.186700</td>\n",
       "      <td>66.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.563346</td>\n",
       "      <td>0.754470</td>\n",
       "      <td>91.240400</td>\n",
       "      <td>66.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.567800</td>\n",
       "      <td>0.597984</td>\n",
       "      <td>0.642480</td>\n",
       "      <td>91.418200</td>\n",
       "      <td>66.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.593200</td>\n",
       "      <td>0.628564</td>\n",
       "      <td>0.704552</td>\n",
       "      <td>91.481500</td>\n",
       "      <td>66.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.554600</td>\n",
       "      <td>0.562753</td>\n",
       "      <td>0.759508</td>\n",
       "      <td>91.325200</td>\n",
       "      <td>66.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.587372</td>\n",
       "      <td>0.716897</td>\n",
       "      <td>91.373300</td>\n",
       "      <td>66.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>0.554909</td>\n",
       "      <td>0.775578</td>\n",
       "      <td>91.608700</td>\n",
       "      <td>66.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.584654</td>\n",
       "      <td>0.774941</td>\n",
       "      <td>91.583900</td>\n",
       "      <td>66.191000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+SIB\n",
      "{'eval_loss': 1.9360039234161377, 'eval_accuracy': 0.9048255382331106, 'eval_f1': 0.9032405252138185, 'eval_precision': 0.903983997692196, 'eval_recall': 0.9025814843826074, 'eval_runtime': 26.5381, 'eval_samples_per_second': 253.786, 'epoch': 2.36, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+SIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4960d6b5f55a4f4a92006dff0ce4fd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d43e8d764f46e7b5c9957b056ed164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-0617f0b0800fe559.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='32000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 32000/143957 5:09:10 < 18:01:44, 1.72 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.605700</td>\n",
       "      <td>0.472485</td>\n",
       "      <td>0.823622</td>\n",
       "      <td>188.470500</td>\n",
       "      <td>32.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.493100</td>\n",
       "      <td>0.466087</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>188.246100</td>\n",
       "      <td>32.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.446362</td>\n",
       "      <td>0.832852</td>\n",
       "      <td>188.163000</td>\n",
       "      <td>32.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.450005</td>\n",
       "      <td>0.826300</td>\n",
       "      <td>188.244100</td>\n",
       "      <td>32.203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.530234</td>\n",
       "      <td>0.838073</td>\n",
       "      <td>188.314100</td>\n",
       "      <td>32.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.462900</td>\n",
       "      <td>0.420377</td>\n",
       "      <td>0.843609</td>\n",
       "      <td>188.428300</td>\n",
       "      <td>32.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.482716</td>\n",
       "      <td>0.826287</td>\n",
       "      <td>188.292400</td>\n",
       "      <td>32.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.461281</td>\n",
       "      <td>0.831581</td>\n",
       "      <td>188.447200</td>\n",
       "      <td>32.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.482679</td>\n",
       "      <td>0.827402</td>\n",
       "      <td>188.219400</td>\n",
       "      <td>32.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.498800</td>\n",
       "      <td>0.531757</td>\n",
       "      <td>0.807617</td>\n",
       "      <td>188.221100</td>\n",
       "      <td>32.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.554120</td>\n",
       "      <td>0.805092</td>\n",
       "      <td>188.309300</td>\n",
       "      <td>32.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.609900</td>\n",
       "      <td>0.691073</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>188.442700</td>\n",
       "      <td>32.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.698810</td>\n",
       "      <td>0.450971</td>\n",
       "      <td>188.356000</td>\n",
       "      <td>32.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.637100</td>\n",
       "      <td>0.593412</td>\n",
       "      <td>0.665792</td>\n",
       "      <td>188.484500</td>\n",
       "      <td>32.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.679700</td>\n",
       "      <td>0.689745</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>188.309400</td>\n",
       "      <td>32.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.689951</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>188.171300</td>\n",
       "      <td>32.215000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+INVSIB\n",
      "{'eval_loss': 2.087074041366577, 'eval_accuracy': 0.9236822568671121, 'eval_f1': 0.9226847571189281, 'eval_precision': 0.9219906083708108, 'eval_recall': 0.9234930258017768, 'eval_runtime': 26.6206, 'eval_samples_per_second': 253.0, 'epoch': 2.22, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+INVSIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c439c7a2f19f4123abda132d4b33a211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3423bb653f145908b9cb3f33168e933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-0617f0b0800fe559.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='143957' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [143957/143957 11:04:47, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.379835</td>\n",
       "      <td>0.854339</td>\n",
       "      <td>52.153900</td>\n",
       "      <td>116.233000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>0.369713</td>\n",
       "      <td>0.872979</td>\n",
       "      <td>52.045000</td>\n",
       "      <td>116.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>0.885681</td>\n",
       "      <td>51.857800</td>\n",
       "      <td>116.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>0.322444</td>\n",
       "      <td>0.899208</td>\n",
       "      <td>51.898700</td>\n",
       "      <td>116.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.359200</td>\n",
       "      <td>0.349202</td>\n",
       "      <td>0.892610</td>\n",
       "      <td>51.998100</td>\n",
       "      <td>116.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.394981</td>\n",
       "      <td>0.884856</td>\n",
       "      <td>51.964600</td>\n",
       "      <td>116.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.317636</td>\n",
       "      <td>0.905807</td>\n",
       "      <td>52.097400</td>\n",
       "      <td>116.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.339281</td>\n",
       "      <td>0.897394</td>\n",
       "      <td>52.127900</td>\n",
       "      <td>116.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.371489</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>52.006200</td>\n",
       "      <td>116.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.330251</td>\n",
       "      <td>0.913065</td>\n",
       "      <td>52.165500</td>\n",
       "      <td>116.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.299789</td>\n",
       "      <td>0.915374</td>\n",
       "      <td>51.974000</td>\n",
       "      <td>116.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.916694</td>\n",
       "      <td>52.105600</td>\n",
       "      <td>116.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>0.297232</td>\n",
       "      <td>0.921148</td>\n",
       "      <td>52.099900</td>\n",
       "      <td>116.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.344572</td>\n",
       "      <td>0.908446</td>\n",
       "      <td>52.072100</td>\n",
       "      <td>116.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.331817</td>\n",
       "      <td>0.917684</td>\n",
       "      <td>52.098800</td>\n",
       "      <td>116.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.308460</td>\n",
       "      <td>0.914220</td>\n",
       "      <td>52.015600</td>\n",
       "      <td>116.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.342693</td>\n",
       "      <td>0.877763</td>\n",
       "      <td>52.008300</td>\n",
       "      <td>116.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.347089</td>\n",
       "      <td>0.901848</td>\n",
       "      <td>52.082800</td>\n",
       "      <td>116.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.339154</td>\n",
       "      <td>0.885846</td>\n",
       "      <td>52.023900</td>\n",
       "      <td>116.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.305305</td>\n",
       "      <td>0.914715</td>\n",
       "      <td>51.967400</td>\n",
       "      <td>116.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.320055</td>\n",
       "      <td>0.921973</td>\n",
       "      <td>52.031400</td>\n",
       "      <td>116.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.307581</td>\n",
       "      <td>0.920488</td>\n",
       "      <td>52.023900</td>\n",
       "      <td>116.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.300754</td>\n",
       "      <td>0.923623</td>\n",
       "      <td>52.082900</td>\n",
       "      <td>116.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.288595</td>\n",
       "      <td>0.930221</td>\n",
       "      <td>52.037100</td>\n",
       "      <td>116.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.299261</td>\n",
       "      <td>0.928242</td>\n",
       "      <td>51.861200</td>\n",
       "      <td>116.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>0.303640</td>\n",
       "      <td>0.926757</td>\n",
       "      <td>51.858500</td>\n",
       "      <td>116.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.298133</td>\n",
       "      <td>0.927417</td>\n",
       "      <td>51.826400</td>\n",
       "      <td>116.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.307284</td>\n",
       "      <td>0.919169</td>\n",
       "      <td>51.932500</td>\n",
       "      <td>116.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.305705</td>\n",
       "      <td>0.933850</td>\n",
       "      <td>51.928100</td>\n",
       "      <td>116.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.244900</td>\n",
       "      <td>0.300128</td>\n",
       "      <td>0.932201</td>\n",
       "      <td>51.931000</td>\n",
       "      <td>116.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.308249</td>\n",
       "      <td>0.929726</td>\n",
       "      <td>51.977100</td>\n",
       "      <td>116.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.305348</td>\n",
       "      <td>0.926757</td>\n",
       "      <td>52.027200</td>\n",
       "      <td>116.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.286170</td>\n",
       "      <td>0.924777</td>\n",
       "      <td>51.979000</td>\n",
       "      <td>116.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.286768</td>\n",
       "      <td>0.922468</td>\n",
       "      <td>51.942400</td>\n",
       "      <td>116.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.290782</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>52.047400</td>\n",
       "      <td>116.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.279384</td>\n",
       "      <td>0.929726</td>\n",
       "      <td>51.988900</td>\n",
       "      <td>116.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.295258</td>\n",
       "      <td>0.933520</td>\n",
       "      <td>51.833400</td>\n",
       "      <td>116.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.284769</td>\n",
       "      <td>0.938304</td>\n",
       "      <td>51.835300</td>\n",
       "      <td>116.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.275198</td>\n",
       "      <td>0.941274</td>\n",
       "      <td>51.844800</td>\n",
       "      <td>116.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.282009</td>\n",
       "      <td>0.936820</td>\n",
       "      <td>51.846900</td>\n",
       "      <td>116.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.224200</td>\n",
       "      <td>0.283070</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>51.953600</td>\n",
       "      <td>116.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.281197</td>\n",
       "      <td>0.941109</td>\n",
       "      <td>51.931200</td>\n",
       "      <td>116.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.263438</td>\n",
       "      <td>0.931706</td>\n",
       "      <td>51.985600</td>\n",
       "      <td>116.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.266686</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>51.981500</td>\n",
       "      <td>116.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.276558</td>\n",
       "      <td>0.941109</td>\n",
       "      <td>51.978400</td>\n",
       "      <td>116.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.267640</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>51.970900</td>\n",
       "      <td>116.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.271843</td>\n",
       "      <td>0.944738</td>\n",
       "      <td>51.980400</td>\n",
       "      <td>116.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.279637</td>\n",
       "      <td>0.946222</td>\n",
       "      <td>51.975900</td>\n",
       "      <td>116.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.283270</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>52.021700</td>\n",
       "      <td>116.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.279142</td>\n",
       "      <td>0.944078</td>\n",
       "      <td>51.946200</td>\n",
       "      <td>116.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.264527</td>\n",
       "      <td>0.949687</td>\n",
       "      <td>51.941800</td>\n",
       "      <td>116.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.263508</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>51.903500</td>\n",
       "      <td>116.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.253707</td>\n",
       "      <td>0.950346</td>\n",
       "      <td>51.911400</td>\n",
       "      <td>116.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.258859</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>51.944400</td>\n",
       "      <td>116.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.270988</td>\n",
       "      <td>0.952161</td>\n",
       "      <td>51.943300</td>\n",
       "      <td>116.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.271222</td>\n",
       "      <td>0.949522</td>\n",
       "      <td>52.019000</td>\n",
       "      <td>116.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.263147</td>\n",
       "      <td>0.951006</td>\n",
       "      <td>51.991600</td>\n",
       "      <td>116.596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.279702</td>\n",
       "      <td>0.949357</td>\n",
       "      <td>52.021300</td>\n",
       "      <td>116.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.276764</td>\n",
       "      <td>0.951336</td>\n",
       "      <td>51.996600</td>\n",
       "      <td>116.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.267150</td>\n",
       "      <td>0.951501</td>\n",
       "      <td>52.053400</td>\n",
       "      <td>116.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.277483</td>\n",
       "      <td>0.951501</td>\n",
       "      <td>52.010000</td>\n",
       "      <td>116.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.264947</td>\n",
       "      <td>0.949192</td>\n",
       "      <td>51.936400</td>\n",
       "      <td>116.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.264794</td>\n",
       "      <td>0.951501</td>\n",
       "      <td>51.982600</td>\n",
       "      <td>116.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.268134</td>\n",
       "      <td>0.951996</td>\n",
       "      <td>51.904100</td>\n",
       "      <td>116.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.270579</td>\n",
       "      <td>0.953151</td>\n",
       "      <td>51.898600</td>\n",
       "      <td>116.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.265755</td>\n",
       "      <td>0.954470</td>\n",
       "      <td>51.802400</td>\n",
       "      <td>117.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.260809</td>\n",
       "      <td>0.954470</td>\n",
       "      <td>51.894900</td>\n",
       "      <td>116.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.267626</td>\n",
       "      <td>0.955460</td>\n",
       "      <td>52.028900</td>\n",
       "      <td>116.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.268208</td>\n",
       "      <td>0.955955</td>\n",
       "      <td>51.906300</td>\n",
       "      <td>116.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.265149</td>\n",
       "      <td>0.954635</td>\n",
       "      <td>51.867300</td>\n",
       "      <td>116.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.265117</td>\n",
       "      <td>0.954800</td>\n",
       "      <td>51.873500</td>\n",
       "      <td>116.861000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+TextMix\n",
      "{'eval_loss': 4.150676250457764, 'eval_accuracy': 0.9518930957683742, 'eval_f1': 0.9511852848332614, 'eval_precision': 0.9510878462701455, 'eval_recall': 0.9512842981910976, 'eval_runtime': 26.6727, 'eval_samples_per_second': 252.505, 'epoch': 10.0, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+TextMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec54ec1928b413a97c4b5a9fd88620d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dfdca0e0ea454abc54052de3273936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-0617f0b0800fe559.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='38000' max='215936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 38000/215936 3:12:18 < 15:00:33, 3.29 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.491600</td>\n",
       "      <td>0.350863</td>\n",
       "      <td>0.715953</td>\n",
       "      <td>100.513400</td>\n",
       "      <td>90.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>0.389889</td>\n",
       "      <td>0.712904</td>\n",
       "      <td>100.631200</td>\n",
       "      <td>90.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.326924</td>\n",
       "      <td>0.760228</td>\n",
       "      <td>100.706300</td>\n",
       "      <td>90.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.294704</td>\n",
       "      <td>0.771255</td>\n",
       "      <td>100.652000</td>\n",
       "      <td>90.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.282394</td>\n",
       "      <td>0.779281</td>\n",
       "      <td>100.694300</td>\n",
       "      <td>90.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.291790</td>\n",
       "      <td>0.758940</td>\n",
       "      <td>100.795700</td>\n",
       "      <td>90.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>0.771956</td>\n",
       "      <td>100.695400</td>\n",
       "      <td>90.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.299800</td>\n",
       "      <td>0.261266</td>\n",
       "      <td>0.772919</td>\n",
       "      <td>100.795800</td>\n",
       "      <td>90.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.268101</td>\n",
       "      <td>0.784646</td>\n",
       "      <td>100.779000</td>\n",
       "      <td>90.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.281862</td>\n",
       "      <td>0.774433</td>\n",
       "      <td>100.825600</td>\n",
       "      <td>90.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.286797</td>\n",
       "      <td>0.775208</td>\n",
       "      <td>100.620800</td>\n",
       "      <td>90.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.289200</td>\n",
       "      <td>0.287822</td>\n",
       "      <td>0.775760</td>\n",
       "      <td>100.562000</td>\n",
       "      <td>90.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.290319</td>\n",
       "      <td>0.770407</td>\n",
       "      <td>100.562300</td>\n",
       "      <td>90.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.280229</td>\n",
       "      <td>0.778548</td>\n",
       "      <td>100.465800</td>\n",
       "      <td>90.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.290982</td>\n",
       "      <td>0.781313</td>\n",
       "      <td>100.644100</td>\n",
       "      <td>90.348000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.276291</td>\n",
       "      <td>0.776947</td>\n",
       "      <td>100.651500</td>\n",
       "      <td>90.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0.770261</td>\n",
       "      <td>100.731000</td>\n",
       "      <td>90.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.280635</td>\n",
       "      <td>0.753972</td>\n",
       "      <td>100.783600</td>\n",
       "      <td>90.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.281172</td>\n",
       "      <td>0.755478</td>\n",
       "      <td>100.774900</td>\n",
       "      <td>90.231000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+SentMix\n",
      "{'eval_loss': 2.606091260910034, 'eval_accuracy': 0.9291759465478842, 'eval_f1': 0.9277320216590118, 'eval_precision': 0.9306033664763365, 'eval_recall': 0.9256503338708106, 'eval_runtime': 26.574, 'eval_samples_per_second': 253.443, 'epoch': 1.76, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+SentMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b644473814244599bef6ddec407fec4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1273ec9f70e1477ea8c97c85cdc68b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-0617f0b0800fe559.arrow\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='44000' max='287916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 44000/287916 3:49:38 < 21:13:05, 3.19 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.298179</td>\n",
       "      <td>0.596130</td>\n",
       "      <td>107.078400</td>\n",
       "      <td>113.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.330469</td>\n",
       "      <td>0.575991</td>\n",
       "      <td>106.782600</td>\n",
       "      <td>113.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.262498</td>\n",
       "      <td>0.622632</td>\n",
       "      <td>106.565000</td>\n",
       "      <td>113.762000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.291122</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>106.378700</td>\n",
       "      <td>113.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.242179</td>\n",
       "      <td>0.632480</td>\n",
       "      <td>106.370400</td>\n",
       "      <td>113.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.643878</td>\n",
       "      <td>106.335100</td>\n",
       "      <td>114.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.235138</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>106.735600</td>\n",
       "      <td>113.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.261517</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>106.624400</td>\n",
       "      <td>113.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>0.236509</td>\n",
       "      <td>0.638936</td>\n",
       "      <td>106.664100</td>\n",
       "      <td>113.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.644712</td>\n",
       "      <td>106.788300</td>\n",
       "      <td>113.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.286491</td>\n",
       "      <td>0.629468</td>\n",
       "      <td>106.814800</td>\n",
       "      <td>113.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.254800</td>\n",
       "      <td>0.230699</td>\n",
       "      <td>0.647674</td>\n",
       "      <td>106.934400</td>\n",
       "      <td>113.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.240414</td>\n",
       "      <td>0.638263</td>\n",
       "      <td>106.778500</td>\n",
       "      <td>113.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.259800</td>\n",
       "      <td>0.236181</td>\n",
       "      <td>0.647099</td>\n",
       "      <td>107.021700</td>\n",
       "      <td>113.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.235610</td>\n",
       "      <td>0.645423</td>\n",
       "      <td>106.674800</td>\n",
       "      <td>113.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.252892</td>\n",
       "      <td>0.644758</td>\n",
       "      <td>106.567000</td>\n",
       "      <td>113.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.239832</td>\n",
       "      <td>0.634275</td>\n",
       "      <td>106.427600</td>\n",
       "      <td>113.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.237026</td>\n",
       "      <td>0.646594</td>\n",
       "      <td>106.652700</td>\n",
       "      <td>113.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.255800</td>\n",
       "      <td>0.260905</td>\n",
       "      <td>0.624665</td>\n",
       "      <td>106.843300</td>\n",
       "      <td>113.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.257600</td>\n",
       "      <td>0.323093</td>\n",
       "      <td>0.619672</td>\n",
       "      <td>106.891200</td>\n",
       "      <td>113.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.247842</td>\n",
       "      <td>0.635057</td>\n",
       "      <td>107.029500</td>\n",
       "      <td>113.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.274200</td>\n",
       "      <td>0.271505</td>\n",
       "      <td>0.631161</td>\n",
       "      <td>107.015900</td>\n",
       "      <td>113.282000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-sst2-ORIG+WordMix\n",
      "{'eval_loss': 2.8750319480895996, 'eval_accuracy': 0.9365998515219005, 'eval_f1': 0.9357062694840792, 'eval_precision': 0.9353618379608855, 'eval_recall': 0.9360734147043492, 'eval_runtime': 26.6857, 'eval_samples_per_second': 252.383, 'epoch': 1.53, 'run': 'pretrained/xlnet-base-cased-sst2-ORIG+WordMix'}\n"
     ]
    }
   ],
   "source": [
    "use_pretrain = False\n",
    "\n",
    "results = []\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "    for t in ['ORIG', 'INV', 'SIB', 'INVSIB', 'TextMix', 'SentMix', 'WordMix']: \n",
    "        \n",
    "        soft_target = False\n",
    "        eval_only = False\n",
    "        \n",
    "        checkpoint = 'pretrained/' + MODEL_NAME + \"-sst2-ORIG+\" + t \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        if t == 'ORIG':\n",
    "            train_dataset = load_dataset('glue', 'sst2', split='train[:90%]')\n",
    "            train_dataset.rename_column_('sentence', 'text')\n",
    "        else: \n",
    "            \n",
    "            # load custom data    \n",
    "            text = npy_load(\"./assets/SST2/\" + t + \"/text.npy\")\n",
    "            label = npy_load(\"./assets/SST2/\" + t + \"/label.npy\")\n",
    "            if len(label.shape) > 1:\n",
    "                df = pd.DataFrame({'text': text, 'label': label.tolist()})\n",
    "                df.text = df.text.astype(str)\n",
    "                df.label = df.label.map(lambda y: np.array(y))\n",
    "            else:\n",
    "                df = pd.DataFrame({'text': text, 'label': label})\n",
    "                df.text = df.text.astype(str)\n",
    "                df.label = df.label.astype(object)\n",
    "            train_dataset = Dataset.from_pandas(df) \n",
    "            \n",
    "            # load orig data\n",
    "            orig_dataset = load_dataset('glue', 'sst2', split='train[:90%]')\n",
    "            orig_dataset.remove_columns_(['idx'])\n",
    "            orig_dataset.rename_column_('sentence', 'text')\n",
    "            df = orig_dataset.to_pandas()\n",
    "            df = df[df.columns[::-1]]\n",
    "            df.text = df.text.astype(str)\n",
    "            if len(label.shape) > 1:\n",
    "                df.label = df.label.map(one_hot_encode)\n",
    "            else:\n",
    "                df.label = df.label.astype(object)\n",
    "            orig_dataset = Dataset.from_pandas(df)\n",
    "            \n",
    "            # merge orig + custom data\n",
    "            train_dataset = concatenate_datasets([orig_dataset, train_dataset])\n",
    "            train_dataset.shuffle()\n",
    "            \n",
    "        if use_pretrain and os.path.exists(checkpoint):\n",
    "            print('loading {}...'.format(checkpoint))\n",
    "            MODEL_NAME = checkpoint\n",
    "            eval_only = True\n",
    "            \n",
    "        # split to get train\n",
    "        dataset_dict = train_dataset.train_test_split(\n",
    "            test_size = 0.05,\n",
    "            train_size = 0.95,\n",
    "            shuffle = True\n",
    "        )\n",
    "        train_dataset = dataset_dict['train']\n",
    "        eval_dataset = dataset_dict['test']\n",
    "        test_dataset = load_dataset('glue', 'sst2', split='train[-10%:]')\n",
    "        test_dataset.rename_column_('sentence', 'text')\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device)\n",
    "            \n",
    "        train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "        eval_dataset = eval_dataset.map(tokenize, batched=True, batch_size=len(eval_dataset))\n",
    "        test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "        train_dataset.rename_column_('label', 'labels')\n",
    "        eval_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset.rename_column_('label', 'labels')\n",
    "        train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        if len(np.array(train_dataset['labels']).shape) > 1:\n",
    "            soft_target = True\n",
    "        \n",
    "        train_batch_size = 8\n",
    "        eval_batch_size = 32\n",
    "        num_epoch = 10\n",
    "        gradient_accumulation_steps=1\n",
    "        max_steps = int((len(train_dataset) * num_epoch / gradient_accumulation_steps) / train_batch_size)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            seed=1,\n",
    "            # adafactor=True,\n",
    "            output_dir=checkpoint,\n",
    "            overwrite_output_dir=True,\n",
    "            max_steps=max_steps,\n",
    "            save_steps=int(max_steps / 10),\n",
    "            save_total_limit=1,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            # gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "            warmup_steps=int(max_steps / 10),\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=2000,\n",
    "            logging_first_step=True,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            # run_name=checkpoint\n",
    "        )\n",
    "\n",
    "        if soft_target:\n",
    "            trainer = Trainer_w_soft_target(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                compute_metrics=compute_metrics_w_soft_target,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                data_collator=DefaultCollator(),\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "            )\n",
    "        else: \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                compute_metrics=compute_metrics,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "            )\n",
    "\n",
    "        if not eval_only:\n",
    "            trainer.train()\n",
    "        \n",
    "        trainer.compute_metrics = compute_metrics\n",
    "            \n",
    "        # test ORIG\n",
    "        trainer.eval_dataset = test_dataset\n",
    "        out = trainer.evaluate()\n",
    "        out['run'] = checkpoint\n",
    "        print('ORIG for {}\\n{}'.format(checkpoint, out))   \n",
    "        \n",
    "        results.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282163</td>\n",
       "      <td>0.938382</td>\n",
       "      <td>0.937341</td>\n",
       "      <td>0.938265</td>\n",
       "      <td>0.936529</td>\n",
       "      <td>16.9324</td>\n",
       "      <td>397.758</td>\n",
       "      <td>7.50</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.251824</td>\n",
       "      <td>0.925761</td>\n",
       "      <td>0.924765</td>\n",
       "      <td>0.924184</td>\n",
       "      <td>0.925420</td>\n",
       "      <td>17.0465</td>\n",
       "      <td>395.095</td>\n",
       "      <td>1.94</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+INV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.599298</td>\n",
       "      <td>0.943133</td>\n",
       "      <td>0.942239</td>\n",
       "      <td>0.942597</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>17.0787</td>\n",
       "      <td>394.350</td>\n",
       "      <td>9.31</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+SIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.637452</td>\n",
       "      <td>0.933482</td>\n",
       "      <td>0.932556</td>\n",
       "      <td>0.932146</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>16.9467</td>\n",
       "      <td>397.422</td>\n",
       "      <td>4.17</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+INVSIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.396307</td>\n",
       "      <td>0.947884</td>\n",
       "      <td>0.947161</td>\n",
       "      <td>0.946722</td>\n",
       "      <td>0.947636</td>\n",
       "      <td>16.9840</td>\n",
       "      <td>396.550</td>\n",
       "      <td>10.00</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+TextMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.498501</td>\n",
       "      <td>0.949963</td>\n",
       "      <td>0.949276</td>\n",
       "      <td>0.948780</td>\n",
       "      <td>0.949819</td>\n",
       "      <td>16.9856</td>\n",
       "      <td>396.512</td>\n",
       "      <td>10.00</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+SentMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.707505</td>\n",
       "      <td>0.945212</td>\n",
       "      <td>0.944412</td>\n",
       "      <td>0.944269</td>\n",
       "      <td>0.944558</td>\n",
       "      <td>16.9568</td>\n",
       "      <td>397.186</td>\n",
       "      <td>7.64</td>\n",
       "      <td>pretrained/bert-base-uncased-sst2-ORIG+WordMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.384818</td>\n",
       "      <td>0.910913</td>\n",
       "      <td>0.910330</td>\n",
       "      <td>0.909143</td>\n",
       "      <td>0.914591</td>\n",
       "      <td>16.5429</td>\n",
       "      <td>407.124</td>\n",
       "      <td>3.33</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.283746</td>\n",
       "      <td>0.908686</td>\n",
       "      <td>0.906146</td>\n",
       "      <td>0.913948</td>\n",
       "      <td>0.902003</td>\n",
       "      <td>16.4950</td>\n",
       "      <td>408.305</td>\n",
       "      <td>1.81</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+INV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.917380</td>\n",
       "      <td>0.912101</td>\n",
       "      <td>0.910557</td>\n",
       "      <td>0.911763</td>\n",
       "      <td>0.909545</td>\n",
       "      <td>16.5944</td>\n",
       "      <td>405.859</td>\n",
       "      <td>2.22</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+SIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.224684</td>\n",
       "      <td>0.916258</td>\n",
       "      <td>0.915123</td>\n",
       "      <td>0.914604</td>\n",
       "      <td>0.915702</td>\n",
       "      <td>16.5837</td>\n",
       "      <td>406.122</td>\n",
       "      <td>2.36</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+INVSIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.759658</td>\n",
       "      <td>0.947884</td>\n",
       "      <td>0.947096</td>\n",
       "      <td>0.947179</td>\n",
       "      <td>0.947014</td>\n",
       "      <td>16.5743</td>\n",
       "      <td>406.353</td>\n",
       "      <td>10.00</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+TextMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.989694</td>\n",
       "      <td>0.935857</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.934180</td>\n",
       "      <td>0.936106</td>\n",
       "      <td>16.5316</td>\n",
       "      <td>407.401</td>\n",
       "      <td>2.69</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+SentMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.043702</td>\n",
       "      <td>0.929324</td>\n",
       "      <td>0.928226</td>\n",
       "      <td>0.928488</td>\n",
       "      <td>0.927976</td>\n",
       "      <td>16.5389</td>\n",
       "      <td>407.221</td>\n",
       "      <td>1.04</td>\n",
       "      <td>pretrained/roberta-base-sst2-ORIG+WordMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.396603</td>\n",
       "      <td>0.918486</td>\n",
       "      <td>0.917204</td>\n",
       "      <td>0.917542</td>\n",
       "      <td>0.916884</td>\n",
       "      <td>26.6179</td>\n",
       "      <td>253.026</td>\n",
       "      <td>3.61</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.277662</td>\n",
       "      <td>0.909577</td>\n",
       "      <td>0.908589</td>\n",
       "      <td>0.907379</td>\n",
       "      <td>0.910365</td>\n",
       "      <td>26.4643</td>\n",
       "      <td>254.494</td>\n",
       "      <td>1.94</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+INV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.936004</td>\n",
       "      <td>0.904826</td>\n",
       "      <td>0.903241</td>\n",
       "      <td>0.903984</td>\n",
       "      <td>0.902581</td>\n",
       "      <td>26.5381</td>\n",
       "      <td>253.786</td>\n",
       "      <td>2.36</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+SIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.087074</td>\n",
       "      <td>0.923682</td>\n",
       "      <td>0.922685</td>\n",
       "      <td>0.921991</td>\n",
       "      <td>0.923493</td>\n",
       "      <td>26.6206</td>\n",
       "      <td>253.000</td>\n",
       "      <td>2.22</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+INVSIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.150676</td>\n",
       "      <td>0.951893</td>\n",
       "      <td>0.951185</td>\n",
       "      <td>0.951088</td>\n",
       "      <td>0.951284</td>\n",
       "      <td>26.6727</td>\n",
       "      <td>252.505</td>\n",
       "      <td>10.00</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+TextMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.606091</td>\n",
       "      <td>0.929176</td>\n",
       "      <td>0.927732</td>\n",
       "      <td>0.930603</td>\n",
       "      <td>0.925650</td>\n",
       "      <td>26.5740</td>\n",
       "      <td>253.443</td>\n",
       "      <td>1.76</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+SentMix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.875032</td>\n",
       "      <td>0.936600</td>\n",
       "      <td>0.935706</td>\n",
       "      <td>0.935362</td>\n",
       "      <td>0.936073</td>\n",
       "      <td>26.6857</td>\n",
       "      <td>252.383</td>\n",
       "      <td>1.53</td>\n",
       "      <td>pretrained/xlnet-base-cased-sst2-ORIG+WordMix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "0    0.282163       0.938382  0.937341        0.938265     0.936529   \n",
       "1    0.251824       0.925761  0.924765        0.924184     0.925420   \n",
       "2    3.599298       0.943133  0.942239        0.942597     0.941900   \n",
       "3    2.637452       0.933482  0.932556        0.932146     0.933000   \n",
       "4    5.396307       0.947884  0.947161        0.946722     0.947636   \n",
       "5    5.498501       0.949963  0.949276        0.948780     0.949819   \n",
       "6    4.707505       0.945212  0.944412        0.944269     0.944558   \n",
       "7    0.384818       0.910913  0.910330        0.909143     0.914591   \n",
       "8    0.283746       0.908686  0.906146        0.913948     0.902003   \n",
       "9    1.917380       0.912101  0.910557        0.911763     0.909545   \n",
       "10   2.224684       0.916258  0.915123        0.914604     0.915702   \n",
       "11   3.759658       0.947884  0.947096        0.947179     0.947014   \n",
       "12   1.989694       0.935857  0.935050        0.934180     0.936106   \n",
       "13   3.043702       0.929324  0.928226        0.928488     0.927976   \n",
       "14   0.396603       0.918486  0.917204        0.917542     0.916884   \n",
       "15   0.277662       0.909577  0.908589        0.907379     0.910365   \n",
       "16   1.936004       0.904826  0.903241        0.903984     0.902581   \n",
       "17   2.087074       0.923682  0.922685        0.921991     0.923493   \n",
       "18   4.150676       0.951893  0.951185        0.951088     0.951284   \n",
       "19   2.606091       0.929176  0.927732        0.930603     0.925650   \n",
       "20   2.875032       0.936600  0.935706        0.935362     0.936073   \n",
       "\n",
       "    eval_runtime  eval_samples_per_second  epoch  \\\n",
       "0        16.9324                  397.758   7.50   \n",
       "1        17.0465                  395.095   1.94   \n",
       "2        17.0787                  394.350   9.31   \n",
       "3        16.9467                  397.422   4.17   \n",
       "4        16.9840                  396.550  10.00   \n",
       "5        16.9856                  396.512  10.00   \n",
       "6        16.9568                  397.186   7.64   \n",
       "7        16.5429                  407.124   3.33   \n",
       "8        16.4950                  408.305   1.81   \n",
       "9        16.5944                  405.859   2.22   \n",
       "10       16.5837                  406.122   2.36   \n",
       "11       16.5743                  406.353  10.00   \n",
       "12       16.5316                  407.401   2.69   \n",
       "13       16.5389                  407.221   1.04   \n",
       "14       26.6179                  253.026   3.61   \n",
       "15       26.4643                  254.494   1.94   \n",
       "16       26.5381                  253.786   2.36   \n",
       "17       26.6206                  253.000   2.22   \n",
       "18       26.6727                  252.505  10.00   \n",
       "19       26.5740                  253.443   1.76   \n",
       "20       26.6857                  252.383   1.53   \n",
       "\n",
       "                                               run  \n",
       "0      pretrained/bert-base-uncased-sst2-ORIG+ORIG  \n",
       "1       pretrained/bert-base-uncased-sst2-ORIG+INV  \n",
       "2       pretrained/bert-base-uncased-sst2-ORIG+SIB  \n",
       "3    pretrained/bert-base-uncased-sst2-ORIG+INVSIB  \n",
       "4   pretrained/bert-base-uncased-sst2-ORIG+TextMix  \n",
       "5   pretrained/bert-base-uncased-sst2-ORIG+SentMix  \n",
       "6   pretrained/bert-base-uncased-sst2-ORIG+WordMix  \n",
       "7           pretrained/roberta-base-sst2-ORIG+ORIG  \n",
       "8            pretrained/roberta-base-sst2-ORIG+INV  \n",
       "9            pretrained/roberta-base-sst2-ORIG+SIB  \n",
       "10        pretrained/roberta-base-sst2-ORIG+INVSIB  \n",
       "11       pretrained/roberta-base-sst2-ORIG+TextMix  \n",
       "12       pretrained/roberta-base-sst2-ORIG+SentMix  \n",
       "13       pretrained/roberta-base-sst2-ORIG+WordMix  \n",
       "14      pretrained/xlnet-base-cased-sst2-ORIG+ORIG  \n",
       "15       pretrained/xlnet-base-cased-sst2-ORIG+INV  \n",
       "16       pretrained/xlnet-base-cased-sst2-ORIG+SIB  \n",
       "17    pretrained/xlnet-base-cased-sst2-ORIG+INVSIB  \n",
       "18   pretrained/xlnet-base-cased-sst2-ORIG+TextMix  \n",
       "19   pretrained/xlnet-base-cased-sst2-ORIG+SentMix  \n",
       "20   pretrained/xlnet-base-cased-sst2-ORIG+WordMix  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_SST2_r3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_SST2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00554915f7ad47b9b80d65294dbfdd37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0768ccf7a2e64f819c7401d7db258d16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14dc24ef59d341a88d1bdb69f3cacde6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "212a6447739d45b5b57e5815ff538f57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "367cfe385d38427dbdf4325a70c0dc2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46cc6e7671244f1d9167855a45a36af8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b1f7506e1a44d109d918b1f16d6bb75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5f641be531341dbb007330b7e245169",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00554915f7ad47b9b80d65294dbfdd37",
      "value": 1382015
     }
    },
    "59b96dd300ae4a56b2d58ca0de0bb7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd27134d896448b6b385ce45da7556ee",
       "IPY_MODEL_c92040617a854d8d96cc8ba678f0b271"
      ],
      "layout": "IPY_MODEL_e3c71b92f2a0484bb70123a86f855f9d"
     }
    },
    "7158ce3f315647aba9299519fcec4be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81821a97e02445539ccabcc2091cba95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b1f7506e1a44d109d918b1f16d6bb75",
       "IPY_MODEL_f177b91513ec4039bc7c6e61d15db9a2"
      ],
      "layout": "IPY_MODEL_212a6447739d45b5b57e5815ff538f57"
     }
    },
    "c92040617a854d8d96cc8ba678f0b271": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46cc6e7671244f1d9167855a45a36af8",
      "placeholder": "​",
      "style": "IPY_MODEL_14dc24ef59d341a88d1bdb69f3cacde6",
      "value": " 798k/798k [00:00&lt;00:00, 1.99MB/s]"
     }
    },
    "d5f641be531341dbb007330b7e245169": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd27134d896448b6b385ce45da7556ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f86a86b6b9c64cc989e89b27693d8a2f",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_367cfe385d38427dbdf4325a70c0dc2e",
      "value": 798011
     }
    },
    "e3c71b92f2a0484bb70123a86f855f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f177b91513ec4039bc7c6e61d15db9a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0768ccf7a2e64f819c7401d7db258d16",
      "placeholder": "​",
      "style": "IPY_MODEL_7158ce3f315647aba9299519fcec4be7",
      "value": " 1.38M/1.38M [00:00&lt;00:00, 5.04MB/s]"
     }
    },
    "f86a86b6b9c64cc989e89b27693d8a2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
