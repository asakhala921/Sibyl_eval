{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from RandAugment import RandAugment\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augs.mix.cutmix2 import cutmix2\n",
    "from augs.mix.mixup2 import mixup2\n",
    "from augs.mix.tile import tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_true, y_pred):\n",
    "    total = y_true.size(0)\n",
    "    correct = (y_pred == y_true).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def get_acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(module):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(module.weight.data, mode='fan_out')\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        module.weight.data.fill_(1)\n",
    "        module.bias.data.zero_()\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 remove_first_relu,\n",
    "                 add_last_bn,\n",
    "                 preact=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self._remove_first_relu = remove_first_relu\n",
    "        self._add_last_bn = add_last_bn\n",
    "        self._preact = preact\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,  # downsample with first conv\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        if add_last_bn:\n",
    "            self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut.add_module(\n",
    "                'conv',\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,  # downsample\n",
    "                    padding=0,\n",
    "                    bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self._preact:\n",
    "            x = F.relu(\n",
    "                self.bn1(x), inplace=True)  # shortcut after preactivation\n",
    "            y = self.conv1(x)\n",
    "        else:\n",
    "            # preactivation only for residual path\n",
    "            y = self.bn1(x)\n",
    "            if not self._remove_first_relu:\n",
    "                y = F.relu(y, inplace=True)\n",
    "            y = self.conv1(y)\n",
    "\n",
    "        y = F.relu(self.bn2(y), inplace=True)\n",
    "        y = self.conv2(y)\n",
    "\n",
    "        if self._add_last_bn:\n",
    "            y = self.bn3(y)\n",
    "\n",
    "        y += self.shortcut(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 remove_first_relu,\n",
    "                 add_last_bn,\n",
    "                 preact=False):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        self._remove_first_relu = remove_first_relu\n",
    "        self._add_last_bn = add_last_bn\n",
    "        self._preact = preact\n",
    "\n",
    "        bottleneck_channels = out_channels // self.expansion\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,  # downsample with 3x3 conv\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False)\n",
    "\n",
    "        if add_last_bn:\n",
    "            self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()  # identity\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut.add_module(\n",
    "                'conv',\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,  # downsample\n",
    "                    padding=0,\n",
    "                    bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self._preact:\n",
    "            x = F.relu(\n",
    "                self.bn1(x), inplace=True)  # shortcut after preactivation\n",
    "            y = self.conv1(x)\n",
    "        else:\n",
    "            # preactivation only for residual path\n",
    "            y = self.bn1(x)\n",
    "            if not self._remove_first_relu:\n",
    "                y = F.relu(y, inplace=True)\n",
    "            y = self.conv1(y)\n",
    "\n",
    "        y = F.relu(self.bn2(y), inplace=True)\n",
    "        y = self.conv2(y)\n",
    "        y = F.relu(self.bn3(y), inplace=True)\n",
    "        y = self.conv3(y)\n",
    "\n",
    "        if self._add_last_bn:\n",
    "            y = self.bn4(y)\n",
    "\n",
    "        y += self.shortcut(x)\n",
    "        return y\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        input_shape = config['input_shape']\n",
    "        n_classes = config['n_classes']\n",
    "\n",
    "        base_channels = config['base_channels']\n",
    "        self._remove_first_relu = False\n",
    "        self._add_last_bn = False\n",
    "        block_type = config['block_type']\n",
    "        depth = config['depth']\n",
    "        preact_stage = [True, True, True]\n",
    "\n",
    "        assert block_type in ['basic', 'bottleneck']\n",
    "        if block_type == 'basic':\n",
    "            block = BasicBlock\n",
    "            n_blocks_per_stage = (depth - 2) // 6\n",
    "            assert n_blocks_per_stage * 6 + 2 == depth\n",
    "        else:\n",
    "            block = BottleneckBlock\n",
    "            n_blocks_per_stage = (depth - 2) // 9\n",
    "            assert n_blocks_per_stage * 9 + 2 == depth\n",
    "\n",
    "        n_channels = [\n",
    "            base_channels,\n",
    "            base_channels * 2 * block.expansion,\n",
    "            base_channels * 4 * block.expansion,\n",
    "        ]\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            input_shape[1],\n",
    "            n_channels[0],\n",
    "            kernel_size=(3, 3),\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "        self.stage1 = self._make_stage(\n",
    "            n_channels[0],\n",
    "            n_channels[0],\n",
    "            n_blocks_per_stage,\n",
    "            block,\n",
    "            stride=1,\n",
    "            preact=preact_stage[0])\n",
    "        self.stage2 = self._make_stage(\n",
    "            n_channels[0],\n",
    "            n_channels[1],\n",
    "            n_blocks_per_stage,\n",
    "            block,\n",
    "            stride=2,\n",
    "            preact=preact_stage[1])\n",
    "        self.stage3 = self._make_stage(\n",
    "            n_channels[1],\n",
    "            n_channels[2],\n",
    "            n_blocks_per_stage,\n",
    "            block,\n",
    "            stride=2,\n",
    "            preact=preact_stage[2])\n",
    "        self.bn = nn.BatchNorm2d(n_channels[2])\n",
    "\n",
    "        # compute conv feature size\n",
    "        with torch.no_grad():\n",
    "            self.feature_size = self._forward_conv(\n",
    "                torch.zeros(*input_shape)).view(-1).shape[0]\n",
    "\n",
    "        self.fc = nn.Linear(self.feature_size, n_classes)\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(initialize_weights)\n",
    "\n",
    "    def _make_stage(self, in_channels, out_channels, n_blocks, block, stride,\n",
    "                    preact):\n",
    "        stage = nn.Sequential()\n",
    "        for index in range(n_blocks):\n",
    "            block_name = 'block{}'.format(index + 1)\n",
    "            if index == 0:\n",
    "                stage.add_module(\n",
    "                    block_name,\n",
    "                    block(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        stride=stride,\n",
    "                        remove_first_relu=self._remove_first_relu,\n",
    "                        add_last_bn=self._add_last_bn,\n",
    "                        preact=preact))\n",
    "            else:\n",
    "                stage.add_module(\n",
    "                    block_name,\n",
    "                    block(\n",
    "                        out_channels,\n",
    "                        out_channels,\n",
    "                        stride=1,\n",
    "                        remove_first_relu=self._remove_first_relu,\n",
    "                        add_last_bn=self._add_last_bn,\n",
    "                        preact=False))\n",
    "        return stage\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = F.relu(\n",
    "            self.bn(x),\n",
    "            inplace=True)  # apply BN and ReLU before average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(model, X, batch_size=8):\n",
    "    out = []\n",
    "    for pos in range(0, len(X), batch_size):\n",
    "        X_ = X[pos:pos + batch_size] \n",
    "        logits = model(X_)\n",
    "        out.append(logits)\n",
    "    return torch.cat(out).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(config):\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    if config['use_basicaug']:\n",
    "        test_transform.transforms.insert(0, transforms.RandomHorizontalFlip())\n",
    "        test_transform.transforms.insert(0, transforms.RandomCrop(32, padding=4))\n",
    "\n",
    "    if config['use_randaug']:\n",
    "        n = config['randaug_n']\n",
    "        m = config['randaug_m']\n",
    "        test_transform.transforms.insert(0, RandAugment(n=2, m=3))\n",
    "\n",
    "    if config['dataset'] == 'CIFAR10':\n",
    "        dataset_dir = 'C:/data/CIFAR10'\n",
    "        _MEAN, _STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "        test_transform.transforms.insert(\n",
    "            len(test_transform.transforms), transforms.Normalize(_MEAN, _STD))\n",
    "        test_dataset = torchvision.datasets.CIFAR10(\n",
    "            dataset_dir, train=False, transform=test_transform, download=True)\n",
    "    elif config['dataset'] == 'MNIST':\n",
    "        dataset_dir = 'C:/data/MNIST'\n",
    "        _MEAN, _STD = (0.1307,), (0.3081,)\n",
    "        test_transform.transforms.insert(\n",
    "            len(test_transform.transforms), transforms.Normalize(_MEAN, _STD))\n",
    "        test_dataset = torchvision.datasets.MNIST(\n",
    "            dataset_dir, train=False, transform=test_transform, download=True)\n",
    "    else:\n",
    "        raise InputError(\"dataset not supported...\")\n",
    "\n",
    "    collator = torch.utils.data.dataloader.default_collate\n",
    "    \n",
    "    if config['use_mixup2']:\n",
    "        collator = mixup2.Mixup2Collator(\n",
    "            alpha=config['alpha'],  \n",
    "            target_pairs=config['target_pairs'], \n",
    "            target_prob=config['target_prob'], \n",
    "            num_classes=config['n_classes']\n",
    "        )\n",
    "    if config['use_cutmix2']:\n",
    "        collator = cutmix2.CutMix2Collator(\n",
    "            alpha=config['alpha'],  \n",
    "            target_pairs=config['target_pairs'], \n",
    "            target_prob=config['target_prob'], \n",
    "            resize_prob=config['resize_prob'], \n",
    "            num_classes=config['n_classes']\n",
    "        )\n",
    "    if config['use_tile']:\n",
    "        collator = tile.TileCollator(\n",
    "            num_tiles=config['num_tiles'],  \n",
    "            target_pairs=config['target_pairs'], \n",
    "            target_prob=config['target_prob'], \n",
    "            num_classes=config['n_classes']\n",
    "        )\n",
    "                \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        num_workers=config['num_workers'],\n",
    "        collate_fn=collator,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from torch.nn.functional import interpolate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\AppData\\Local\\Continuum\\anaconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\functional.py:3454: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_examples = 100\n",
    "\n",
    "new_size = (500, 500)\n",
    "\n",
    "class_names = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "\n",
    "for d in [\"MNIST\"]:                      \n",
    "    for t in ['ORIG', 'INV', 'Mixup2', 'Cutmix', 'Cutmix2', 'Tile']:\n",
    "        config = {\n",
    "            'dataset': d,\n",
    "            'batch_size': 100,\n",
    "            'num_workers': 2,\n",
    "            'use_basicaug': t == 'INV' and d == 'MNIST',\n",
    "            'use_randaug': t == 'INV' and d != 'MNIST',\n",
    "            'use_mixup2': t == 'Mixup2',\n",
    "            'use_cutmix2': 'Cutmix' in t,\n",
    "            'use_tile': t == 'Tile',\n",
    "            'randaug_n': 2,\n",
    "            'randaug_m': 3,\n",
    "            'alpha': 1.0,\n",
    "            'target_pairs': [],\n",
    "            'target_prob': 1.0,\n",
    "            'resize_prob': 1.0 if t == 'Cutmix2' else 0,\n",
    "            'n_classes': 10,\n",
    "            'num_tiles': 4,\n",
    "        }\n",
    "        \n",
    "        dataloader = get_dataloader(config)\n",
    "        \n",
    "        img_dir = \"imgs/MNIST/\" + t\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        \n",
    "        out = []\n",
    "        for i in range(num_examples):\n",
    "            X, y_true = next(iter(dataloader))\n",
    "            for x, y in zip(X, y_true):\n",
    "                img_name = os.path.join(img_dir, 'img_' + str(i) + '.png')\n",
    "                out.append({\n",
    "                    'img_name': img_name,\n",
    "                    'label': y.numpy().tolist(),\n",
    "                })\n",
    "                x = interpolate(x.unsqueeze(0), new_size, mode='bilinear')\n",
    "                save_image(x, img_name)\n",
    "                break\n",
    "\n",
    "        df = pd.DataFrame(out)\n",
    "        csv_name = os.path.join(img_dir, t + '_input_label_pairs.csv')\n",
    "        df.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_models = glob('augs/mix/*/*/*/*/*/*.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b07c2b619b409abe4f2b0d511cd5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'MODEL_NAME': 'PreAct ResNet', 'model_path': 'augs/mix\\\\cutmix2\\\\results\\\\MNIST\\\\cutmix2\\\\t0.0_r0.0\\\\model_state.pth', 'dataset': 'MNIST', 'trans': 'Cutmix', 'test_acc': 0.6752114106714725}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65d655e11644bbab333417c2b440c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'MODEL_NAME': 'PreAct ResNet', 'model_path': 'augs/mix\\\\mixup2\\\\results\\\\MNIST\\\\mixup2\\\\t0.0\\\\model_state.pth', 'dataset': 'MNIST', 'trans': 'Cutmix', 'test_acc': 0.6067962106317282}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330316c2ff134ec387760447ca0a34b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'MODEL_NAME': 'PreAct ResNet', 'model_path': 'augs/mix\\\\tile\\\\results\\\\MNIST\\\\tile\\\\t0.0_n4\\\\model_state.pth', 'dataset': 'MNIST', 'trans': 'Cutmix', 'test_acc': 0.5568723197281361}\n"
     ]
    }
   ],
   "source": [
    "num_suites = 100\n",
    "num_tests = 100\n",
    "\n",
    "datasets = ['MNIST']\n",
    "trans = ['ORIG', 'INV', 'Mixup2', 'Cutmix', 'Cutmix2', 'Tile']\n",
    "model_paths = [\n",
    "    'augs/mix\\\\cutmix2\\\\results\\\\MNIST\\\\cutmix2\\\\t0.0_r0.0\\\\model_state.pth',\n",
    "    'augs/mix\\\\mixup2\\\\results\\\\MNIST\\\\mixup2\\\\t0.0\\\\model_state.pth',\n",
    "    'augs/mix\\\\tile\\\\results\\\\MNIST\\\\tile\\\\t0.0_n4\\\\model_state.pth',\n",
    "]\n",
    "\n",
    "results = []\n",
    "for model_path in model_paths:\n",
    "    \n",
    "    model = Network({\n",
    "        'block_type': 'basic',\n",
    "        'depth': 20,\n",
    "        'base_channels': 64,\n",
    "        'input_shape': [1,1,28,28],\n",
    "        'n_classes': 10}).to(device)\n",
    "    model.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "    \n",
    "    for t in trans:\n",
    "    \n",
    "        for d in datasets:\n",
    "\n",
    "            config = {\n",
    "                    'dataset': d,\n",
    "                    'batch_size': num_tests,\n",
    "                    'num_workers': 2,\n",
    "                    'use_basicaug': t == 'INV' and d == 'MNIST',\n",
    "                    'use_randaug': t == 'INV' and d != 'MNIST',\n",
    "                    'use_mixup2': t == 'Mixup2',\n",
    "                    'use_cutmix2': 'Cutmix' in t,\n",
    "                    'use_tile': t == 'Tile',\n",
    "                    'randaug_n': 2,\n",
    "                    'randaug_m': 3,\n",
    "                    'alpha': 1.0,\n",
    "                    'target_pairs': [],\n",
    "                    'target_prob': 1.0,\n",
    "                    'resize_prob': 1.0 if t == 'Cutmix2' else 0,\n",
    "                    'n_classes': 10,\n",
    "                    'num_tiles': 4,\n",
    "                }\n",
    "\n",
    "            dataloader = get_dataloader(config)\n",
    "            is_soft_label = False\n",
    "            if t not in ['ORIG', 'INV']:\n",
    "                is_soft_label = True\n",
    "\n",
    "            accs = []\n",
    "            for _ in tqdm(range(num_suites)):\n",
    "\n",
    "                    X, y_true = next(iter(dataloader))\n",
    "\n",
    "                    logits = get_logits(model, X.to(device), batch_size=8)\n",
    "\n",
    "                    if is_soft_label:\n",
    "                        acc = get_acc_at_k(y_true, logits, k=2)\n",
    "                    else:\n",
    "                        y_pred = logits.argmax(-1)\n",
    "                        acc = get_acc(y_true, y_pred)\n",
    "\n",
    "                    # print(acc)\n",
    "\n",
    "                    accs.append(acc)\n",
    "\n",
    "            test_acc = sum(accs) / len(accs)\n",
    "\n",
    "            out = {\n",
    "                \"MODEL_NAME\": 'PreAct ResNet',\n",
    "                \"model_path\": model_path,\n",
    "                \"dataset\": d,\n",
    "                'trans': t,\n",
    "                \"test_acc\": test_acc\n",
    "            }\n",
    "\n",
    "            print(out)\n",
    "            results.append(out)\n",
    "        \n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_models_mnist_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values_on_bars(axs, values, y_height_addon=0):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p, v in zip(ax.patches, values):\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height() + y_height_addon\n",
    "            if type(v) != str:\n",
    "                value = (\"+\" if v > 0 else \"\") + '{:.0f}%'.format(v)\n",
    "            else:\n",
    "                value = v\n",
    "            ax.text(_x, _y, value, ha=\"center\", size='small') \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790000000000001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in ['MNIST']: \n",
    "    \n",
    "    df = pd.read_csv('test_models_mnist_results.csv')\n",
    "    \n",
    "    ds = (df['dataset']==d)\n",
    "    \n",
    "    df = df[ds]\n",
    "    \n",
    "    ORIG_acc = df[(df['trans']=='ORIG')]['test_acc'].iloc[0]\n",
    "    print(ORIG_acc)\n",
    "    df['improv'] = (df['test_acc'] - ORIG_acc) * 100\n",
    "    \n",
    "    g = sns.barplot(data=df[df.dataset.str.contains(d)], x='trans', y='test_acc', palette='Spectral')\n",
    "    g.set_xlabel('Transformation Pipeline $TP$')\n",
    "    g.set_ylabel('Accuracy')\n",
    "    g.set_ylim((0.3, 1.00))\n",
    "    # g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "    g.set_title('Test Accuracy | ' +  d)\n",
    "    values = df.improv.tolist()\n",
    "    values[0] = \"\"\n",
    "    show_values_on_bars(g, values, 0.075)\n",
    "    g.figure.savefig('imgs/test_acc_' + d)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
