{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted SIB Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    TrainerCallback, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers.trainer_callback import TrainerControl\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transforms import TextMix, SentMix, WordMix\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(text):\n",
    "    return tokenizer(text, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=250)\n",
    "\n",
    "def acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()\n",
    "\n",
    "def CEwST_loss(logits, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Cross Entropy with Soft Target (CEwST) Loss\n",
    "    :param logits: (batch, *)\n",
    "    :param target: (batch, *) same shape as logits, each item must be a valid distribution: target[i, :].sum() == 1.\n",
    "    \"\"\"\n",
    "    logprobs = torch.nn.functional.log_softmax(logits.view(logits.shape[0], -1), dim=1)\n",
    "    batchloss = - torch.sum(target.view(target.shape[0], -1) * logprobs, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return batchloss\n",
    "    elif reduction == 'mean':\n",
    "        return torch.mean(batchloss)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(batchloss)\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported reduction mode.')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1.mean(),\n",
    "        'precision': precision.mean(),\n",
    "        'recall': recall.mean()\n",
    "    }        \n",
    "        \n",
    "def compute_metrics_w_soft_target(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    acc = acc_at_k(labels, preds, k=2)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }\n",
    "\n",
    "class TargetedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = CEwST_loss(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "class TargetedMixturesCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A callback that calculates a confusion matrix on the validation\n",
    "    data and returns the most confused class pairings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, model, tokenizer, **kwargs):\n",
    "        cnf_mat = self.get_confusion_matrix(model, tokenizer, self.dataloader)\n",
    "        new_targets = self.get_most_confused_per_class(cnf_mat)\n",
    "        print(\"New targets:\", new_targets)\n",
    "        control = TrainerControl\n",
    "        control.new_targets = new_targets\n",
    "        if state.global_step < state.max_steps:\n",
    "            control.should_training_stop = False\n",
    "        else:\n",
    "            control.should_training_stop = True\n",
    "        return control\n",
    "        \n",
    "    def get_confusion_matrix(self, model, tokenizer, dataloader, normalize=True):\n",
    "        n_classes = max(dataloader.dataset['label']) + 1\n",
    "        confusion_matrix = torch.zeros(n_classes, n_classes)\n",
    "        with torch.no_grad():\n",
    "            for batch in iter(self.dataloader):\n",
    "                data, targets = batch['text'], batch['label']\n",
    "                data = tokenizer(data, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "                input_ids = data['input_ids'].to(self.device)\n",
    "                attention_mask = data['attention_mask'].to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = model(input_ids, attention_mask=attention_mask).logits\n",
    "                preds = torch.argmax(outputs, dim=1).cpu()\n",
    "                for t, p in zip(targets.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1    \n",
    "            if normalize:\n",
    "                confusion_matrix = confusion_matrix / confusion_matrix.sum(dim=0)\n",
    "        return confusion_matrix\n",
    "\n",
    "    def get_most_confused_per_class(self, confusion_matrix):\n",
    "        idx = torch.arange(len(confusion_matrix))\n",
    "        cnf = confusion_matrix.fill_diagonal_(0).max(dim=1)[1]\n",
    "        return torch.stack((idx, cnf)).T.tolist()\n",
    "\n",
    "class TargetedMixturesCollator:\n",
    "    def __init__(self, tokenize_fn, transform, target_pairs=[], target_prob=1.0, num_classes=2):\n",
    "        self.tokenize_fn = tokenize_fn\n",
    "        self.transform = transform\n",
    "        self.target_pairs = target_pairs\n",
    "        self.target_prob = target_prob\n",
    "        self.num_classes = num_classes\n",
    "        print(\"TargetedMixturesCollator initialized with {}\".format(transform.__class__.__name__))\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        text = [x['text'] for x in batch]\n",
    "        labels = [x['label'] for x in batch]\n",
    "        batch = (text, labels)\n",
    "        batch = self.transform(\n",
    "            batch, \n",
    "            self.target_pairs,   \n",
    "            self.target_prob,\n",
    "            self.num_classes\n",
    "        )\n",
    "        text, labels = batch\n",
    "        batch = self.tokenize_fn(text)\n",
    "        batch['labels'] = torch.tensor(labels)\n",
    "        return batch\n",
    "    \n",
    "class DefaultCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']\n",
    "ts = [TextMix(), SentMix(), WordMix()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "<ipython-input-5-ecc9b90abdcd>:13: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use Dataset.rename_column instead.\n",
      "  dataset.rename_column_('sentence', 'text')\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bee6553c9cc47a593017a7d340d82fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='128000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [128000/143957 3:31:17 < 26:20, 10.10 it/s, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.578551</td>\n",
       "      <td>0.765754</td>\n",
       "      <td>7.685700</td>\n",
       "      <td>394.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.842296</td>\n",
       "      <td>7.715300</td>\n",
       "      <td>392.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>0.454919</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>7.777400</td>\n",
       "      <td>389.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.502953</td>\n",
       "      <td>0.872649</td>\n",
       "      <td>7.494100</td>\n",
       "      <td>404.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.901023</td>\n",
       "      <td>7.601800</td>\n",
       "      <td>398.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.425973</td>\n",
       "      <td>0.894754</td>\n",
       "      <td>7.621100</td>\n",
       "      <td>397.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.398105</td>\n",
       "      <td>0.903992</td>\n",
       "      <td>7.580700</td>\n",
       "      <td>399.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.905312</td>\n",
       "      <td>7.744300</td>\n",
       "      <td>391.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.421396</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>7.424700</td>\n",
       "      <td>408.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.399580</td>\n",
       "      <td>0.892445</td>\n",
       "      <td>7.685600</td>\n",
       "      <td>394.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.415062</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>7.576500</td>\n",
       "      <td>400.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.392137</td>\n",
       "      <td>0.917849</td>\n",
       "      <td>7.758700</td>\n",
       "      <td>390.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>0.432366</td>\n",
       "      <td>0.880897</td>\n",
       "      <td>7.679100</td>\n",
       "      <td>394.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>0.387717</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>7.780400</td>\n",
       "      <td>389.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.407044</td>\n",
       "      <td>0.921808</td>\n",
       "      <td>7.545300</td>\n",
       "      <td>401.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.399084</td>\n",
       "      <td>0.916529</td>\n",
       "      <td>7.714100</td>\n",
       "      <td>392.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.389744</td>\n",
       "      <td>0.908281</td>\n",
       "      <td>7.576500</td>\n",
       "      <td>400.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.394079</td>\n",
       "      <td>0.915539</td>\n",
       "      <td>7.627000</td>\n",
       "      <td>397.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.410656</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>7.527100</td>\n",
       "      <td>402.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.327900</td>\n",
       "      <td>0.406461</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>7.525500</td>\n",
       "      <td>402.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.390806</td>\n",
       "      <td>0.925767</td>\n",
       "      <td>7.557200</td>\n",
       "      <td>401.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.406810</td>\n",
       "      <td>0.921808</td>\n",
       "      <td>7.550500</td>\n",
       "      <td>401.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.410181</td>\n",
       "      <td>0.934675</td>\n",
       "      <td>7.675800</td>\n",
       "      <td>394.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.409009</td>\n",
       "      <td>0.925107</td>\n",
       "      <td>7.548600</td>\n",
       "      <td>401.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.404386</td>\n",
       "      <td>0.926427</td>\n",
       "      <td>7.651500</td>\n",
       "      <td>396.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.404011</td>\n",
       "      <td>0.931376</td>\n",
       "      <td>7.648600</td>\n",
       "      <td>396.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.441299</td>\n",
       "      <td>0.930056</td>\n",
       "      <td>7.534200</td>\n",
       "      <td>402.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.376860</td>\n",
       "      <td>0.936984</td>\n",
       "      <td>7.657500</td>\n",
       "      <td>395.821000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.398768</td>\n",
       "      <td>0.935665</td>\n",
       "      <td>7.717300</td>\n",
       "      <td>392.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.400456</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>7.545400</td>\n",
       "      <td>401.703000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.392798</td>\n",
       "      <td>0.940944</td>\n",
       "      <td>7.689100</td>\n",
       "      <td>394.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.393979</td>\n",
       "      <td>0.937314</td>\n",
       "      <td>7.411800</td>\n",
       "      <td>408.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.410403</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>7.526400</td>\n",
       "      <td>402.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.429274</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>7.461300</td>\n",
       "      <td>406.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.417957</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>7.497000</td>\n",
       "      <td>404.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.399407</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>7.755400</td>\n",
       "      <td>390.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.399198</td>\n",
       "      <td>0.931046</td>\n",
       "      <td>7.538400</td>\n",
       "      <td>402.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.387553</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>7.655800</td>\n",
       "      <td>395.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.410587</td>\n",
       "      <td>0.941603</td>\n",
       "      <td>7.751400</td>\n",
       "      <td>391.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>0.387127</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>7.701900</td>\n",
       "      <td>393.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.427982</td>\n",
       "      <td>0.942593</td>\n",
       "      <td>7.713100</td>\n",
       "      <td>392.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.421206</td>\n",
       "      <td>0.937315</td>\n",
       "      <td>7.633700</td>\n",
       "      <td>397.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.423596</td>\n",
       "      <td>0.941933</td>\n",
       "      <td>7.611600</td>\n",
       "      <td>398.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.412345</td>\n",
       "      <td>0.944573</td>\n",
       "      <td>7.623000</td>\n",
       "      <td>397.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.391449</td>\n",
       "      <td>0.945233</td>\n",
       "      <td>7.643200</td>\n",
       "      <td>396.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.286400</td>\n",
       "      <td>0.417055</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>7.670300</td>\n",
       "      <td>395.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.419654</td>\n",
       "      <td>0.929726</td>\n",
       "      <td>7.732100</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>0.423135</td>\n",
       "      <td>0.938634</td>\n",
       "      <td>7.454800</td>\n",
       "      <td>406.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.406086</td>\n",
       "      <td>0.944573</td>\n",
       "      <td>7.593500</td>\n",
       "      <td>399.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.398894</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>7.554400</td>\n",
       "      <td>401.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.411019</td>\n",
       "      <td>0.946552</td>\n",
       "      <td>7.682700</td>\n",
       "      <td>394.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.427052</td>\n",
       "      <td>0.941604</td>\n",
       "      <td>7.635200</td>\n",
       "      <td>396.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.276600</td>\n",
       "      <td>0.396414</td>\n",
       "      <td>0.951501</td>\n",
       "      <td>7.510500</td>\n",
       "      <td>403.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.953151</td>\n",
       "      <td>7.465400</td>\n",
       "      <td>406.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.422396</td>\n",
       "      <td>0.947542</td>\n",
       "      <td>7.545500</td>\n",
       "      <td>401.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.400256</td>\n",
       "      <td>0.946552</td>\n",
       "      <td>7.665800</td>\n",
       "      <td>395.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.426559</td>\n",
       "      <td>0.948532</td>\n",
       "      <td>7.618700</td>\n",
       "      <td>397.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.409317</td>\n",
       "      <td>0.945562</td>\n",
       "      <td>7.463400</td>\n",
       "      <td>406.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.429210</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>7.596800</td>\n",
       "      <td>398.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>7.579500</td>\n",
       "      <td>399.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.412866</td>\n",
       "      <td>0.946882</td>\n",
       "      <td>7.584300</td>\n",
       "      <td>399.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.440438</td>\n",
       "      <td>0.942593</td>\n",
       "      <td>7.664300</td>\n",
       "      <td>395.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.267300</td>\n",
       "      <td>0.420025</td>\n",
       "      <td>0.951831</td>\n",
       "      <td>7.714900</td>\n",
       "      <td>392.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.435709</td>\n",
       "      <td>0.941274</td>\n",
       "      <td>7.637100</td>\n",
       "      <td>396.876000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n",
      "ORIG for ./results/bert-base-uncased-targeted-TextMix\n",
      "{'eval_loss': 3.8884871006011963, 'eval_accuracy': 0.9392724573125464, 'eval_f1': 0.9382225675862759, 'eval_precision': 0.9393564136059972, 'eval_recall': 0.9372503844920124, 'eval_runtime': 17.6167, 'eval_samples_per_second': 382.307, 'epoch': 17.78, 'run': './results/bert-base-uncased-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee77e0f16194ab099ba2e194135779c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='114000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114000/143957 3:07:22 < 49:14, 10.14 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.581104</td>\n",
       "      <td>0.774662</td>\n",
       "      <td>7.672000</td>\n",
       "      <td>395.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.430262</td>\n",
       "      <td>0.830419</td>\n",
       "      <td>7.828800</td>\n",
       "      <td>387.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.428839</td>\n",
       "      <td>0.874299</td>\n",
       "      <td>7.961000</td>\n",
       "      <td>380.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.446683</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>7.777600</td>\n",
       "      <td>389.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>0.439805</td>\n",
       "      <td>0.872319</td>\n",
       "      <td>7.783600</td>\n",
       "      <td>389.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.404043</td>\n",
       "      <td>0.895084</td>\n",
       "      <td>7.671800</td>\n",
       "      <td>395.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.397630</td>\n",
       "      <td>0.872649</td>\n",
       "      <td>7.718700</td>\n",
       "      <td>392.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.413653</td>\n",
       "      <td>0.906632</td>\n",
       "      <td>7.968700</td>\n",
       "      <td>380.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.406766</td>\n",
       "      <td>0.904652</td>\n",
       "      <td>7.771500</td>\n",
       "      <td>390.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>0.388488</td>\n",
       "      <td>0.902672</td>\n",
       "      <td>7.925100</td>\n",
       "      <td>382.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.417808</td>\n",
       "      <td>0.901353</td>\n",
       "      <td>7.798500</td>\n",
       "      <td>388.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.415157</td>\n",
       "      <td>0.885846</td>\n",
       "      <td>7.717800</td>\n",
       "      <td>392.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.398676</td>\n",
       "      <td>0.916859</td>\n",
       "      <td>7.640000</td>\n",
       "      <td>396.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>0.400823</td>\n",
       "      <td>0.908941</td>\n",
       "      <td>7.799200</td>\n",
       "      <td>388.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.410021</td>\n",
       "      <td>0.917519</td>\n",
       "      <td>7.770200</td>\n",
       "      <td>390.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.342300</td>\n",
       "      <td>0.411805</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>7.862100</td>\n",
       "      <td>385.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.418312</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>7.826700</td>\n",
       "      <td>387.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.396713</td>\n",
       "      <td>0.908611</td>\n",
       "      <td>7.865700</td>\n",
       "      <td>385.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.399253</td>\n",
       "      <td>0.923128</td>\n",
       "      <td>7.804000</td>\n",
       "      <td>388.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.411706</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>7.847100</td>\n",
       "      <td>386.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.387856</td>\n",
       "      <td>0.930386</td>\n",
       "      <td>7.727800</td>\n",
       "      <td>392.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>0.423569</td>\n",
       "      <td>0.911910</td>\n",
       "      <td>7.789400</td>\n",
       "      <td>389.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.397721</td>\n",
       "      <td>0.925767</td>\n",
       "      <td>7.976900</td>\n",
       "      <td>379.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.402070</td>\n",
       "      <td>0.932036</td>\n",
       "      <td>7.863200</td>\n",
       "      <td>385.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.925767</td>\n",
       "      <td>7.801300</td>\n",
       "      <td>388.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.928736</td>\n",
       "      <td>7.752100</td>\n",
       "      <td>390.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.420814</td>\n",
       "      <td>0.927417</td>\n",
       "      <td>7.759400</td>\n",
       "      <td>390.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.405230</td>\n",
       "      <td>0.932366</td>\n",
       "      <td>7.895200</td>\n",
       "      <td>383.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.407919</td>\n",
       "      <td>0.921808</td>\n",
       "      <td>7.798800</td>\n",
       "      <td>388.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.415187</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>7.603100</td>\n",
       "      <td>398.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.314800</td>\n",
       "      <td>0.403604</td>\n",
       "      <td>0.935335</td>\n",
       "      <td>7.850200</td>\n",
       "      <td>386.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.423052</td>\n",
       "      <td>0.924777</td>\n",
       "      <td>7.893900</td>\n",
       "      <td>383.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.403752</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>7.821900</td>\n",
       "      <td>387.503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.302600</td>\n",
       "      <td>0.422410</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>7.687500</td>\n",
       "      <td>394.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.410138</td>\n",
       "      <td>0.930716</td>\n",
       "      <td>7.764800</td>\n",
       "      <td>390.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.416749</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>7.737900</td>\n",
       "      <td>391.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>0.402965</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>7.668700</td>\n",
       "      <td>395.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>0.927417</td>\n",
       "      <td>7.825800</td>\n",
       "      <td>387.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.397602</td>\n",
       "      <td>0.915209</td>\n",
       "      <td>7.773700</td>\n",
       "      <td>389.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.408803</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>7.862400</td>\n",
       "      <td>385.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.438173</td>\n",
       "      <td>0.934015</td>\n",
       "      <td>7.713500</td>\n",
       "      <td>392.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.405137</td>\n",
       "      <td>0.939294</td>\n",
       "      <td>7.722800</td>\n",
       "      <td>392.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.422482</td>\n",
       "      <td>0.934675</td>\n",
       "      <td>7.794700</td>\n",
       "      <td>388.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.429620</td>\n",
       "      <td>0.936984</td>\n",
       "      <td>7.835400</td>\n",
       "      <td>386.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.413768</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>8.009000</td>\n",
       "      <td>378.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.419055</td>\n",
       "      <td>0.934345</td>\n",
       "      <td>7.939200</td>\n",
       "      <td>381.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.394270</td>\n",
       "      <td>0.944903</td>\n",
       "      <td>7.848100</td>\n",
       "      <td>386.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>0.420490</td>\n",
       "      <td>0.931706</td>\n",
       "      <td>7.787900</td>\n",
       "      <td>389.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.405735</td>\n",
       "      <td>0.938634</td>\n",
       "      <td>7.638700</td>\n",
       "      <td>396.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.435795</td>\n",
       "      <td>0.938634</td>\n",
       "      <td>7.810500</td>\n",
       "      <td>388.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.436707</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>7.806600</td>\n",
       "      <td>388.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.432293</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>7.796600</td>\n",
       "      <td>388.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.443054</td>\n",
       "      <td>0.939294</td>\n",
       "      <td>7.937800</td>\n",
       "      <td>381.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.414012</td>\n",
       "      <td>0.944573</td>\n",
       "      <td>7.719800</td>\n",
       "      <td>392.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.444125</td>\n",
       "      <td>0.934675</td>\n",
       "      <td>7.692200</td>\n",
       "      <td>394.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.434415</td>\n",
       "      <td>0.935335</td>\n",
       "      <td>7.815700</td>\n",
       "      <td>387.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.273900</td>\n",
       "      <td>0.432153</td>\n",
       "      <td>0.939624</td>\n",
       "      <td>7.842100</td>\n",
       "      <td>386.503000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n",
      "ORIG for ./results/bert-base-uncased-targeted-SentMix\n",
      "{'eval_loss': 3.712137460708618, 'eval_accuracy': 0.9376391982182628, 'eval_f1': 0.9366704266945021, 'eval_precision': 0.9369365518694865, 'eval_recall': 0.9364153494652911, 'eval_runtime': 16.9257, 'eval_samples_per_second': 397.916, 'epoch': 15.84, 'run': './results/bert-base-uncased-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bebe7aac3042e384071f75ee5c8d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='114000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114000/143957 3:09:41 < 49:50, 10.02 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.673900</td>\n",
       "      <td>0.631729</td>\n",
       "      <td>0.653250</td>\n",
       "      <td>7.731200</td>\n",
       "      <td>392.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.517900</td>\n",
       "      <td>0.535726</td>\n",
       "      <td>0.769053</td>\n",
       "      <td>7.825700</td>\n",
       "      <td>387.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.481833</td>\n",
       "      <td>0.791818</td>\n",
       "      <td>7.704800</td>\n",
       "      <td>393.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.507732</td>\n",
       "      <td>0.788849</td>\n",
       "      <td>7.756000</td>\n",
       "      <td>390.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.477258</td>\n",
       "      <td>0.806005</td>\n",
       "      <td>7.726600</td>\n",
       "      <td>392.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.464450</td>\n",
       "      <td>0.815902</td>\n",
       "      <td>7.821000</td>\n",
       "      <td>387.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>0.477520</td>\n",
       "      <td>0.808974</td>\n",
       "      <td>7.944800</td>\n",
       "      <td>381.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.476921</td>\n",
       "      <td>0.817882</td>\n",
       "      <td>7.696200</td>\n",
       "      <td>393.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>0.482498</td>\n",
       "      <td>0.818542</td>\n",
       "      <td>7.718900</td>\n",
       "      <td>392.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.467404</td>\n",
       "      <td>0.816232</td>\n",
       "      <td>7.728300</td>\n",
       "      <td>392.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.464790</td>\n",
       "      <td>0.838007</td>\n",
       "      <td>7.674600</td>\n",
       "      <td>394.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.469092</td>\n",
       "      <td>0.823821</td>\n",
       "      <td>8.093000</td>\n",
       "      <td>374.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.497965</td>\n",
       "      <td>0.827780</td>\n",
       "      <td>7.929800</td>\n",
       "      <td>382.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.442156</td>\n",
       "      <td>0.845596</td>\n",
       "      <td>7.628200</td>\n",
       "      <td>397.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.459771</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>7.795100</td>\n",
       "      <td>388.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.465007</td>\n",
       "      <td>0.833058</td>\n",
       "      <td>7.803200</td>\n",
       "      <td>388.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>0.443648</td>\n",
       "      <td>0.850214</td>\n",
       "      <td>7.685100</td>\n",
       "      <td>394.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.432167</td>\n",
       "      <td>0.853184</td>\n",
       "      <td>7.749000</td>\n",
       "      <td>391.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.437454</td>\n",
       "      <td>0.855493</td>\n",
       "      <td>7.832300</td>\n",
       "      <td>386.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.480939</td>\n",
       "      <td>0.855823</td>\n",
       "      <td>7.864700</td>\n",
       "      <td>385.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.371400</td>\n",
       "      <td>0.435183</td>\n",
       "      <td>0.854503</td>\n",
       "      <td>7.736400</td>\n",
       "      <td>391.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>0.457201</td>\n",
       "      <td>0.866051</td>\n",
       "      <td>7.785800</td>\n",
       "      <td>389.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.356200</td>\n",
       "      <td>0.439257</td>\n",
       "      <td>0.852854</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>395.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.474622</td>\n",
       "      <td>0.854173</td>\n",
       "      <td>7.626000</td>\n",
       "      <td>397.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.454303</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>7.798100</td>\n",
       "      <td>388.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.454978</td>\n",
       "      <td>0.854833</td>\n",
       "      <td>7.654800</td>\n",
       "      <td>395.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>0.456943</td>\n",
       "      <td>0.855163</td>\n",
       "      <td>7.974800</td>\n",
       "      <td>380.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.453631</td>\n",
       "      <td>0.863741</td>\n",
       "      <td>7.816800</td>\n",
       "      <td>387.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.447215</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>7.963500</td>\n",
       "      <td>380.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.338700</td>\n",
       "      <td>0.437349</td>\n",
       "      <td>0.860442</td>\n",
       "      <td>7.878100</td>\n",
       "      <td>384.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.418967</td>\n",
       "      <td>0.870340</td>\n",
       "      <td>7.839100</td>\n",
       "      <td>386.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.438845</td>\n",
       "      <td>0.866381</td>\n",
       "      <td>7.970200</td>\n",
       "      <td>380.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.445169</td>\n",
       "      <td>0.864071</td>\n",
       "      <td>7.830600</td>\n",
       "      <td>387.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.333900</td>\n",
       "      <td>0.443146</td>\n",
       "      <td>0.864071</td>\n",
       "      <td>7.816900</td>\n",
       "      <td>387.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.332400</td>\n",
       "      <td>0.425119</td>\n",
       "      <td>0.870340</td>\n",
       "      <td>7.703900</td>\n",
       "      <td>393.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.440054</td>\n",
       "      <td>0.864731</td>\n",
       "      <td>7.848900</td>\n",
       "      <td>386.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.422064</td>\n",
       "      <td>0.876278</td>\n",
       "      <td>7.793500</td>\n",
       "      <td>388.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.441047</td>\n",
       "      <td>0.882547</td>\n",
       "      <td>8.019100</td>\n",
       "      <td>377.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>0.445363</td>\n",
       "      <td>0.867041</td>\n",
       "      <td>7.590300</td>\n",
       "      <td>399.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.430109</td>\n",
       "      <td>0.886176</td>\n",
       "      <td>7.937200</td>\n",
       "      <td>381.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.321200</td>\n",
       "      <td>0.428941</td>\n",
       "      <td>0.882877</td>\n",
       "      <td>7.699500</td>\n",
       "      <td>393.661000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.449792</td>\n",
       "      <td>0.876279</td>\n",
       "      <td>7.846800</td>\n",
       "      <td>386.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.441895</td>\n",
       "      <td>0.870340</td>\n",
       "      <td>7.640900</td>\n",
       "      <td>396.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.440240</td>\n",
       "      <td>0.876938</td>\n",
       "      <td>7.638400</td>\n",
       "      <td>396.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.445966</td>\n",
       "      <td>0.874299</td>\n",
       "      <td>7.788400</td>\n",
       "      <td>389.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.321900</td>\n",
       "      <td>0.457078</td>\n",
       "      <td>0.865721</td>\n",
       "      <td>7.800400</td>\n",
       "      <td>388.567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.429464</td>\n",
       "      <td>0.893764</td>\n",
       "      <td>7.741400</td>\n",
       "      <td>391.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.446452</td>\n",
       "      <td>0.879248</td>\n",
       "      <td>7.793700</td>\n",
       "      <td>388.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.429944</td>\n",
       "      <td>0.879248</td>\n",
       "      <td>7.621900</td>\n",
       "      <td>397.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.314700</td>\n",
       "      <td>0.455884</td>\n",
       "      <td>0.867041</td>\n",
       "      <td>7.925300</td>\n",
       "      <td>382.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.425771</td>\n",
       "      <td>0.883867</td>\n",
       "      <td>7.841600</td>\n",
       "      <td>386.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.458381</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>7.769200</td>\n",
       "      <td>390.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.440789</td>\n",
       "      <td>0.886836</td>\n",
       "      <td>7.762600</td>\n",
       "      <td>390.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.416324</td>\n",
       "      <td>0.879908</td>\n",
       "      <td>7.743400</td>\n",
       "      <td>391.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.435790</td>\n",
       "      <td>0.891455</td>\n",
       "      <td>7.863900</td>\n",
       "      <td>385.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>0.444060</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>7.888300</td>\n",
       "      <td>384.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.440535</td>\n",
       "      <td>0.876938</td>\n",
       "      <td>8.044700</td>\n",
       "      <td>376.769000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/bert-base-uncased-targeted-WordMix\n",
      "{'eval_loss': 2.8262295722961426, 'eval_accuracy': 0.9373422420193022, 'eval_f1': 0.9362260902532189, 'eval_precision': 0.9376362285894349, 'eval_recall': 0.9350536964217183, 'eval_runtime': 16.9506, 'eval_samples_per_second': 397.331, 'epoch': 15.84, 'run': './results/bert-base-uncased-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0685e25ad761454199ac33b209ccb847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='114000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114000/143957 3:19:09 < 52:20, 9.54 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.615800</td>\n",
       "      <td>0.595183</td>\n",
       "      <td>0.786869</td>\n",
       "      <td>7.606000</td>\n",
       "      <td>398.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.472041</td>\n",
       "      <td>0.858463</td>\n",
       "      <td>7.645300</td>\n",
       "      <td>396.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>0.413785</td>\n",
       "      <td>0.909931</td>\n",
       "      <td>7.743100</td>\n",
       "      <td>391.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.451109</td>\n",
       "      <td>0.898053</td>\n",
       "      <td>7.773400</td>\n",
       "      <td>389.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.433989</td>\n",
       "      <td>0.898713</td>\n",
       "      <td>7.778000</td>\n",
       "      <td>389.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.450637</td>\n",
       "      <td>0.892115</td>\n",
       "      <td>7.645000</td>\n",
       "      <td>396.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.473055</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>7.544700</td>\n",
       "      <td>401.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.480303</td>\n",
       "      <td>0.893764</td>\n",
       "      <td>7.623400</td>\n",
       "      <td>397.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.446567</td>\n",
       "      <td>0.878258</td>\n",
       "      <td>7.734900</td>\n",
       "      <td>391.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.403400</td>\n",
       "      <td>0.417151</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>7.603600</td>\n",
       "      <td>398.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>0.901683</td>\n",
       "      <td>7.487100</td>\n",
       "      <td>404.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.440610</td>\n",
       "      <td>0.905312</td>\n",
       "      <td>7.691800</td>\n",
       "      <td>394.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.445261</td>\n",
       "      <td>0.913230</td>\n",
       "      <td>7.737600</td>\n",
       "      <td>391.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.446092</td>\n",
       "      <td>0.899373</td>\n",
       "      <td>7.803300</td>\n",
       "      <td>388.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.441706</td>\n",
       "      <td>0.916529</td>\n",
       "      <td>7.755000</td>\n",
       "      <td>390.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.447160</td>\n",
       "      <td>0.907951</td>\n",
       "      <td>7.784000</td>\n",
       "      <td>389.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>0.460267</td>\n",
       "      <td>0.917519</td>\n",
       "      <td>7.642400</td>\n",
       "      <td>396.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>0.907291</td>\n",
       "      <td>7.743100</td>\n",
       "      <td>391.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.437085</td>\n",
       "      <td>0.910261</td>\n",
       "      <td>7.668300</td>\n",
       "      <td>395.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>0.425780</td>\n",
       "      <td>0.927087</td>\n",
       "      <td>7.670400</td>\n",
       "      <td>395.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.431482</td>\n",
       "      <td>0.925437</td>\n",
       "      <td>7.741000</td>\n",
       "      <td>391.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.421686</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>7.502000</td>\n",
       "      <td>404.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.321900</td>\n",
       "      <td>0.455651</td>\n",
       "      <td>0.916199</td>\n",
       "      <td>7.683800</td>\n",
       "      <td>394.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.430155</td>\n",
       "      <td>0.919169</td>\n",
       "      <td>7.480700</td>\n",
       "      <td>405.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.431243</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>7.671600</td>\n",
       "      <td>395.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.424634</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>7.567000</td>\n",
       "      <td>400.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.438875</td>\n",
       "      <td>0.925107</td>\n",
       "      <td>7.653000</td>\n",
       "      <td>396.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>0.444215</td>\n",
       "      <td>0.909931</td>\n",
       "      <td>7.826000</td>\n",
       "      <td>387.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.443195</td>\n",
       "      <td>0.933355</td>\n",
       "      <td>7.598000</td>\n",
       "      <td>398.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.314800</td>\n",
       "      <td>0.444511</td>\n",
       "      <td>0.919828</td>\n",
       "      <td>7.730500</td>\n",
       "      <td>392.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.428886</td>\n",
       "      <td>0.918179</td>\n",
       "      <td>7.628800</td>\n",
       "      <td>397.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.438350</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>7.599000</td>\n",
       "      <td>398.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.447979</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>7.896400</td>\n",
       "      <td>383.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.457037</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>7.732200</td>\n",
       "      <td>391.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.440319</td>\n",
       "      <td>0.932366</td>\n",
       "      <td>7.952200</td>\n",
       "      <td>381.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.428899</td>\n",
       "      <td>0.929396</td>\n",
       "      <td>7.557400</td>\n",
       "      <td>401.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.417483</td>\n",
       "      <td>0.932695</td>\n",
       "      <td>7.771200</td>\n",
       "      <td>390.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.924777</td>\n",
       "      <td>7.617500</td>\n",
       "      <td>397.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.934015</td>\n",
       "      <td>7.574800</td>\n",
       "      <td>400.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.458994</td>\n",
       "      <td>0.928077</td>\n",
       "      <td>7.688400</td>\n",
       "      <td>394.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.298900</td>\n",
       "      <td>0.467135</td>\n",
       "      <td>0.927417</td>\n",
       "      <td>7.631800</td>\n",
       "      <td>397.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.432741</td>\n",
       "      <td>0.930716</td>\n",
       "      <td>7.713200</td>\n",
       "      <td>392.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.451640</td>\n",
       "      <td>0.927747</td>\n",
       "      <td>7.697300</td>\n",
       "      <td>393.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.465910</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>7.628400</td>\n",
       "      <td>397.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.450652</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>7.578100</td>\n",
       "      <td>399.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.453228</td>\n",
       "      <td>0.919169</td>\n",
       "      <td>7.683200</td>\n",
       "      <td>394.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.426031</td>\n",
       "      <td>0.935005</td>\n",
       "      <td>7.744400</td>\n",
       "      <td>391.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.455177</td>\n",
       "      <td>0.926097</td>\n",
       "      <td>7.619300</td>\n",
       "      <td>397.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.439380</td>\n",
       "      <td>0.931376</td>\n",
       "      <td>7.732600</td>\n",
       "      <td>391.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.448599</td>\n",
       "      <td>0.928407</td>\n",
       "      <td>7.681700</td>\n",
       "      <td>394.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.452425</td>\n",
       "      <td>0.932696</td>\n",
       "      <td>7.761400</td>\n",
       "      <td>390.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.429321</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>7.568300</td>\n",
       "      <td>400.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.457236</td>\n",
       "      <td>0.931046</td>\n",
       "      <td>7.629400</td>\n",
       "      <td>397.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.488170</td>\n",
       "      <td>0.930056</td>\n",
       "      <td>7.614600</td>\n",
       "      <td>398.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.455827</td>\n",
       "      <td>0.933355</td>\n",
       "      <td>7.756600</td>\n",
       "      <td>390.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.460111</td>\n",
       "      <td>0.932696</td>\n",
       "      <td>7.636600</td>\n",
       "      <td>396.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.442810</td>\n",
       "      <td>0.934345</td>\n",
       "      <td>7.698500</td>\n",
       "      <td>393.715000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-TextMix\n",
      "{'eval_loss': 2.9884274005889893, 'eval_accuracy': 0.9435783221974758, 'eval_f1': 0.9427891787608251, 'eval_precision': 0.9423966499162479, 'eval_recall': 0.9432109504327504, 'eval_runtime': 16.545, 'eval_samples_per_second': 407.072, 'epoch': 15.84, 'run': './results/roberta-base-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c8ac5ecd2442cf8d63d48c9da9413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='112000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112000/143957 3:17:34 < 56:22, 9.45 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>0.564919</td>\n",
       "      <td>0.844606</td>\n",
       "      <td>7.702600</td>\n",
       "      <td>393.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.398181</td>\n",
       "      <td>0.903002</td>\n",
       "      <td>7.776700</td>\n",
       "      <td>389.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.454227</td>\n",
       "      <td>0.900033</td>\n",
       "      <td>7.717300</td>\n",
       "      <td>392.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>0.503579</td>\n",
       "      <td>0.893764</td>\n",
       "      <td>7.833100</td>\n",
       "      <td>386.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.403762</td>\n",
       "      <td>0.908281</td>\n",
       "      <td>7.834800</td>\n",
       "      <td>386.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.916529</td>\n",
       "      <td>7.966600</td>\n",
       "      <td>380.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.434807</td>\n",
       "      <td>0.885516</td>\n",
       "      <td>7.666500</td>\n",
       "      <td>395.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.410900</td>\n",
       "      <td>0.447512</td>\n",
       "      <td>0.905312</td>\n",
       "      <td>7.795400</td>\n",
       "      <td>388.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.450322</td>\n",
       "      <td>0.885516</td>\n",
       "      <td>7.657300</td>\n",
       "      <td>395.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.411100</td>\n",
       "      <td>0.434285</td>\n",
       "      <td>0.916859</td>\n",
       "      <td>7.585200</td>\n",
       "      <td>399.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.455358</td>\n",
       "      <td>0.915539</td>\n",
       "      <td>7.802000</td>\n",
       "      <td>388.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.394437</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>7.820900</td>\n",
       "      <td>387.552000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.427204</td>\n",
       "      <td>0.899703</td>\n",
       "      <td>7.612400</td>\n",
       "      <td>398.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.371900</td>\n",
       "      <td>0.425990</td>\n",
       "      <td>0.903662</td>\n",
       "      <td>7.867700</td>\n",
       "      <td>385.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.442465</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>7.967300</td>\n",
       "      <td>380.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.422704</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>7.771700</td>\n",
       "      <td>390.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.418690</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>7.844300</td>\n",
       "      <td>386.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.388796</td>\n",
       "      <td>0.932036</td>\n",
       "      <td>7.835200</td>\n",
       "      <td>386.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.419830</td>\n",
       "      <td>0.919499</td>\n",
       "      <td>7.842300</td>\n",
       "      <td>386.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.406639</td>\n",
       "      <td>0.928077</td>\n",
       "      <td>7.784000</td>\n",
       "      <td>389.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.410883</td>\n",
       "      <td>0.920818</td>\n",
       "      <td>7.752700</td>\n",
       "      <td>390.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.419308</td>\n",
       "      <td>0.921808</td>\n",
       "      <td>7.594200</td>\n",
       "      <td>399.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.339200</td>\n",
       "      <td>0.403838</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>7.672000</td>\n",
       "      <td>395.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.413595</td>\n",
       "      <td>0.918179</td>\n",
       "      <td>7.601400</td>\n",
       "      <td>398.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.407928</td>\n",
       "      <td>0.929066</td>\n",
       "      <td>7.869600</td>\n",
       "      <td>385.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.416441</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>7.822900</td>\n",
       "      <td>387.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.937314</td>\n",
       "      <td>7.515000</td>\n",
       "      <td>403.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.417119</td>\n",
       "      <td>0.937314</td>\n",
       "      <td>7.661600</td>\n",
       "      <td>395.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.399905</td>\n",
       "      <td>0.942263</td>\n",
       "      <td>7.791000</td>\n",
       "      <td>389.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.408631</td>\n",
       "      <td>0.936984</td>\n",
       "      <td>7.750800</td>\n",
       "      <td>391.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.418691</td>\n",
       "      <td>0.922138</td>\n",
       "      <td>7.633300</td>\n",
       "      <td>397.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.418266</td>\n",
       "      <td>0.940614</td>\n",
       "      <td>7.748700</td>\n",
       "      <td>391.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.405856</td>\n",
       "      <td>0.935335</td>\n",
       "      <td>7.759900</td>\n",
       "      <td>390.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.407211</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>7.927300</td>\n",
       "      <td>382.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>0.395328</td>\n",
       "      <td>0.939624</td>\n",
       "      <td>7.862300</td>\n",
       "      <td>385.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.405157</td>\n",
       "      <td>0.930386</td>\n",
       "      <td>8.040700</td>\n",
       "      <td>376.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.304900</td>\n",
       "      <td>0.403118</td>\n",
       "      <td>0.942263</td>\n",
       "      <td>7.642800</td>\n",
       "      <td>396.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.394044</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>7.888300</td>\n",
       "      <td>384.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.390014</td>\n",
       "      <td>0.943583</td>\n",
       "      <td>7.658100</td>\n",
       "      <td>395.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.398180</td>\n",
       "      <td>0.921148</td>\n",
       "      <td>7.708400</td>\n",
       "      <td>393.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.409402</td>\n",
       "      <td>0.940944</td>\n",
       "      <td>7.651400</td>\n",
       "      <td>396.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.402260</td>\n",
       "      <td>0.933025</td>\n",
       "      <td>7.848700</td>\n",
       "      <td>386.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.417132</td>\n",
       "      <td>0.937974</td>\n",
       "      <td>7.702600</td>\n",
       "      <td>393.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.401867</td>\n",
       "      <td>0.946222</td>\n",
       "      <td>7.585400</td>\n",
       "      <td>399.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.300200</td>\n",
       "      <td>0.438242</td>\n",
       "      <td>0.935665</td>\n",
       "      <td>7.649900</td>\n",
       "      <td>396.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.404527</td>\n",
       "      <td>0.947212</td>\n",
       "      <td>7.738100</td>\n",
       "      <td>391.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.401870</td>\n",
       "      <td>0.942923</td>\n",
       "      <td>7.744000</td>\n",
       "      <td>391.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.437562</td>\n",
       "      <td>0.933355</td>\n",
       "      <td>7.650500</td>\n",
       "      <td>396.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.428783</td>\n",
       "      <td>0.933685</td>\n",
       "      <td>7.868300</td>\n",
       "      <td>385.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.412858</td>\n",
       "      <td>0.942263</td>\n",
       "      <td>7.677200</td>\n",
       "      <td>394.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.423130</td>\n",
       "      <td>0.933355</td>\n",
       "      <td>7.638100</td>\n",
       "      <td>396.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.425983</td>\n",
       "      <td>0.943583</td>\n",
       "      <td>7.435000</td>\n",
       "      <td>407.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.426410</td>\n",
       "      <td>0.940944</td>\n",
       "      <td>7.666400</td>\n",
       "      <td>395.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>0.427552</td>\n",
       "      <td>0.940284</td>\n",
       "      <td>7.794300</td>\n",
       "      <td>388.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.290800</td>\n",
       "      <td>0.413443</td>\n",
       "      <td>0.946222</td>\n",
       "      <td>7.810500</td>\n",
       "      <td>388.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>0.415257</td>\n",
       "      <td>0.936655</td>\n",
       "      <td>7.704400</td>\n",
       "      <td>393.409000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n",
      "ORIG for ./results/roberta-base-targeted-SentMix\n",
      "{'eval_loss': 2.7558422088623047, 'eval_accuracy': 0.9429844097995546, 'eval_f1': 0.9421787597086402, 'eval_precision': 0.9418434046063713, 'eval_recall': 0.9425350464111215, 'eval_runtime': 16.5536, 'eval_samples_per_second': 406.861, 'epoch': 15.56, 'run': './results/roberta-base-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbab77a6fc6644b5bf6284a9facad9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='52000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 52000/143957 1:32:16 < 2:43:11, 9.39 it/s, Epoch 7/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.659900</td>\n",
       "      <td>0.622896</td>\n",
       "      <td>0.695480</td>\n",
       "      <td>7.861000</td>\n",
       "      <td>385.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.773012</td>\n",
       "      <td>7.747400</td>\n",
       "      <td>391.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.512739</td>\n",
       "      <td>0.749588</td>\n",
       "      <td>7.725100</td>\n",
       "      <td>392.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.497800</td>\n",
       "      <td>0.493153</td>\n",
       "      <td>0.797426</td>\n",
       "      <td>7.900400</td>\n",
       "      <td>383.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.479546</td>\n",
       "      <td>0.801056</td>\n",
       "      <td>7.923500</td>\n",
       "      <td>382.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.547117</td>\n",
       "      <td>0.786869</td>\n",
       "      <td>7.731400</td>\n",
       "      <td>392.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.486300</td>\n",
       "      <td>0.482812</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>7.941800</td>\n",
       "      <td>381.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.480900</td>\n",
       "      <td>0.523391</td>\n",
       "      <td>0.793797</td>\n",
       "      <td>7.821500</td>\n",
       "      <td>387.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>0.495720</td>\n",
       "      <td>0.812603</td>\n",
       "      <td>7.945900</td>\n",
       "      <td>381.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.482666</td>\n",
       "      <td>0.783240</td>\n",
       "      <td>8.018200</td>\n",
       "      <td>378.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.489388</td>\n",
       "      <td>0.803695</td>\n",
       "      <td>7.996700</td>\n",
       "      <td>379.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.474124</td>\n",
       "      <td>0.817222</td>\n",
       "      <td>7.861500</td>\n",
       "      <td>385.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.448800</td>\n",
       "      <td>0.489075</td>\n",
       "      <td>0.813263</td>\n",
       "      <td>7.775000</td>\n",
       "      <td>389.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.501285</td>\n",
       "      <td>0.823161</td>\n",
       "      <td>7.639900</td>\n",
       "      <td>396.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>0.491874</td>\n",
       "      <td>0.820521</td>\n",
       "      <td>7.796700</td>\n",
       "      <td>388.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.468934</td>\n",
       "      <td>0.824810</td>\n",
       "      <td>7.602600</td>\n",
       "      <td>398.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.463200</td>\n",
       "      <td>0.541674</td>\n",
       "      <td>0.801056</td>\n",
       "      <td>7.942700</td>\n",
       "      <td>381.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.525713</td>\n",
       "      <td>0.812603</td>\n",
       "      <td>7.771000</td>\n",
       "      <td>390.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.531299</td>\n",
       "      <td>0.791488</td>\n",
       "      <td>7.822400</td>\n",
       "      <td>387.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>0.696703</td>\n",
       "      <td>0.516661</td>\n",
       "      <td>7.865000</td>\n",
       "      <td>385.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.692100</td>\n",
       "      <td>0.691457</td>\n",
       "      <td>0.529198</td>\n",
       "      <td>7.808300</td>\n",
       "      <td>388.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>0.694387</td>\n",
       "      <td>0.463873</td>\n",
       "      <td>7.673900</td>\n",
       "      <td>394.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.691845</td>\n",
       "      <td>0.531838</td>\n",
       "      <td>7.793500</td>\n",
       "      <td>388.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.699464</td>\n",
       "      <td>0.523590</td>\n",
       "      <td>7.718500</td>\n",
       "      <td>392.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.536127</td>\n",
       "      <td>7.720200</td>\n",
       "      <td>392.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.690516</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>7.757300</td>\n",
       "      <td>390.730000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/roberta-base-targeted-WordMix\n",
      "{'eval_loss': 1.4908337593078613, 'eval_accuracy': 0.880920564216778, 'eval_f1': 0.8758818492505398, 'eval_precision': 0.8951886823536714, 'eval_recall': 0.8692707020666626, 'eval_runtime': 16.5048, 'eval_samples_per_second': 408.064, 'epoch': 7.22, 'run': './results/roberta-base-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8d7efe8f094087966c14e3a2c18d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with TextMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='48000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 48000/143957 1:43:00 < 3:25:56, 7.77 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>0.594827</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>12.244300</td>\n",
       "      <td>247.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.436235</td>\n",
       "      <td>0.863411</td>\n",
       "      <td>12.511600</td>\n",
       "      <td>242.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>0.456206</td>\n",
       "      <td>0.825800</td>\n",
       "      <td>12.546500</td>\n",
       "      <td>241.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.454064</td>\n",
       "      <td>0.877928</td>\n",
       "      <td>12.847100</td>\n",
       "      <td>235.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.429549</td>\n",
       "      <td>0.867371</td>\n",
       "      <td>12.774900</td>\n",
       "      <td>237.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.456181</td>\n",
       "      <td>0.851204</td>\n",
       "      <td>12.780100</td>\n",
       "      <td>237.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.427129</td>\n",
       "      <td>0.866051</td>\n",
       "      <td>12.569500</td>\n",
       "      <td>241.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.430067</td>\n",
       "      <td>0.888156</td>\n",
       "      <td>12.636900</td>\n",
       "      <td>239.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.427950</td>\n",
       "      <td>0.887826</td>\n",
       "      <td>12.613100</td>\n",
       "      <td>240.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>0.443465</td>\n",
       "      <td>0.883867</td>\n",
       "      <td>12.204400</td>\n",
       "      <td>248.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.440177</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>12.949400</td>\n",
       "      <td>234.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.423781</td>\n",
       "      <td>0.892775</td>\n",
       "      <td>12.795800</td>\n",
       "      <td>236.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.451904</td>\n",
       "      <td>0.893434</td>\n",
       "      <td>12.904500</td>\n",
       "      <td>234.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.434206</td>\n",
       "      <td>0.908611</td>\n",
       "      <td>12.729000</td>\n",
       "      <td>238.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.458678</td>\n",
       "      <td>0.875289</td>\n",
       "      <td>12.479600</td>\n",
       "      <td>242.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>0.443642</td>\n",
       "      <td>0.903002</td>\n",
       "      <td>13.066100</td>\n",
       "      <td>231.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.429924</td>\n",
       "      <td>0.893104</td>\n",
       "      <td>12.443000</td>\n",
       "      <td>243.591000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>0.896404</td>\n",
       "      <td>12.582400</td>\n",
       "      <td>240.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.460068</td>\n",
       "      <td>0.892445</td>\n",
       "      <td>12.588400</td>\n",
       "      <td>240.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>0.431009</td>\n",
       "      <td>0.900363</td>\n",
       "      <td>12.928400</td>\n",
       "      <td>234.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.427872</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>12.800800</td>\n",
       "      <td>236.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.473776</td>\n",
       "      <td>0.900033</td>\n",
       "      <td>12.347000</td>\n",
       "      <td>245.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.463551</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>12.526500</td>\n",
       "      <td>241.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.479741</td>\n",
       "      <td>0.876938</td>\n",
       "      <td>12.597300</td>\n",
       "      <td>240.606000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/xlnet-base-cased-targeted-TextMix\n",
      "{'eval_loss': 2.389803647994995, 'eval_accuracy': 0.9273942093541203, 'eval_f1': 0.9260501016250737, 'eval_precision': 0.927810066510642, 'eval_recall': 0.9246463228386823, 'eval_runtime': 26.3955, 'eval_samples_per_second': 255.158, 'epoch': 6.67, 'run': './results/xlnet-base-cased-targeted-TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450503530728439a8dab6575a478a0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with SentMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='66000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 66000/143957 2:21:39 < 2:47:19, 7.76 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.647600</td>\n",
       "      <td>0.613538</td>\n",
       "      <td>0.778951</td>\n",
       "      <td>13.333400</td>\n",
       "      <td>227.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>0.495636</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>13.009200</td>\n",
       "      <td>232.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.432980</td>\n",
       "      <td>0.880238</td>\n",
       "      <td>13.287500</td>\n",
       "      <td>228.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.420400</td>\n",
       "      <td>0.431587</td>\n",
       "      <td>0.877928</td>\n",
       "      <td>12.913500</td>\n",
       "      <td>234.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.418200</td>\n",
       "      <td>0.414039</td>\n",
       "      <td>0.892115</td>\n",
       "      <td>13.029200</td>\n",
       "      <td>232.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.419400</td>\n",
       "      <td>0.479870</td>\n",
       "      <td>0.876278</td>\n",
       "      <td>13.303400</td>\n",
       "      <td>227.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>0.867041</td>\n",
       "      <td>13.339300</td>\n",
       "      <td>227.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.427618</td>\n",
       "      <td>0.875619</td>\n",
       "      <td>13.347300</td>\n",
       "      <td>227.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>0.470780</td>\n",
       "      <td>0.866711</td>\n",
       "      <td>13.729300</td>\n",
       "      <td>220.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.444799</td>\n",
       "      <td>0.885516</td>\n",
       "      <td>13.203700</td>\n",
       "      <td>229.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.432362</td>\n",
       "      <td>0.887166</td>\n",
       "      <td>13.082000</td>\n",
       "      <td>231.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.374700</td>\n",
       "      <td>0.428857</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>13.226600</td>\n",
       "      <td>229.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.518629</td>\n",
       "      <td>0.864401</td>\n",
       "      <td>13.232600</td>\n",
       "      <td>229.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.451283</td>\n",
       "      <td>0.872979</td>\n",
       "      <td>13.463000</td>\n",
       "      <td>225.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.417076</td>\n",
       "      <td>0.902013</td>\n",
       "      <td>13.229600</td>\n",
       "      <td>229.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.375100</td>\n",
       "      <td>0.410759</td>\n",
       "      <td>0.900033</td>\n",
       "      <td>13.156800</td>\n",
       "      <td>230.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.428146</td>\n",
       "      <td>0.903662</td>\n",
       "      <td>13.234000</td>\n",
       "      <td>229.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.446567</td>\n",
       "      <td>0.904322</td>\n",
       "      <td>13.300500</td>\n",
       "      <td>227.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.405590</td>\n",
       "      <td>0.891785</td>\n",
       "      <td>12.847700</td>\n",
       "      <td>235.918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.890465</td>\n",
       "      <td>13.508900</td>\n",
       "      <td>224.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.429740</td>\n",
       "      <td>0.901353</td>\n",
       "      <td>13.043100</td>\n",
       "      <td>232.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.345300</td>\n",
       "      <td>0.424227</td>\n",
       "      <td>0.914550</td>\n",
       "      <td>12.908500</td>\n",
       "      <td>234.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.439379</td>\n",
       "      <td>0.919169</td>\n",
       "      <td>13.283500</td>\n",
       "      <td>228.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.414008</td>\n",
       "      <td>0.898053</td>\n",
       "      <td>13.246600</td>\n",
       "      <td>228.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>13.062100</td>\n",
       "      <td>232.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.434036</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>13.055100</td>\n",
       "      <td>232.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.430593</td>\n",
       "      <td>0.897064</td>\n",
       "      <td>13.478000</td>\n",
       "      <td>224.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.383850</td>\n",
       "      <td>0.897064</td>\n",
       "      <td>13.408200</td>\n",
       "      <td>226.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.427427</td>\n",
       "      <td>0.918839</td>\n",
       "      <td>13.115000</td>\n",
       "      <td>231.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.334800</td>\n",
       "      <td>0.431889</td>\n",
       "      <td>0.888815</td>\n",
       "      <td>13.439100</td>\n",
       "      <td>225.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.910261</td>\n",
       "      <td>12.910500</td>\n",
       "      <td>234.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.918509</td>\n",
       "      <td>13.706400</td>\n",
       "      <td>221.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.415843</td>\n",
       "      <td>0.910261</td>\n",
       "      <td>13.115900</td>\n",
       "      <td>231.093000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/xlnet-base-cased-targeted-SentMix\n",
      "{'eval_loss': 2.586996555328369, 'eval_accuracy': 0.9361544172234595, 'eval_f1': 0.9352841806698615, 'eval_precision': 0.9347649379982681, 'eval_recall': 0.9358589726974871, 'eval_runtime': 26.3615, 'eval_samples_per_second': 255.486, 'epoch': 9.17, 'run': './results/xlnet-base-cased-targeted-SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40af92106eff4b838eca4b1bef2e192a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TargetedMixturesCollator initialized with WordMix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='30000' max='143957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 30000/143957 1:04:54 < 4:06:34, 7.70 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.672600</td>\n",
       "      <td>0.636210</td>\n",
       "      <td>0.677004</td>\n",
       "      <td>12.988300</td>\n",
       "      <td>233.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.593850</td>\n",
       "      <td>0.751237</td>\n",
       "      <td>12.505600</td>\n",
       "      <td>242.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.545183</td>\n",
       "      <td>0.771033</td>\n",
       "      <td>12.472700</td>\n",
       "      <td>243.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.602829</td>\n",
       "      <td>0.744309</td>\n",
       "      <td>12.366900</td>\n",
       "      <td>245.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>0.498178</td>\n",
       "      <td>0.797097</td>\n",
       "      <td>12.460700</td>\n",
       "      <td>243.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>0.498005</td>\n",
       "      <td>0.774662</td>\n",
       "      <td>12.371900</td>\n",
       "      <td>244.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.709821</td>\n",
       "      <td>0.698449</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>234.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.700436</td>\n",
       "      <td>0.549984</td>\n",
       "      <td>12.698100</td>\n",
       "      <td>238.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.687496</td>\n",
       "      <td>0.548994</td>\n",
       "      <td>12.831700</td>\n",
       "      <td>236.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>0.689743</td>\n",
       "      <td>0.551633</td>\n",
       "      <td>12.798800</td>\n",
       "      <td>236.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.689731</td>\n",
       "      <td>0.533817</td>\n",
       "      <td>12.647200</td>\n",
       "      <td>239.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.687676</td>\n",
       "      <td>0.547014</td>\n",
       "      <td>12.617300</td>\n",
       "      <td>240.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.688834</td>\n",
       "      <td>0.546684</td>\n",
       "      <td>12.550500</td>\n",
       "      <td>241.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.696700</td>\n",
       "      <td>0.694540</td>\n",
       "      <td>0.456615</td>\n",
       "      <td>12.800800</td>\n",
       "      <td>236.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.698595</td>\n",
       "      <td>0.526559</td>\n",
       "      <td>12.525600</td>\n",
       "      <td>241.985000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping_patience_counter\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [211/211 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for ./results/xlnet-base-cased-targeted-WordMix\n",
      "{'eval_loss': 1.8109349012374878, 'eval_accuracy': 0.8974016332590943, 'eval_f1': 0.8953633509736856, 'eval_precision': 0.8977366081715648, 'eval_recall': 0.8936208335958666, 'eval_runtime': 26.3755, 'eval_samples_per_second': 255.351, 'epoch': 4.17, 'run': './results/xlnet-base-cased-targeted-WordMix', 'test': 'ORIG'}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "    for t in ts:  \n",
    "    \n",
    "        t_str = t.__class__.__name__\n",
    "        checkpoint = './results/' + MODEL_NAME + '-targeted-' + t_str\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
    "\n",
    "        dataset = load_dataset('glue', 'sst2', split='train[:90%]') \n",
    "        dataset.rename_column_('sentence', 'text')\n",
    "        dataset_dict = dataset.train_test_split(\n",
    "            test_size = 0.05,\n",
    "            train_size = 0.95,\n",
    "            shuffle = True\n",
    "        )\n",
    "        train_dataset = dataset_dict['train']\n",
    "        eval_dataset = dataset_dict['test']\n",
    "\n",
    "        test_dataset = load_dataset('glue', 'sst2', split='train[90%:]')\n",
    "        test_dataset.rename_column_('sentence', 'text') \n",
    "        test_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        train_batch_size = 8\n",
    "        eval_batch_size = 32\n",
    "        num_epoch = 20\n",
    "        gradient_accumulation_steps = 1\n",
    "        max_steps = int((len(train_dataset) * num_epoch / gradient_accumulation_steps) / train_batch_size)\n",
    "\n",
    "#         tmcb = TargetedMixturesCallback(\n",
    "#             dataloader=DataLoader(eval_dataset, batch_size=32),\n",
    "#             device=device\n",
    "#         )\n",
    "        escb = EarlyStoppingCallback(\n",
    "            early_stopping_patience=10\n",
    "        )\n",
    "        tmc = TargetedMixturesCollator(\n",
    "            tokenize_fn=tokenize_fn, \n",
    "            transform=t,\n",
    "            target_pairs=[(0,1),(1,0)],\n",
    "            target_prob=0.5,\n",
    "            num_classes=2\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=checkpoint,\n",
    "            overwrite_output_dir=True,\n",
    "            max_steps=max_steps,\n",
    "            save_steps=int(max_steps / 10),\n",
    "            save_total_limit=1,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "            warmup_steps=int(max_steps / 10),\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=2000,\n",
    "            logging_first_step=True,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            remove_unused_columns=False\n",
    "        )\n",
    "\n",
    "        trainer = TargetedTrainer(\n",
    "            model=model, \n",
    "            tokenizer=tokenizer,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_metrics_w_soft_target,                  \n",
    "            train_dataset=train_dataset,         \n",
    "            eval_dataset=eval_dataset,\n",
    "            data_collator=tmc,\n",
    "            callbacks=[escb] # [tmcb, escb]\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # test with ORIG data\n",
    "        trainer.eval_dataset = test_dataset\n",
    "        trainer.compute_metrics = compute_metrics\n",
    "        trainer.data_collator = DefaultCollator()\n",
    "        # trainer.remove_callback(tmcb)\n",
    "\n",
    "        out_orig = trainer.evaluate()\n",
    "        out_orig['run'] = checkpoint\n",
    "        out_orig['test'] = \"ORIG\"\n",
    "        print('ORIG for {}\\n{}'.format(checkpoint, out_orig))\n",
    "\n",
    "        results.append(out_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>run</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.888487</td>\n",
       "      <td>0.939272</td>\n",
       "      <td>0.938223</td>\n",
       "      <td>0.939356</td>\n",
       "      <td>0.937250</td>\n",
       "      <td>17.6167</td>\n",
       "      <td>382.307</td>\n",
       "      <td>17.78</td>\n",
       "      <td>./results/bert-base-uncased-targeted-TextMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.712137</td>\n",
       "      <td>0.937639</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.936415</td>\n",
       "      <td>16.9257</td>\n",
       "      <td>397.916</td>\n",
       "      <td>15.84</td>\n",
       "      <td>./results/bert-base-uncased-targeted-SentMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.826230</td>\n",
       "      <td>0.937342</td>\n",
       "      <td>0.936226</td>\n",
       "      <td>0.937636</td>\n",
       "      <td>0.935054</td>\n",
       "      <td>16.9506</td>\n",
       "      <td>397.331</td>\n",
       "      <td>15.84</td>\n",
       "      <td>./results/bert-base-uncased-targeted-WordMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.988427</td>\n",
       "      <td>0.943578</td>\n",
       "      <td>0.942789</td>\n",
       "      <td>0.942397</td>\n",
       "      <td>0.943211</td>\n",
       "      <td>16.5450</td>\n",
       "      <td>407.072</td>\n",
       "      <td>15.84</td>\n",
       "      <td>./results/roberta-base-targeted-TextMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.755842</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>0.942179</td>\n",
       "      <td>0.941843</td>\n",
       "      <td>0.942535</td>\n",
       "      <td>16.5536</td>\n",
       "      <td>406.861</td>\n",
       "      <td>15.56</td>\n",
       "      <td>./results/roberta-base-targeted-SentMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.490834</td>\n",
       "      <td>0.880921</td>\n",
       "      <td>0.875882</td>\n",
       "      <td>0.895189</td>\n",
       "      <td>0.869271</td>\n",
       "      <td>16.5048</td>\n",
       "      <td>408.064</td>\n",
       "      <td>7.22</td>\n",
       "      <td>./results/roberta-base-targeted-WordMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.389804</td>\n",
       "      <td>0.927394</td>\n",
       "      <td>0.926050</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.924646</td>\n",
       "      <td>26.3955</td>\n",
       "      <td>255.158</td>\n",
       "      <td>6.67</td>\n",
       "      <td>./results/xlnet-base-cased-targeted-TextMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.586997</td>\n",
       "      <td>0.936154</td>\n",
       "      <td>0.935284</td>\n",
       "      <td>0.934765</td>\n",
       "      <td>0.935859</td>\n",
       "      <td>26.3615</td>\n",
       "      <td>255.486</td>\n",
       "      <td>9.17</td>\n",
       "      <td>./results/xlnet-base-cased-targeted-SentMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.810935</td>\n",
       "      <td>0.897402</td>\n",
       "      <td>0.895363</td>\n",
       "      <td>0.897737</td>\n",
       "      <td>0.893621</td>\n",
       "      <td>26.3755</td>\n",
       "      <td>255.351</td>\n",
       "      <td>4.17</td>\n",
       "      <td>./results/xlnet-base-cased-targeted-WordMix</td>\n",
       "      <td>ORIG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "0   3.888487       0.939272  0.938223        0.939356     0.937250   \n",
       "1   3.712137       0.937639  0.936670        0.936937     0.936415   \n",
       "2   2.826230       0.937342  0.936226        0.937636     0.935054   \n",
       "3   2.988427       0.943578  0.942789        0.942397     0.943211   \n",
       "4   2.755842       0.942984  0.942179        0.941843     0.942535   \n",
       "5   1.490834       0.880921  0.875882        0.895189     0.869271   \n",
       "6   2.389804       0.927394  0.926050        0.927810     0.924646   \n",
       "7   2.586997       0.936154  0.935284        0.934765     0.935859   \n",
       "8   1.810935       0.897402  0.895363        0.897737     0.893621   \n",
       "\n",
       "   eval_runtime  eval_samples_per_second  epoch  \\\n",
       "0       17.6167                  382.307  17.78   \n",
       "1       16.9257                  397.916  15.84   \n",
       "2       16.9506                  397.331  15.84   \n",
       "3       16.5450                  407.072  15.84   \n",
       "4       16.5536                  406.861  15.56   \n",
       "5       16.5048                  408.064   7.22   \n",
       "6       26.3955                  255.158   6.67   \n",
       "7       26.3615                  255.486   9.17   \n",
       "8       26.3755                  255.351   4.17   \n",
       "\n",
       "                                            run  test  \n",
       "0  ./results/bert-base-uncased-targeted-TextMix  ORIG  \n",
       "1  ./results/bert-base-uncased-targeted-SentMix  ORIG  \n",
       "2  ./results/bert-base-uncased-targeted-WordMix  ORIG  \n",
       "3       ./results/roberta-base-targeted-TextMix  ORIG  \n",
       "4       ./results/roberta-base-targeted-SentMix  ORIG  \n",
       "5       ./results/roberta-base-targeted-WordMix  ORIG  \n",
       "6   ./results/xlnet-base-cased-targeted-TextMix  ORIG  \n",
       "7   ./results/xlnet-base-cased-targeted-SentMix  ORIG  \n",
       "8   ./results/xlnet-base-cased-targeted-WordMix  ORIG  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_SST2_targeted_r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(excel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
