{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\").shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate 100 test suites with n tests\n",
    "# n = 100\n",
    "# test_suites = {}\n",
    "# for i in range(100):\n",
    "#     j = random.randint(0, len(dataset['train']['text']) - 1 - n)\n",
    "#     X, y = dataset['train']['text'][j:j+n], dataset['train']['label'][j:j+n]\n",
    "#     test_suite = {'data': X, 'target': y}\n",
    "#     test_suites[i] = test_suite  \n",
    "# pkl_save(test_suites, 'assets/AG_NEWS/test_suites.pkl')\n",
    "test_suites = pkl_load('assets/AG_NEWS/test_suites.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:25<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "INV_test_suites = transform_test_suites(test_suites, num_transforms=2, task='topic', tran='INV')\n",
    "pkl_save(INV_test_suites, 'assets/AG_NEWS/INV_test_suites.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 176.67it/s]\n"
     ]
    }
   ],
   "source": [
    "SIB_test_suites = transform_test_suites(test_suites, num_transforms=1, task='topic', tran='SIB-mix')\n",
    "pkl_save(SIB_test_suites, 'assets/AG_NEWS/SIB_test_suites.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot easily apply since SIB transformations return soft-labels and INV ones return hard-labels\n",
    "# would require some time to think about how to do this (via one-hot-encoding), but then how to measure? loss BCEwithLogits?\n",
    "\n",
    "# both_test_suites = transform_test_suites(test_suites, num_transforms=2, task='sentiment', tran=None)\n",
    "# pkl_save(both_test_suites, 'assets/AG_NEWS/both_test_suites.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suites = pkl_load('assets/AG_NEWS/test_suites.pkl')\n",
    "INV_test_suites = pkl_load('assets/AG_NEWS/INV_test_suites.pkl')\n",
    "SIB_test_suites = pkl_load('assets/AG_NEWS/SIB_test_suites.pkl')\n",
    "# both_test_suites = pkl_load('assets/IMDB/both_test_suites.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_pred, y_true):\n",
    "    total = y_true.size(0)\n",
    "    correct = (y_pred == y_true).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def get_topk_acc(logits, y_true, k):\n",
    "    total = y_true.size(0)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=1)\n",
    "    out_weights, out_idx = torch.topk(logits, k=k, dim=1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a58280aff30456ea906e89fee5e553c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=706.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a47d00d58be49e1972c15df935bd550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d361fdab35394d4eada4b234615f679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016d3414cdb84ecf8d236ade8fcce659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=48.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcaed4d3b254b03a0426da8a1bca76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=437991539.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def load_huggingface_model(model_name, device, max_length=500):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "    def pipeline(sentence):\n",
    "        encode = tokenizer(sentence, \n",
    "                           padding=True, \n",
    "                           truncation=True, \n",
    "                           max_length=max_length, \n",
    "                           return_tensors=\"pt\").to(device)\n",
    "        logits = model(**encode)[0]\n",
    "        soft_m = torch.softmax(logits, dim=1)\n",
    "        return soft_m\n",
    "    return pipeline\n",
    "\n",
    "MODEL_NAME = \"textattack/bert-base-uncased-ag-news\" #\"textattack/distilbert-base-uncased-ag-news\" \n",
    "model = load_huggingface_model(MODEL_NAME, device, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = {\n",
    "    'test_suites' : test_suites,\n",
    "    'INV_test_suites' : INV_test_suites,\n",
    "    'SIB_test_suites' : SIB_test_suites,\n",
    "    # 'both_test_suites' : both_test_suites\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting test_suites...\n",
      "test suite 0 acc: 0.99\n",
      "test suite 1 acc: 1.0\n",
      "test suite 2 acc: 0.99\n",
      "test suite 3 acc: 1.0\n",
      "test suite 4 acc: 1.0\n",
      "test suite 5 acc: 1.0\n",
      "test suite 6 acc: 1.0\n",
      "test suite 7 acc: 1.0\n",
      "test suite 8 acc: 1.0\n",
      "test suite 9 acc: 1.0\n",
      "test suite 10 acc: 0.97\n",
      "test suite 11 acc: 1.0\n",
      "test suite 12 acc: 0.99\n",
      "test suite 13 acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "for t_name, test_suites in tss.items():\n",
    "    print('starting {}...'.format(t_name))\n",
    "    if 'SIB' in t_name:\n",
    "        for idx, t in test_suites.items():\n",
    "            logits = model([str(x) for x in t['data'].tolist()])\n",
    "            y_true = torch.tensor(t['target'])\n",
    "            acc = get_topk_acc(logits, y_true, k=2)\n",
    "            t['performance'] = {\n",
    "                'MODEL_NAME' : MODEL_NAME,\n",
    "                'acc' : acc\n",
    "            }\n",
    "            print('test suite {} acc: {}'.format(idx, acc))\n",
    "    else:\n",
    "        for idx, t in test_suites.items():\n",
    "            logits = model(t['data'])\n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            y_true = torch.tensor(t['target'])\n",
    "            acc = get_acc(y_pred, y_true)\n",
    "            t['performance'] = {\n",
    "                'MODEL_NAME' : MODEL_NAME,\n",
    "                'acc' : acc\n",
    "            }\n",
    "            print('test suite {} acc: {}'.format(idx, acc))\n",
    "    file_path = 'assets/AG_NEWS/BERT/' + t_name + '_w_acc.pkl'\n",
    "    pkl_save(test_suites, file_path)\n",
    "    print('saving {}'.format(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "for t_name, test_suites in tss.items():\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for idx, t in test_suites.items():\n",
    "        total += t['performance']['acc']\n",
    "        count += 1\n",
    "    avg_acc = total / count\n",
    "    print('average acc: {0:1.2f} | {1}'.format(avg_acc, t_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average acc: 0.97 | test_suites\n",
      "average acc: 0.44 | INV_test_suites\n",
      "average acc: 0.60 | SIB_test_suites\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "for t_name, test_suites in tss.items():\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for idx, t in test_suites.items():\n",
    "        total += t['performance']['acc']\n",
    "        count += 1\n",
    "    avg_acc = total / count\n",
    "    print('average acc: {0:1.2f} | {1}'.format(avg_acc, t_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample some transforms to see if they're reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./assets/csv_examples/agnews_inv_examples.csv\"\n",
    "    \n",
    "# writing to csv file  \n",
    "with open(filename, 'w') as csvfile:  \n",
    "    # creating a csv writer object  \n",
    "    csvwriter = csv.writer(csvfile)  \n",
    "    csvwriter.writerow(['text', 'label', 'sound good?'])\n",
    "    # writing the fields  \n",
    "    for i in range(50):\n",
    "        row = [INV_test_suites[i]['data'][i], INV_test_suites[i]['target'][i], True ]#, INV_test_suites[i]['ts'][i] ]\n",
    "        csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./assets/csv_examples/agnews_sib_examples.csv\"\n",
    "    \n",
    "# writing to csv file  \n",
    "with open(filename, 'w') as csvfile:  \n",
    "    # creating a csv writer object  \n",
    "    csvwriter = csv.writer(csvfile)  \n",
    "    csvwriter.writerow(['text', 'label', 'sound good?'])\n",
    "    # writing the fields  \n",
    "    for i in range(50):\n",
    "        row = [SIB_test_suites[i]['data'][i], SIB_test_suites[i]['target'][i], True ]#, INV_test_suites[i]['ts'][i] ]\n",
    "        csvwriter.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
