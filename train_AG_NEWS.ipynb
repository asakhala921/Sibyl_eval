{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "utjMLdmqsUuA"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wandb.login()\n",
    "\n",
    "# %env WANDB_PROJECT = train_SST2\n",
    "# %env WANDB_WATCH = 'all'\n",
    "# %env WANDB_SILENT = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WT_xnGBpTNuZ"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y, nb_classes=4):\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.expand_dims(np.array(y), 0)\n",
    "    res = np.eye(nb_classes)[np.array(y).reshape(-1)]\n",
    "    return res.reshape(list(y.shape)+[nb_classes])[0]\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=250)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1.mean(),\n",
    "        'precision': precision.mean(),\n",
    "        'recall': recall.mean()\n",
    "    }\n",
    "\n",
    "def acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()\n",
    "\n",
    "def CEwST_loss(logits, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Cross Entropy with Soft Target (CEwST) Loss\n",
    "    :param logits: (batch, *)\n",
    "    :param target: (batch, *) same shape as logits, each item must be a valid distribution: target[i, :].sum() == 1.\n",
    "    \"\"\"\n",
    "    logprobs = torch.nn.functional.log_softmax(logits.view(logits.shape[0], -1), dim=1)\n",
    "    batchloss = - torch.sum(target.view(target.shape[0], -1) * logprobs, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return batchloss\n",
    "    elif reduction == 'mean':\n",
    "        return torch.mean(batchloss)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(batchloss)\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported reduction mode.')\n",
    "\n",
    "def compute_metrics_w_soft_target(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    acc = acc_at_k(labels, preds, k=2)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }\n",
    "\n",
    "class Trainer_w_soft_target(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = CEwST_loss(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "    \n",
    "class DefaultCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def get_20NG_test_dataset():\n",
    "    cats = [\n",
    "        'talk.politics.mideast',                                # Wolrd 0\n",
    "        'rec.sport.hockey', 'rec.sport.baseball',               # Sports 1\n",
    "        # 'misc.forsale',                                       # Business 2\n",
    "        'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', # Sci/Tech 3\n",
    "    ]\n",
    "\n",
    "    dataset = fetch_20newsgroups(\n",
    "        subset='all',\n",
    "        categories=cats,\n",
    "        remove=('headers', 'footers', 'quotes')\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame([dataset.data, dataset.target]).T\n",
    "    df.rename(columns={0:'text', 1: 'label'}, inplace=True)\n",
    "\n",
    "    mapper = {\n",
    "        0: 1,\n",
    "        1: 1,\n",
    "        2: 3,\n",
    "        3: 3,\n",
    "        4: 3,\n",
    "        5: 3,\n",
    "        6: 0,\n",
    "    }\n",
    "\n",
    "    df.label = df.label.map(mapper)\n",
    "    df.text = df.text.replace('\\n', ' ', regex=True).str.strip()\n",
    "\n",
    "    test_dataset = Dataset.from_pandas(df)\n",
    "    \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['ORIG', INV', 'SIB', 'INVSIB', 'TextMix', 'SentMix', 'WordMix']\n",
    "# ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nq1i8QiBtY0e"
   },
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['roberta-base', 'xlnet-base-cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "59b96dd300ae4a56b2d58ca0de0bb7f6",
      "e3c71b92f2a0484bb70123a86f855f9d",
      "dd27134d896448b6b385ce45da7556ee",
      "c92040617a854d8d96cc8ba678f0b271",
      "367cfe385d38427dbdf4325a70c0dc2e",
      "f86a86b6b9c64cc989e89b27693d8a2f",
      "14dc24ef59d341a88d1bdb69f3cacde6",
      "46cc6e7671244f1d9167855a45a36af8",
      "81821a97e02445539ccabcc2091cba95",
      "212a6447739d45b5b57e5815ff538f57",
      "4b1f7506e1a44d109d918b1f16d6bb75",
      "f177b91513ec4039bc7c6e61d15db9a2",
      "00554915f7ad47b9b80d65294dbfdd37",
      "d5f641be531341dbb007330b7e245169",
      "7158ce3f315647aba9299519fcec4be7",
      "0768ccf7a2e64f819c7401d7db258d16"
     ]
    },
    "id": "T-krnPy6TDSB",
    "outputId": "7161b883-f15a-449f-86fa-e8bbbfc6e9c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015ce99afb514d5399d6026df463b0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cf2a7cd0804bfe88c5c0deab7d12af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c980c33825b04d18a2d326d25341b485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rename_column_ is deprecated and will be removed in the next major version of datasets. Use the dataset.rename_column method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='11500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 11500/216000 1:05:44 < 19:29:08, 2.92 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.391800</td>\n",
       "      <td>1.279394</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.415678</td>\n",
       "      <td>0.524844</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>98.053100</td>\n",
       "      <td>77.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.744924</td>\n",
       "      <td>0.851316</td>\n",
       "      <td>0.851317</td>\n",
       "      <td>0.855698</td>\n",
       "      <td>0.851316</td>\n",
       "      <td>98.809300</td>\n",
       "      <td>76.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.365533</td>\n",
       "      <td>0.884737</td>\n",
       "      <td>0.884499</td>\n",
       "      <td>0.886943</td>\n",
       "      <td>0.884737</td>\n",
       "      <td>98.529400</td>\n",
       "      <td>77.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.476200</td>\n",
       "      <td>0.394324</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.894711</td>\n",
       "      <td>0.895307</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>98.491000</td>\n",
       "      <td>77.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>0.428221</td>\n",
       "      <td>0.901842</td>\n",
       "      <td>0.901770</td>\n",
       "      <td>0.902269</td>\n",
       "      <td>0.901842</td>\n",
       "      <td>98.469000</td>\n",
       "      <td>77.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.899079</td>\n",
       "      <td>0.898208</td>\n",
       "      <td>0.902952</td>\n",
       "      <td>0.899079</td>\n",
       "      <td>98.545500</td>\n",
       "      <td>77.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.426663</td>\n",
       "      <td>0.908421</td>\n",
       "      <td>0.908615</td>\n",
       "      <td>0.910561</td>\n",
       "      <td>0.908421</td>\n",
       "      <td>98.642200</td>\n",
       "      <td>77.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.397863</td>\n",
       "      <td>0.908421</td>\n",
       "      <td>0.908513</td>\n",
       "      <td>0.910502</td>\n",
       "      <td>0.908421</td>\n",
       "      <td>98.642600</td>\n",
       "      <td>77.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.433700</td>\n",
       "      <td>0.582612</td>\n",
       "      <td>0.889342</td>\n",
       "      <td>0.889155</td>\n",
       "      <td>0.893778</td>\n",
       "      <td>0.889342</td>\n",
       "      <td>98.658000</td>\n",
       "      <td>77.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.518400</td>\n",
       "      <td>0.435768</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>0.909190</td>\n",
       "      <td>0.911630</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>98.606500</td>\n",
       "      <td>77.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>0.424632</td>\n",
       "      <td>0.913289</td>\n",
       "      <td>0.913030</td>\n",
       "      <td>0.913147</td>\n",
       "      <td>0.913289</td>\n",
       "      <td>98.626500</td>\n",
       "      <td>77.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.450107</td>\n",
       "      <td>0.905789</td>\n",
       "      <td>0.905407</td>\n",
       "      <td>0.906154</td>\n",
       "      <td>0.905789</td>\n",
       "      <td>98.619500</td>\n",
       "      <td>77.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>0.398108</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>98.609200</td>\n",
       "      <td>77.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.388855</td>\n",
       "      <td>0.908289</td>\n",
       "      <td>0.908479</td>\n",
       "      <td>0.912123</td>\n",
       "      <td>0.908289</td>\n",
       "      <td>98.583300</td>\n",
       "      <td>77.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.428800</td>\n",
       "      <td>0.402034</td>\n",
       "      <td>0.906316</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.909043</td>\n",
       "      <td>0.906316</td>\n",
       "      <td>98.594900</td>\n",
       "      <td>77.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.436438</td>\n",
       "      <td>0.915132</td>\n",
       "      <td>0.915032</td>\n",
       "      <td>0.915895</td>\n",
       "      <td>0.915132</td>\n",
       "      <td>98.592300</td>\n",
       "      <td>77.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.437312</td>\n",
       "      <td>0.911447</td>\n",
       "      <td>0.911431</td>\n",
       "      <td>0.911902</td>\n",
       "      <td>0.911447</td>\n",
       "      <td>98.640200</td>\n",
       "      <td>77.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.443450</td>\n",
       "      <td>0.910132</td>\n",
       "      <td>0.910063</td>\n",
       "      <td>0.910599</td>\n",
       "      <td>0.910132</td>\n",
       "      <td>98.632100</td>\n",
       "      <td>77.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>0.393307</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.915850</td>\n",
       "      <td>0.916583</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>98.653600</td>\n",
       "      <td>77.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.435973</td>\n",
       "      <td>0.908816</td>\n",
       "      <td>0.908719</td>\n",
       "      <td>0.909905</td>\n",
       "      <td>0.908816</td>\n",
       "      <td>98.685400</td>\n",
       "      <td>77.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.445250</td>\n",
       "      <td>0.910921</td>\n",
       "      <td>0.910540</td>\n",
       "      <td>0.910539</td>\n",
       "      <td>0.910921</td>\n",
       "      <td>98.674900</td>\n",
       "      <td>77.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>0.427776</td>\n",
       "      <td>0.903684</td>\n",
       "      <td>0.903926</td>\n",
       "      <td>0.906662</td>\n",
       "      <td>0.903684</td>\n",
       "      <td>98.624500</td>\n",
       "      <td>77.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.469036</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>0.909050</td>\n",
       "      <td>0.912481</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>98.611200</td>\n",
       "      <td>77.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.3981076180934906, 'eval_accuracy': 0.9157894736842105, 'eval_f1': 0.9156453459413902, 'eval_precision': 0.9162553217551063, 'eval_recall': 0.9157894736842105, 'eval_runtime': 99.1891, 'eval_samples_per_second': 76.621, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.7608842849731445, 'eval_accuracy': 0.8225127087872186, 'eval_f1': 0.6387646402833478, 'eval_precision': 0.6607739782946607, 'eval_recall': 0.6189966234759033, 'eval_runtime': 89.9924, 'eval_samples_per_second': 76.506, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d017a0771a14bc694b4f9aa6e88d5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06055b26d44e4d52948b0dbc6089498f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37893716e6240ac90bbc9330868d056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='8000' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8000/216000 1:43:11 < 44:43:26, 1.29 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.401400</td>\n",
       "      <td>1.339915</td>\n",
       "      <td>0.373342</td>\n",
       "      <td>313.537100</td>\n",
       "      <td>76.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.186100</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>0.693596</td>\n",
       "      <td>312.860400</td>\n",
       "      <td>76.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.753800</td>\n",
       "      <td>0.625990</td>\n",
       "      <td>0.776996</td>\n",
       "      <td>312.843200</td>\n",
       "      <td>76.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.576724</td>\n",
       "      <td>0.780144</td>\n",
       "      <td>313.373000</td>\n",
       "      <td>76.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>0.583685</td>\n",
       "      <td>0.769466</td>\n",
       "      <td>313.515500</td>\n",
       "      <td>76.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.569334</td>\n",
       "      <td>0.789183</td>\n",
       "      <td>313.646100</td>\n",
       "      <td>76.519000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.617323</td>\n",
       "      <td>0.768270</td>\n",
       "      <td>313.700100</td>\n",
       "      <td>76.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>0.586748</td>\n",
       "      <td>0.781876</td>\n",
       "      <td>313.680200</td>\n",
       "      <td>76.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>0.584709</td>\n",
       "      <td>0.777206</td>\n",
       "      <td>313.649900</td>\n",
       "      <td>76.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.603300</td>\n",
       "      <td>0.568350</td>\n",
       "      <td>0.759837</td>\n",
       "      <td>313.640800</td>\n",
       "      <td>76.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.594740</td>\n",
       "      <td>0.774581</td>\n",
       "      <td>313.638800</td>\n",
       "      <td>76.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.542261</td>\n",
       "      <td>0.784900</td>\n",
       "      <td>313.669500</td>\n",
       "      <td>76.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.528227</td>\n",
       "      <td>0.764461</td>\n",
       "      <td>313.588800</td>\n",
       "      <td>76.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>0.576942</td>\n",
       "      <td>0.776066</td>\n",
       "      <td>313.581800</td>\n",
       "      <td>76.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.565814</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>313.589200</td>\n",
       "      <td>76.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.634700</td>\n",
       "      <td>0.557632</td>\n",
       "      <td>0.780218</td>\n",
       "      <td>313.547800</td>\n",
       "      <td>76.543000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+SIB\n",
      "{'eval_loss': 24.4759578704834, 'eval_accuracy': 0.9089473684210526, 'eval_f1': 0.9086363385138754, 'eval_precision': 0.9091866368529096, 'eval_recall': 0.9089473684210526, 'eval_runtime': 99.5726, 'eval_samples_per_second': 76.326, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+SIB\n",
      "{'eval_loss': 29.666675567626953, 'eval_accuracy': 0.9003631082062454, 'eval_f1': 0.6651768987063545, 'eval_precision': 0.6838086494709936, 'eval_recall': 0.6498429853678157, 'eval_runtime': 90.4223, 'eval_samples_per_second': 76.143, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ee39d5859143559ebe1e8fc2a8556c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04665ca1121416782a1011a0ccffbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c6fe28466a495f83fd75b4ead5c6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='18000' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18000/216000 14:06:13 < 155:09:25, 0.35 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.364900</td>\n",
       "      <td>1.291298</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>314.664700</td>\n",
       "      <td>76.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.058400</td>\n",
       "      <td>0.760444</td>\n",
       "      <td>0.788323</td>\n",
       "      <td>314.090600</td>\n",
       "      <td>76.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.816937</td>\n",
       "      <td>314.107200</td>\n",
       "      <td>76.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.508033</td>\n",
       "      <td>0.833269</td>\n",
       "      <td>314.071500</td>\n",
       "      <td>76.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.545907</td>\n",
       "      <td>0.835639</td>\n",
       "      <td>314.051500</td>\n",
       "      <td>76.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.496954</td>\n",
       "      <td>0.830333</td>\n",
       "      <td>314.208400</td>\n",
       "      <td>76.382000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.543800</td>\n",
       "      <td>0.560293</td>\n",
       "      <td>0.826574</td>\n",
       "      <td>314.087800</td>\n",
       "      <td>76.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>0.544773</td>\n",
       "      <td>0.826733</td>\n",
       "      <td>314.223400</td>\n",
       "      <td>76.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.532814</td>\n",
       "      <td>0.835370</td>\n",
       "      <td>314.050000</td>\n",
       "      <td>76.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.522391</td>\n",
       "      <td>0.832855</td>\n",
       "      <td>314.045600</td>\n",
       "      <td>76.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.592345</td>\n",
       "      <td>0.828928</td>\n",
       "      <td>314.119600</td>\n",
       "      <td>76.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.528100</td>\n",
       "      <td>0.581878</td>\n",
       "      <td>0.819376</td>\n",
       "      <td>313.971100</td>\n",
       "      <td>76.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.439806</td>\n",
       "      <td>0.835392</td>\n",
       "      <td>313.969000</td>\n",
       "      <td>76.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.507268</td>\n",
       "      <td>0.840469</td>\n",
       "      <td>314.114700</td>\n",
       "      <td>76.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.463577</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>314.020800</td>\n",
       "      <td>76.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.489122</td>\n",
       "      <td>0.834559</td>\n",
       "      <td>313.983700</td>\n",
       "      <td>76.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.433275</td>\n",
       "      <td>0.841590</td>\n",
       "      <td>314.016900</td>\n",
       "      <td>76.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.487800</td>\n",
       "      <td>0.531981</td>\n",
       "      <td>0.841821</td>\n",
       "      <td>314.074300</td>\n",
       "      <td>76.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>0.473976</td>\n",
       "      <td>0.834169</td>\n",
       "      <td>314.163500</td>\n",
       "      <td>76.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.487707</td>\n",
       "      <td>0.838635</td>\n",
       "      <td>314.198300</td>\n",
       "      <td>76.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.454219</td>\n",
       "      <td>0.840803</td>\n",
       "      <td>314.126900</td>\n",
       "      <td>76.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.522600</td>\n",
       "      <td>0.566117</td>\n",
       "      <td>0.823176</td>\n",
       "      <td>314.235800</td>\n",
       "      <td>76.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.488300</td>\n",
       "      <td>0.507215</td>\n",
       "      <td>0.846050</td>\n",
       "      <td>314.131400</td>\n",
       "      <td>76.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.440078</td>\n",
       "      <td>0.844938</td>\n",
       "      <td>314.133800</td>\n",
       "      <td>76.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.496756</td>\n",
       "      <td>0.832192</td>\n",
       "      <td>37160.348100</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.484113</td>\n",
       "      <td>0.850246</td>\n",
       "      <td>313.429100</td>\n",
       "      <td>76.572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.471200</td>\n",
       "      <td>0.510628</td>\n",
       "      <td>0.844211</td>\n",
       "      <td>312.930900</td>\n",
       "      <td>76.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.501067</td>\n",
       "      <td>0.845098</td>\n",
       "      <td>313.054400</td>\n",
       "      <td>76.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.530400</td>\n",
       "      <td>0.489067</td>\n",
       "      <td>0.835541</td>\n",
       "      <td>313.083600</td>\n",
       "      <td>76.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.510903</td>\n",
       "      <td>0.834785</td>\n",
       "      <td>312.993400</td>\n",
       "      <td>76.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>0.548091</td>\n",
       "      <td>0.825389</td>\n",
       "      <td>312.983500</td>\n",
       "      <td>76.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>0.463973</td>\n",
       "      <td>0.836785</td>\n",
       "      <td>313.035600</td>\n",
       "      <td>76.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.525900</td>\n",
       "      <td>0.554073</td>\n",
       "      <td>0.818347</td>\n",
       "      <td>313.024300</td>\n",
       "      <td>76.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>0.519573</td>\n",
       "      <td>0.833197</td>\n",
       "      <td>312.771800</td>\n",
       "      <td>76.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.491373</td>\n",
       "      <td>0.843170</td>\n",
       "      <td>312.868300</td>\n",
       "      <td>76.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.564793</td>\n",
       "      <td>0.826746</td>\n",
       "      <td>312.940500</td>\n",
       "      <td>76.692000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 30.694591522216797, 'eval_accuracy': 0.9184210526315789, 'eval_f1': 0.9183232318745234, 'eval_precision': 0.9203697597715643, 'eval_recall': 0.918421052631579, 'eval_runtime': 99.1659, 'eval_samples_per_second': 76.639, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 35.89020538330078, 'eval_accuracy': 0.8530137981118373, 'eval_f1': 0.6478650292411576, 'eval_precision': 0.6847052801624964, 'eval_recall': 0.6173132652899586, 'eval_runtime': 90.0866, 'eval_samples_per_second': 76.426, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85f8c968a8e4a17ac10578e131289ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43104f24e0c348fb8219143fc4f60c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4555a99f310c43e8b5f059bea8a5cb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='12500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 12500/216000 2:41:17 < 43:46:10, 1.29 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.367600</td>\n",
       "      <td>1.199957</td>\n",
       "      <td>0.468375</td>\n",
       "      <td>314.337500</td>\n",
       "      <td>76.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.018700</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.711344</td>\n",
       "      <td>313.975300</td>\n",
       "      <td>76.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.622826</td>\n",
       "      <td>0.767936</td>\n",
       "      <td>313.975500</td>\n",
       "      <td>76.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>0.562511</td>\n",
       "      <td>0.788578</td>\n",
       "      <td>313.854200</td>\n",
       "      <td>76.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.594700</td>\n",
       "      <td>0.537453</td>\n",
       "      <td>0.790736</td>\n",
       "      <td>313.862300</td>\n",
       "      <td>76.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.572446</td>\n",
       "      <td>0.769876</td>\n",
       "      <td>313.883800</td>\n",
       "      <td>76.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.598700</td>\n",
       "      <td>0.563389</td>\n",
       "      <td>0.775516</td>\n",
       "      <td>313.729800</td>\n",
       "      <td>76.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.563921</td>\n",
       "      <td>0.781201</td>\n",
       "      <td>313.775600</td>\n",
       "      <td>76.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.587844</td>\n",
       "      <td>0.790214</td>\n",
       "      <td>313.908400</td>\n",
       "      <td>76.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.543700</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>0.791080</td>\n",
       "      <td>313.913900</td>\n",
       "      <td>76.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>313.876500</td>\n",
       "      <td>76.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.613700</td>\n",
       "      <td>0.576236</td>\n",
       "      <td>0.774679</td>\n",
       "      <td>313.861700</td>\n",
       "      <td>76.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.493526</td>\n",
       "      <td>0.804884</td>\n",
       "      <td>313.684400</td>\n",
       "      <td>76.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.546700</td>\n",
       "      <td>0.547329</td>\n",
       "      <td>0.812592</td>\n",
       "      <td>313.906600</td>\n",
       "      <td>76.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.498152</td>\n",
       "      <td>0.816447</td>\n",
       "      <td>313.734600</td>\n",
       "      <td>76.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.591900</td>\n",
       "      <td>0.538178</td>\n",
       "      <td>0.781954</td>\n",
       "      <td>313.768400</td>\n",
       "      <td>76.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.510550</td>\n",
       "      <td>0.805507</td>\n",
       "      <td>313.973800</td>\n",
       "      <td>76.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.518111</td>\n",
       "      <td>0.804669</td>\n",
       "      <td>313.869300</td>\n",
       "      <td>76.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>0.553975</td>\n",
       "      <td>0.790079</td>\n",
       "      <td>313.835700</td>\n",
       "      <td>76.473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.529600</td>\n",
       "      <td>0.544108</td>\n",
       "      <td>0.790196</td>\n",
       "      <td>313.798200</td>\n",
       "      <td>76.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.618800</td>\n",
       "      <td>0.529048</td>\n",
       "      <td>0.776155</td>\n",
       "      <td>313.858400</td>\n",
       "      <td>76.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.544536</td>\n",
       "      <td>0.775566</td>\n",
       "      <td>313.934900</td>\n",
       "      <td>76.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.539320</td>\n",
       "      <td>0.815053</td>\n",
       "      <td>313.942300</td>\n",
       "      <td>76.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.572158</td>\n",
       "      <td>0.781314</td>\n",
       "      <td>313.958100</td>\n",
       "      <td>76.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.586700</td>\n",
       "      <td>0.575582</td>\n",
       "      <td>0.792326</td>\n",
       "      <td>313.852800</td>\n",
       "      <td>76.469000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 27.844295501708984, 'eval_accuracy': 0.9173684210526316, 'eval_f1': 0.9173654941024086, 'eval_precision': 0.9178486123968598, 'eval_recall': 0.9173684210526316, 'eval_runtime': 99.2833, 'eval_samples_per_second': 76.549, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 29.816225051879883, 'eval_accuracy': 0.8753812636165578, 'eval_f1': 0.6571557615048226, 'eval_precision': 0.6771921957433351, 'eval_recall': 0.6397893704717308, 'eval_runtime': 90.1324, 'eval_samples_per_second': 76.388, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382f90e294354c5882260085380ae51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e40ce67ac849239334a44fd665e562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afbe2a92a2046eb89e17480dfa1313d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='20500' max='324000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 20500/324000 75:58:33 < 1124:55:26, 0.07 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.151100</td>\n",
       "      <td>1.114268</td>\n",
       "      <td>0.323402</td>\n",
       "      <td>470.123300</td>\n",
       "      <td>76.576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.033600</td>\n",
       "      <td>0.884952</td>\n",
       "      <td>0.521566</td>\n",
       "      <td>469.438000</td>\n",
       "      <td>76.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.763100</td>\n",
       "      <td>0.649266</td>\n",
       "      <td>0.602489</td>\n",
       "      <td>18897.154400</td>\n",
       "      <td>1.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>0.572656</td>\n",
       "      <td>0.618744</td>\n",
       "      <td>88473.852200</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.512929</td>\n",
       "      <td>0.647215</td>\n",
       "      <td>468.665400</td>\n",
       "      <td>76.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.501517</td>\n",
       "      <td>0.642441</td>\n",
       "      <td>469.326900</td>\n",
       "      <td>76.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.505045</td>\n",
       "      <td>0.631754</td>\n",
       "      <td>469.519300</td>\n",
       "      <td>76.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.494097</td>\n",
       "      <td>0.651360</td>\n",
       "      <td>469.577600</td>\n",
       "      <td>76.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.500400</td>\n",
       "      <td>0.506767</td>\n",
       "      <td>0.651022</td>\n",
       "      <td>469.618600</td>\n",
       "      <td>76.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.496959</td>\n",
       "      <td>0.651673</td>\n",
       "      <td>469.654400</td>\n",
       "      <td>76.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.455462</td>\n",
       "      <td>0.659262</td>\n",
       "      <td>66418.771600</td>\n",
       "      <td>0.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.495505</td>\n",
       "      <td>0.655642</td>\n",
       "      <td>469.855200</td>\n",
       "      <td>76.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.485500</td>\n",
       "      <td>0.462275</td>\n",
       "      <td>0.662584</td>\n",
       "      <td>470.232000</td>\n",
       "      <td>76.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.498400</td>\n",
       "      <td>0.460948</td>\n",
       "      <td>0.667625</td>\n",
       "      <td>469.398200</td>\n",
       "      <td>76.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.480385</td>\n",
       "      <td>0.654357</td>\n",
       "      <td>469.194200</td>\n",
       "      <td>76.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>0.496083</td>\n",
       "      <td>0.644552</td>\n",
       "      <td>469.193700</td>\n",
       "      <td>76.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.467528</td>\n",
       "      <td>0.651410</td>\n",
       "      <td>468.910300</td>\n",
       "      <td>76.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.515486</td>\n",
       "      <td>0.640564</td>\n",
       "      <td>469.322200</td>\n",
       "      <td>76.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.485990</td>\n",
       "      <td>0.647673</td>\n",
       "      <td>469.727900</td>\n",
       "      <td>76.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.473103</td>\n",
       "      <td>0.658712</td>\n",
       "      <td>469.733800</td>\n",
       "      <td>76.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.491297</td>\n",
       "      <td>0.672103</td>\n",
       "      <td>469.849300</td>\n",
       "      <td>76.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.478654</td>\n",
       "      <td>0.648304</td>\n",
       "      <td>469.889900</td>\n",
       "      <td>76.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.506646</td>\n",
       "      <td>0.619402</td>\n",
       "      <td>470.060600</td>\n",
       "      <td>76.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.529176</td>\n",
       "      <td>0.656626</td>\n",
       "      <td>470.098400</td>\n",
       "      <td>76.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.467713</td>\n",
       "      <td>0.660313</td>\n",
       "      <td>470.171500</td>\n",
       "      <td>76.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.452795</td>\n",
       "      <td>0.680658</td>\n",
       "      <td>469.521500</td>\n",
       "      <td>76.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.473837</td>\n",
       "      <td>0.652216</td>\n",
       "      <td>469.528500</td>\n",
       "      <td>76.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.466153</td>\n",
       "      <td>0.672796</td>\n",
       "      <td>469.166400</td>\n",
       "      <td>76.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>0.477068</td>\n",
       "      <td>0.664126</td>\n",
       "      <td>469.026500</td>\n",
       "      <td>76.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.469900</td>\n",
       "      <td>0.485553</td>\n",
       "      <td>0.673551</td>\n",
       "      <td>469.176200</td>\n",
       "      <td>76.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.477653</td>\n",
       "      <td>0.681194</td>\n",
       "      <td>469.708800</td>\n",
       "      <td>76.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.460200</td>\n",
       "      <td>0.465943</td>\n",
       "      <td>0.670841</td>\n",
       "      <td>469.664400</td>\n",
       "      <td>76.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.671069</td>\n",
       "      <td>470.206200</td>\n",
       "      <td>76.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.450711</td>\n",
       "      <td>0.669966</td>\n",
       "      <td>470.283900</td>\n",
       "      <td>76.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.472383</td>\n",
       "      <td>0.679797</td>\n",
       "      <td>470.350500</td>\n",
       "      <td>76.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.489125</td>\n",
       "      <td>0.650552</td>\n",
       "      <td>470.582800</td>\n",
       "      <td>76.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.473436</td>\n",
       "      <td>0.661287</td>\n",
       "      <td>470.605300</td>\n",
       "      <td>76.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.506148</td>\n",
       "      <td>0.664692</td>\n",
       "      <td>470.733400</td>\n",
       "      <td>76.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.531176</td>\n",
       "      <td>0.656900</td>\n",
       "      <td>470.718200</td>\n",
       "      <td>76.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.472850</td>\n",
       "      <td>0.666786</td>\n",
       "      <td>470.705100</td>\n",
       "      <td>76.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.499005</td>\n",
       "      <td>0.672253</td>\n",
       "      <td>470.515000</td>\n",
       "      <td>76.512000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 30.52907943725586, 'eval_accuracy': 0.9234210526315789, 'eval_f1': 0.9235062438613701, 'eval_precision': 0.9243024338768785, 'eval_recall': 0.9234210526315789, 'eval_runtime': 98.7901, 'eval_samples_per_second': 76.931, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 31.589269638061523, 'eval_accuracy': 0.8697167755991285, 'eval_f1': 0.6420058179069323, 'eval_precision': 0.6875337737021379, 'eval_recall': 0.6091545591811411, 'eval_runtime': 89.6363, 'eval_samples_per_second': 76.81, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f66701b4704e2b95a044947d8d335d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182183959bc54587a7a1088b634fdeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02c136e8bc5472f8083bd7af6809099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='16500' max='432000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16500/432000 6:26:34 < 162:15:53, 0.71 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.990300</td>\n",
       "      <td>0.944980</td>\n",
       "      <td>0.233069</td>\n",
       "      <td>628.090400</td>\n",
       "      <td>76.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.807549</td>\n",
       "      <td>0.400352</td>\n",
       "      <td>627.847600</td>\n",
       "      <td>76.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.615274</td>\n",
       "      <td>0.474420</td>\n",
       "      <td>627.855400</td>\n",
       "      <td>76.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>0.509235</td>\n",
       "      <td>628.458600</td>\n",
       "      <td>76.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.498900</td>\n",
       "      <td>0.460997</td>\n",
       "      <td>0.521279</td>\n",
       "      <td>628.916700</td>\n",
       "      <td>76.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.448890</td>\n",
       "      <td>0.521158</td>\n",
       "      <td>629.028600</td>\n",
       "      <td>76.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.447766</td>\n",
       "      <td>0.524062</td>\n",
       "      <td>629.417000</td>\n",
       "      <td>76.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.438179</td>\n",
       "      <td>0.512496</td>\n",
       "      <td>629.792500</td>\n",
       "      <td>76.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.418281</td>\n",
       "      <td>0.527870</td>\n",
       "      <td>629.781300</td>\n",
       "      <td>76.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.424507</td>\n",
       "      <td>0.519998</td>\n",
       "      <td>629.835700</td>\n",
       "      <td>76.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.410666</td>\n",
       "      <td>0.533117</td>\n",
       "      <td>629.764000</td>\n",
       "      <td>76.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.398100</td>\n",
       "      <td>0.429429</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>629.840000</td>\n",
       "      <td>76.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.424093</td>\n",
       "      <td>0.517602</td>\n",
       "      <td>629.960600</td>\n",
       "      <td>76.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.415745</td>\n",
       "      <td>0.515969</td>\n",
       "      <td>629.904300</td>\n",
       "      <td>76.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.412300</td>\n",
       "      <td>0.416428</td>\n",
       "      <td>0.537408</td>\n",
       "      <td>629.874200</td>\n",
       "      <td>76.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.405016</td>\n",
       "      <td>0.533398</td>\n",
       "      <td>629.235900</td>\n",
       "      <td>76.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.415193</td>\n",
       "      <td>0.530567</td>\n",
       "      <td>628.621800</td>\n",
       "      <td>76.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.409088</td>\n",
       "      <td>0.523753</td>\n",
       "      <td>628.336700</td>\n",
       "      <td>76.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.441592</td>\n",
       "      <td>0.543974</td>\n",
       "      <td>628.434900</td>\n",
       "      <td>76.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.402712</td>\n",
       "      <td>0.536695</td>\n",
       "      <td>629.566700</td>\n",
       "      <td>76.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.404510</td>\n",
       "      <td>0.540176</td>\n",
       "      <td>629.824300</td>\n",
       "      <td>76.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.390583</td>\n",
       "      <td>0.545740</td>\n",
       "      <td>630.089800</td>\n",
       "      <td>76.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.398664</td>\n",
       "      <td>0.554655</td>\n",
       "      <td>630.018300</td>\n",
       "      <td>76.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.401200</td>\n",
       "      <td>0.441380</td>\n",
       "      <td>0.534445</td>\n",
       "      <td>630.191000</td>\n",
       "      <td>76.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.397716</td>\n",
       "      <td>0.549293</td>\n",
       "      <td>630.184600</td>\n",
       "      <td>76.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.410892</td>\n",
       "      <td>0.540425</td>\n",
       "      <td>630.036200</td>\n",
       "      <td>76.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.429800</td>\n",
       "      <td>0.390628</td>\n",
       "      <td>0.547317</td>\n",
       "      <td>630.350900</td>\n",
       "      <td>76.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.417333</td>\n",
       "      <td>0.542503</td>\n",
       "      <td>629.855500</td>\n",
       "      <td>76.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.547806</td>\n",
       "      <td>630.043800</td>\n",
       "      <td>76.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.416472</td>\n",
       "      <td>0.534749</td>\n",
       "      <td>630.242400</td>\n",
       "      <td>76.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.395254</td>\n",
       "      <td>0.535758</td>\n",
       "      <td>629.840500</td>\n",
       "      <td>76.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.381684</td>\n",
       "      <td>0.550451</td>\n",
       "      <td>630.042300</td>\n",
       "      <td>76.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.520989</td>\n",
       "      <td>629.845400</td>\n",
       "      <td>76.209000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 29.310897827148438, 'eval_accuracy': 0.9189473684210526, 'eval_f1': 0.9187454210176963, 'eval_precision': 0.9192500556299591, 'eval_recall': 0.9189473684210525, 'eval_runtime': 99.5289, 'eval_samples_per_second': 76.36, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 33.30519104003906, 'eval_accuracy': 0.8854030501089325, 'eval_f1': 0.6563653404860761, 'eval_precision': 0.6732143055544277, 'eval_recall': 0.6416973260155483, 'eval_runtime': 90.4387, 'eval_samples_per_second': 76.129, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39229b4bf3b4f4191fe2ad3b7feacc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9360d52f5a48348fd11085fe2fa5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb96c3eeb1df4e5d81bc5f28c5f05869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10000' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 10000/216000 2:09:03 < 44:19:03, 1.29 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.531600</td>\n",
       "      <td>8.248725</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>312.292700</td>\n",
       "      <td>76.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.447200</td>\n",
       "      <td>8.248702</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>312.054800</td>\n",
       "      <td>76.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>8.666300</td>\n",
       "      <td>8.248710</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>311.880900</td>\n",
       "      <td>76.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.343500</td>\n",
       "      <td>8.248634</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>311.953000</td>\n",
       "      <td>76.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.161500</td>\n",
       "      <td>8.248737</td>\n",
       "      <td>1.755000</td>\n",
       "      <td>312.029300</td>\n",
       "      <td>76.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>8.553300</td>\n",
       "      <td>8.248922</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>311.862200</td>\n",
       "      <td>76.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>8.327400</td>\n",
       "      <td>8.248660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.837300</td>\n",
       "      <td>76.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>8.438700</td>\n",
       "      <td>8.248704</td>\n",
       "      <td>0.039750</td>\n",
       "      <td>311.928700</td>\n",
       "      <td>76.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>8.242300</td>\n",
       "      <td>8.248625</td>\n",
       "      <td>1.605625</td>\n",
       "      <td>311.778300</td>\n",
       "      <td>76.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>8.249500</td>\n",
       "      <td>8.249076</td>\n",
       "      <td>2.996375</td>\n",
       "      <td>311.875900</td>\n",
       "      <td>76.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>8.504700</td>\n",
       "      <td>8.248606</td>\n",
       "      <td>0.039375</td>\n",
       "      <td>311.728000</td>\n",
       "      <td>76.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>8.474800</td>\n",
       "      <td>8.248585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.999500</td>\n",
       "      <td>76.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>8.009100</td>\n",
       "      <td>8.248577</td>\n",
       "      <td>1.474500</td>\n",
       "      <td>311.958500</td>\n",
       "      <td>76.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>8.504900</td>\n",
       "      <td>8.248542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.835000</td>\n",
       "      <td>76.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>8.201000</td>\n",
       "      <td>8.248737</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>311.892000</td>\n",
       "      <td>76.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>8.149200</td>\n",
       "      <td>8.248485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.736800</td>\n",
       "      <td>76.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>8.578300</td>\n",
       "      <td>8.249107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.835200</td>\n",
       "      <td>76.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>8.145400</td>\n",
       "      <td>8.248481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.657000</td>\n",
       "      <td>77.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>8.245100</td>\n",
       "      <td>8.248720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.618800</td>\n",
       "      <td>77.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>8.518800</td>\n",
       "      <td>8.248509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>311.519400</td>\n",
       "      <td>77.042000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+INV\n",
      "{'eval_loss': 8.318387985229492, 'eval_accuracy': 0.24986842105263157, 'eval_f1': 0.100031605562579, 'eval_precision': 0.06253292939936776, 'eval_recall': 0.24986842105263157, 'eval_runtime': 98.7048, 'eval_samples_per_second': 76.997, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+INV\n",
      "{'eval_loss': 11.154783248901367, 'eval_accuracy': 0.00014524328249818446, 'eval_f1': 0.000250501002004008, 'eval_precision': 0.08333333333333333, 'eval_recall': 0.0001254390366281987, 'eval_runtime': 89.9665, 'eval_samples_per_second': 76.529, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b105f818fd443c4b223203e4b1cdefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3586b9f1ef1547539eacec78cec0af98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f41c33d91a14a2d87350ed9ac07214a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='17000' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17000/216000 3:39:51 < 42:53:52, 1.29 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.389100</td>\n",
       "      <td>1.377349</td>\n",
       "      <td>0.244517</td>\n",
       "      <td>312.283600</td>\n",
       "      <td>76.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.025400</td>\n",
       "      <td>0.634774</td>\n",
       "      <td>0.771021</td>\n",
       "      <td>311.679800</td>\n",
       "      <td>77.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.598100</td>\n",
       "      <td>0.640084</td>\n",
       "      <td>0.785710</td>\n",
       "      <td>311.493000</td>\n",
       "      <td>77.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>0.568483</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>311.488500</td>\n",
       "      <td>77.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.626662</td>\n",
       "      <td>0.789294</td>\n",
       "      <td>311.509700</td>\n",
       "      <td>77.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>0.592289</td>\n",
       "      <td>0.790893</td>\n",
       "      <td>311.611600</td>\n",
       "      <td>77.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.638700</td>\n",
       "      <td>0.612530</td>\n",
       "      <td>0.774661</td>\n",
       "      <td>311.806900</td>\n",
       "      <td>76.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.588685</td>\n",
       "      <td>0.796113</td>\n",
       "      <td>311.297400</td>\n",
       "      <td>77.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>0.592107</td>\n",
       "      <td>0.798151</td>\n",
       "      <td>310.837400</td>\n",
       "      <td>77.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.620400</td>\n",
       "      <td>0.597476</td>\n",
       "      <td>0.740854</td>\n",
       "      <td>310.694200</td>\n",
       "      <td>77.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>0.561522</td>\n",
       "      <td>0.788753</td>\n",
       "      <td>310.848400</td>\n",
       "      <td>77.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.567953</td>\n",
       "      <td>0.784162</td>\n",
       "      <td>310.958900</td>\n",
       "      <td>77.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>0.511576</td>\n",
       "      <td>0.786179</td>\n",
       "      <td>311.054600</td>\n",
       "      <td>77.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.643070</td>\n",
       "      <td>0.774351</td>\n",
       "      <td>311.218200</td>\n",
       "      <td>77.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>0.543171</td>\n",
       "      <td>0.785292</td>\n",
       "      <td>311.385100</td>\n",
       "      <td>77.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.594128</td>\n",
       "      <td>0.757690</td>\n",
       "      <td>311.492400</td>\n",
       "      <td>77.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.614400</td>\n",
       "      <td>0.540835</td>\n",
       "      <td>0.778335</td>\n",
       "      <td>311.381000</td>\n",
       "      <td>77.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.574751</td>\n",
       "      <td>0.789600</td>\n",
       "      <td>311.551200</td>\n",
       "      <td>77.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.559768</td>\n",
       "      <td>0.802087</td>\n",
       "      <td>311.450300</td>\n",
       "      <td>77.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.549576</td>\n",
       "      <td>0.793528</td>\n",
       "      <td>311.613500</td>\n",
       "      <td>77.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.598700</td>\n",
       "      <td>0.572684</td>\n",
       "      <td>0.759647</td>\n",
       "      <td>311.620200</td>\n",
       "      <td>77.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.674700</td>\n",
       "      <td>0.542216</td>\n",
       "      <td>0.777296</td>\n",
       "      <td>311.667100</td>\n",
       "      <td>77.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.574495</td>\n",
       "      <td>0.774310</td>\n",
       "      <td>311.678200</td>\n",
       "      <td>77.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.566894</td>\n",
       "      <td>0.804483</td>\n",
       "      <td>311.693300</td>\n",
       "      <td>76.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>0.768283</td>\n",
       "      <td>311.581400</td>\n",
       "      <td>77.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>0.566672</td>\n",
       "      <td>0.793305</td>\n",
       "      <td>311.606200</td>\n",
       "      <td>77.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.779173</td>\n",
       "      <td>311.625100</td>\n",
       "      <td>77.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>0.638745</td>\n",
       "      <td>0.788495</td>\n",
       "      <td>311.543700</td>\n",
       "      <td>77.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>0.626392</td>\n",
       "      <td>0.752518</td>\n",
       "      <td>311.585900</td>\n",
       "      <td>77.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.639528</td>\n",
       "      <td>0.751775</td>\n",
       "      <td>311.627400</td>\n",
       "      <td>77.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.567100</td>\n",
       "      <td>0.573019</td>\n",
       "      <td>0.770819</td>\n",
       "      <td>311.510100</td>\n",
       "      <td>77.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.626500</td>\n",
       "      <td>0.583036</td>\n",
       "      <td>0.748663</td>\n",
       "      <td>311.564400</td>\n",
       "      <td>77.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>0.624229</td>\n",
       "      <td>0.770629</td>\n",
       "      <td>311.576700</td>\n",
       "      <td>77.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>0.601789</td>\n",
       "      <td>0.726399</td>\n",
       "      <td>311.667900</td>\n",
       "      <td>77.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+SIB\n",
      "{'eval_loss': 27.992504119873047, 'eval_accuracy': 0.9146052631578947, 'eval_f1': 0.9146066311486704, 'eval_precision': 0.9151864499847272, 'eval_recall': 0.9146052631578947, 'eval_runtime': 98.1858, 'eval_samples_per_second': 77.404, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+SIB\n",
      "{'eval_loss': 33.876922607421875, 'eval_accuracy': 0.8152505446623094, 'eval_f1': 0.6161710661872044, 'eval_precision': 0.6353659433310554, 'eval_recall': 0.6082873968734226, 'eval_runtime': 89.5341, 'eval_samples_per_second': 76.898, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d15fd34fcf41378cf0c5f2eb28daa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbd8e61f6a5470c9e77c27231768817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344c23d4c9a44bfabe95721d77d18d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='17500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17500/216000 3:46:34 < 42:50:15, 1.29 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.382200</td>\n",
       "      <td>1.371978</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>312.674800</td>\n",
       "      <td>76.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.988600</td>\n",
       "      <td>0.558032</td>\n",
       "      <td>0.810924</td>\n",
       "      <td>312.443900</td>\n",
       "      <td>76.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.540100</td>\n",
       "      <td>0.542028</td>\n",
       "      <td>0.836299</td>\n",
       "      <td>312.414000</td>\n",
       "      <td>76.821000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.558300</td>\n",
       "      <td>0.538455</td>\n",
       "      <td>0.836084</td>\n",
       "      <td>312.535600</td>\n",
       "      <td>76.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.547300</td>\n",
       "      <td>0.544730</td>\n",
       "      <td>0.843620</td>\n",
       "      <td>312.429600</td>\n",
       "      <td>76.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>0.520598</td>\n",
       "      <td>0.838724</td>\n",
       "      <td>312.407200</td>\n",
       "      <td>76.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.585717</td>\n",
       "      <td>0.843131</td>\n",
       "      <td>312.526900</td>\n",
       "      <td>76.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.518247</td>\n",
       "      <td>0.830847</td>\n",
       "      <td>312.542300</td>\n",
       "      <td>76.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.521081</td>\n",
       "      <td>0.840007</td>\n",
       "      <td>312.639200</td>\n",
       "      <td>76.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>0.504393</td>\n",
       "      <td>0.843257</td>\n",
       "      <td>312.676400</td>\n",
       "      <td>76.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.601343</td>\n",
       "      <td>0.835406</td>\n",
       "      <td>312.586200</td>\n",
       "      <td>76.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>0.576595</td>\n",
       "      <td>0.827789</td>\n",
       "      <td>312.638500</td>\n",
       "      <td>76.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.564700</td>\n",
       "      <td>0.479156</td>\n",
       "      <td>0.838964</td>\n",
       "      <td>312.585500</td>\n",
       "      <td>76.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.586157</td>\n",
       "      <td>0.838740</td>\n",
       "      <td>312.568100</td>\n",
       "      <td>76.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.486416</td>\n",
       "      <td>0.847827</td>\n",
       "      <td>312.562000</td>\n",
       "      <td>76.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.485581</td>\n",
       "      <td>0.849902</td>\n",
       "      <td>312.667500</td>\n",
       "      <td>76.759000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.483060</td>\n",
       "      <td>0.831427</td>\n",
       "      <td>311.673000</td>\n",
       "      <td>77.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.531476</td>\n",
       "      <td>0.843481</td>\n",
       "      <td>311.472800</td>\n",
       "      <td>77.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>0.491657</td>\n",
       "      <td>0.834216</td>\n",
       "      <td>311.272700</td>\n",
       "      <td>77.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.570912</td>\n",
       "      <td>0.840832</td>\n",
       "      <td>311.070700</td>\n",
       "      <td>77.153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.561200</td>\n",
       "      <td>0.453411</td>\n",
       "      <td>0.844279</td>\n",
       "      <td>311.552100</td>\n",
       "      <td>77.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.578100</td>\n",
       "      <td>0.481712</td>\n",
       "      <td>0.843699</td>\n",
       "      <td>311.638200</td>\n",
       "      <td>77.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.436310</td>\n",
       "      <td>0.838683</td>\n",
       "      <td>311.702400</td>\n",
       "      <td>76.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.519900</td>\n",
       "      <td>0.615674</td>\n",
       "      <td>0.808497</td>\n",
       "      <td>311.724900</td>\n",
       "      <td>76.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.488856</td>\n",
       "      <td>0.850720</td>\n",
       "      <td>311.664300</td>\n",
       "      <td>77.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.610892</td>\n",
       "      <td>0.827475</td>\n",
       "      <td>311.893600</td>\n",
       "      <td>76.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.542968</td>\n",
       "      <td>0.838858</td>\n",
       "      <td>311.841400</td>\n",
       "      <td>76.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.507997</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>311.900300</td>\n",
       "      <td>76.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.563700</td>\n",
       "      <td>0.447948</td>\n",
       "      <td>0.837664</td>\n",
       "      <td>311.917700</td>\n",
       "      <td>76.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.633086</td>\n",
       "      <td>0.810463</td>\n",
       "      <td>312.009300</td>\n",
       "      <td>76.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.528703</td>\n",
       "      <td>0.832693</td>\n",
       "      <td>311.981300</td>\n",
       "      <td>76.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.448699</td>\n",
       "      <td>0.840855</td>\n",
       "      <td>311.754800</td>\n",
       "      <td>76.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>0.501057</td>\n",
       "      <td>0.834288</td>\n",
       "      <td>311.816900</td>\n",
       "      <td>76.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.504091</td>\n",
       "      <td>0.830842</td>\n",
       "      <td>311.792200</td>\n",
       "      <td>76.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.463780</td>\n",
       "      <td>0.835668</td>\n",
       "      <td>311.746600</td>\n",
       "      <td>76.986000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 28.53048324584961, 'eval_accuracy': 0.9172368421052631, 'eval_f1': 0.9168902171309844, 'eval_precision': 0.9169935930710416, 'eval_recall': 0.9172368421052632, 'eval_runtime': 98.0926, 'eval_samples_per_second': 77.478, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 32.78082275390625, 'eval_accuracy': 0.8614379084967321, 'eval_f1': 0.6371545302917003, 'eval_precision': 0.6375424593791854, 'eval_recall': 0.637571651471424, 'eval_runtime': 89.4302, 'eval_samples_per_second': 76.987, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49e96b650a64f4996b2d59a0471fcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d727f9cb124d5a852781d99444a631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1418b37a01604bd295ddc579cb7a9ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='8500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8500/216000 1:50:21 < 44:54:36, 1.28 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.384700</td>\n",
       "      <td>1.373084</td>\n",
       "      <td>0.268592</td>\n",
       "      <td>313.157500</td>\n",
       "      <td>76.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.611669</td>\n",
       "      <td>0.788161</td>\n",
       "      <td>312.699900</td>\n",
       "      <td>76.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.580798</td>\n",
       "      <td>0.792831</td>\n",
       "      <td>312.670400</td>\n",
       "      <td>76.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.567294</td>\n",
       "      <td>0.807660</td>\n",
       "      <td>312.783300</td>\n",
       "      <td>76.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.557860</td>\n",
       "      <td>0.802769</td>\n",
       "      <td>312.603300</td>\n",
       "      <td>76.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>0.629352</td>\n",
       "      <td>0.769624</td>\n",
       "      <td>312.550600</td>\n",
       "      <td>76.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.568968</td>\n",
       "      <td>0.811223</td>\n",
       "      <td>312.813300</td>\n",
       "      <td>76.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.585694</td>\n",
       "      <td>0.783193</td>\n",
       "      <td>312.864800</td>\n",
       "      <td>76.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.636635</td>\n",
       "      <td>0.775946</td>\n",
       "      <td>312.824300</td>\n",
       "      <td>76.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.593835</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>312.873600</td>\n",
       "      <td>76.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.558676</td>\n",
       "      <td>0.795660</td>\n",
       "      <td>312.774600</td>\n",
       "      <td>76.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.608600</td>\n",
       "      <td>0.640241</td>\n",
       "      <td>0.783166</td>\n",
       "      <td>312.891900</td>\n",
       "      <td>76.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.598700</td>\n",
       "      <td>0.513201</td>\n",
       "      <td>0.808687</td>\n",
       "      <td>312.842700</td>\n",
       "      <td>76.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>0.617349</td>\n",
       "      <td>0.789662</td>\n",
       "      <td>312.926300</td>\n",
       "      <td>76.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.573600</td>\n",
       "      <td>0.567924</td>\n",
       "      <td>0.773991</td>\n",
       "      <td>312.920400</td>\n",
       "      <td>76.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.579100</td>\n",
       "      <td>0.520937</td>\n",
       "      <td>0.805867</td>\n",
       "      <td>312.639300</td>\n",
       "      <td>76.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.586500</td>\n",
       "      <td>0.530856</td>\n",
       "      <td>0.776462</td>\n",
       "      <td>311.949500</td>\n",
       "      <td>76.936000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 28.125120162963867, 'eval_accuracy': 0.9030263157894737, 'eval_f1': 0.9027590040639824, 'eval_precision': 0.9083255026965441, 'eval_recall': 0.9030263157894738, 'eval_runtime': 97.9335, 'eval_samples_per_second': 77.604, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 35.096580505371094, 'eval_accuracy': 0.8883079157588961, 'eval_f1': 0.647538205679139, 'eval_precision': 0.6903325430220992, 'eval_recall': 0.6185810250868564, 'eval_runtime': 89.2875, 'eval_samples_per_second': 77.11, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5603f7347a641bcb4c1956e472e6376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e453c66b3d24e40aec0c995dc6a71a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f579a31312df48308466602e7eb3f7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14000' max='324000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 14000/324000 4:13:51 < 93:41:53, 0.92 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.156000</td>\n",
       "      <td>1.155155</td>\n",
       "      <td>0.232862</td>\n",
       "      <td>467.051300</td>\n",
       "      <td>77.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.989700</td>\n",
       "      <td>0.624172</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>467.026500</td>\n",
       "      <td>77.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.535716</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>467.059200</td>\n",
       "      <td>77.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.542142</td>\n",
       "      <td>0.651680</td>\n",
       "      <td>467.055700</td>\n",
       "      <td>77.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.508811</td>\n",
       "      <td>0.641255</td>\n",
       "      <td>467.412100</td>\n",
       "      <td>77.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.491901</td>\n",
       "      <td>0.657055</td>\n",
       "      <td>467.619900</td>\n",
       "      <td>76.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.482801</td>\n",
       "      <td>0.663657</td>\n",
       "      <td>467.555800</td>\n",
       "      <td>76.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>0.488640</td>\n",
       "      <td>0.668669</td>\n",
       "      <td>467.736900</td>\n",
       "      <td>76.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.496708</td>\n",
       "      <td>0.658924</td>\n",
       "      <td>467.596500</td>\n",
       "      <td>76.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.513449</td>\n",
       "      <td>0.647862</td>\n",
       "      <td>467.832800</td>\n",
       "      <td>76.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.471024</td>\n",
       "      <td>0.650939</td>\n",
       "      <td>467.746400</td>\n",
       "      <td>76.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.499262</td>\n",
       "      <td>0.645513</td>\n",
       "      <td>467.741800</td>\n",
       "      <td>76.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.493647</td>\n",
       "      <td>0.673726</td>\n",
       "      <td>467.806200</td>\n",
       "      <td>76.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.532625</td>\n",
       "      <td>0.643209</td>\n",
       "      <td>468.164100</td>\n",
       "      <td>76.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.674004</td>\n",
       "      <td>467.776300</td>\n",
       "      <td>76.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.496700</td>\n",
       "      <td>0.491649</td>\n",
       "      <td>0.671590</td>\n",
       "      <td>466.988200</td>\n",
       "      <td>77.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.513400</td>\n",
       "      <td>0.508055</td>\n",
       "      <td>0.671192</td>\n",
       "      <td>466.829500</td>\n",
       "      <td>77.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.489799</td>\n",
       "      <td>0.678635</td>\n",
       "      <td>466.596800</td>\n",
       "      <td>77.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.475445</td>\n",
       "      <td>0.673941</td>\n",
       "      <td>467.096100</td>\n",
       "      <td>77.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.667610</td>\n",
       "      <td>467.351900</td>\n",
       "      <td>77.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>0.472509</td>\n",
       "      <td>0.657514</td>\n",
       "      <td>467.233700</td>\n",
       "      <td>77.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>0.508164</td>\n",
       "      <td>0.648811</td>\n",
       "      <td>467.251500</td>\n",
       "      <td>77.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>0.497890</td>\n",
       "      <td>0.631260</td>\n",
       "      <td>467.337200</td>\n",
       "      <td>77.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.459670</td>\n",
       "      <td>0.664538</td>\n",
       "      <td>467.359000</td>\n",
       "      <td>77.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.443800</td>\n",
       "      <td>0.467259</td>\n",
       "      <td>0.662937</td>\n",
       "      <td>467.396800</td>\n",
       "      <td>77.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.473092</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>467.573200</td>\n",
       "      <td>76.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>0.489147</td>\n",
       "      <td>0.663525</td>\n",
       "      <td>468.151300</td>\n",
       "      <td>76.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>0.487221</td>\n",
       "      <td>0.638819</td>\n",
       "      <td>467.936100</td>\n",
       "      <td>76.934000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 29.974964141845703, 'eval_accuracy': 0.9276315789473685, 'eval_f1': 0.9274385832425893, 'eval_precision': 0.9273289076908191, 'eval_recall': 0.9276315789473685, 'eval_runtime': 98.4892, 'eval_samples_per_second': 77.166, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 35.96977233886719, 'eval_accuracy': 0.8592592592592593, 'eval_f1': 0.6423933170822469, 'eval_precision': 0.6444988862898565, 'eval_recall': 0.6471557154969605, 'eval_runtime': 89.7269, 'eval_samples_per_second': 76.733, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5176bf68f6434f5aac0d22748853c9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41be8f84b60c46e49a737c65fa6e3367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1283d4a590294db1b637d5a20bc0ba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='18500' max='432000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18500/432000 7:11:47 < 160:52:20, 0.71 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.972900</td>\n",
       "      <td>0.962359</td>\n",
       "      <td>0.171750</td>\n",
       "      <td>622.004300</td>\n",
       "      <td>77.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.902585</td>\n",
       "      <td>0.401629</td>\n",
       "      <td>621.509700</td>\n",
       "      <td>77.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.638400</td>\n",
       "      <td>0.469298</td>\n",
       "      <td>0.524624</td>\n",
       "      <td>621.865600</td>\n",
       "      <td>77.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.487600</td>\n",
       "      <td>0.443331</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>622.225900</td>\n",
       "      <td>77.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.434020</td>\n",
       "      <td>0.529342</td>\n",
       "      <td>622.356900</td>\n",
       "      <td>77.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.420592</td>\n",
       "      <td>0.543279</td>\n",
       "      <td>622.405700</td>\n",
       "      <td>77.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.439362</td>\n",
       "      <td>0.531302</td>\n",
       "      <td>622.549300</td>\n",
       "      <td>77.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.435820</td>\n",
       "      <td>0.523751</td>\n",
       "      <td>622.811000</td>\n",
       "      <td>77.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.428152</td>\n",
       "      <td>0.546004</td>\n",
       "      <td>622.859600</td>\n",
       "      <td>77.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.425502</td>\n",
       "      <td>0.539215</td>\n",
       "      <td>623.192700</td>\n",
       "      <td>77.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>0.427978</td>\n",
       "      <td>0.541313</td>\n",
       "      <td>621.910300</td>\n",
       "      <td>77.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>0.536944</td>\n",
       "      <td>623.205300</td>\n",
       "      <td>77.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.437053</td>\n",
       "      <td>0.507848</td>\n",
       "      <td>623.192200</td>\n",
       "      <td>77.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.422996</td>\n",
       "      <td>0.538120</td>\n",
       "      <td>623.102600</td>\n",
       "      <td>77.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.419569</td>\n",
       "      <td>0.542964</td>\n",
       "      <td>623.373500</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.437800</td>\n",
       "      <td>0.439912</td>\n",
       "      <td>0.545085</td>\n",
       "      <td>623.399100</td>\n",
       "      <td>76.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.448214</td>\n",
       "      <td>0.506491</td>\n",
       "      <td>624.236100</td>\n",
       "      <td>76.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.415304</td>\n",
       "      <td>0.554651</td>\n",
       "      <td>624.128200</td>\n",
       "      <td>76.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.434160</td>\n",
       "      <td>0.548142</td>\n",
       "      <td>624.440400</td>\n",
       "      <td>76.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.405608</td>\n",
       "      <td>0.517092</td>\n",
       "      <td>623.518200</td>\n",
       "      <td>76.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.401455</td>\n",
       "      <td>0.546456</td>\n",
       "      <td>622.987900</td>\n",
       "      <td>77.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.406906</td>\n",
       "      <td>0.547068</td>\n",
       "      <td>622.408900</td>\n",
       "      <td>77.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.423589</td>\n",
       "      <td>0.541196</td>\n",
       "      <td>622.589300</td>\n",
       "      <td>77.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>0.421001</td>\n",
       "      <td>0.557007</td>\n",
       "      <td>623.905100</td>\n",
       "      <td>76.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.391089</td>\n",
       "      <td>0.550244</td>\n",
       "      <td>623.931200</td>\n",
       "      <td>76.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.396235</td>\n",
       "      <td>0.542734</td>\n",
       "      <td>624.230100</td>\n",
       "      <td>76.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.366967</td>\n",
       "      <td>0.567677</td>\n",
       "      <td>624.602400</td>\n",
       "      <td>76.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.437559</td>\n",
       "      <td>0.544961</td>\n",
       "      <td>624.960100</td>\n",
       "      <td>76.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.387778</td>\n",
       "      <td>0.552261</td>\n",
       "      <td>625.226800</td>\n",
       "      <td>76.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.439955</td>\n",
       "      <td>0.535735</td>\n",
       "      <td>625.249200</td>\n",
       "      <td>76.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.394695</td>\n",
       "      <td>0.551539</td>\n",
       "      <td>625.943000</td>\n",
       "      <td>76.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.388699</td>\n",
       "      <td>0.544578</td>\n",
       "      <td>625.344600</td>\n",
       "      <td>76.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.390259</td>\n",
       "      <td>0.533850</td>\n",
       "      <td>625.209800</td>\n",
       "      <td>76.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.405883</td>\n",
       "      <td>0.529672</td>\n",
       "      <td>625.354200</td>\n",
       "      <td>76.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.413124</td>\n",
       "      <td>0.535007</td>\n",
       "      <td>625.406200</td>\n",
       "      <td>76.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.409089</td>\n",
       "      <td>0.555674</td>\n",
       "      <td>625.687600</td>\n",
       "      <td>76.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.429539</td>\n",
       "      <td>0.544933</td>\n",
       "      <td>625.486100</td>\n",
       "      <td>76.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 24.538375854492188, 'eval_accuracy': 0.9267105263157894, 'eval_f1': 0.9267659838994593, 'eval_precision': 0.9271496483776024, 'eval_recall': 0.9267105263157895, 'eval_runtime': 98.432, 'eval_samples_per_second': 77.211, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 28.26263999938965, 'eval_accuracy': 0.8326797385620915, 'eval_f1': 0.5882521925204612, 'eval_precision': 0.6174529757388829, 'eval_recall': 0.567786621256273, 'eval_runtime': 89.7437, 'eval_samples_per_second': 76.718, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e817376a721b42059ed533cc003e6fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953b1b69199e4535a6c8510d6ff46b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a216ecce504c6f8357d901e249494b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fef5d65e00c44c8a80160417fbecf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='13000' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13000/216000 6:11:00 < 96:34:13, 0.58 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.671400</td>\n",
       "      <td>8.285028</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>751.130700</td>\n",
       "      <td>31.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>8.253657</td>\n",
       "      <td>0.765375</td>\n",
       "      <td>750.810500</td>\n",
       "      <td>31.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>8.682800</td>\n",
       "      <td>8.251933</td>\n",
       "      <td>0.809125</td>\n",
       "      <td>751.029500</td>\n",
       "      <td>31.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.352400</td>\n",
       "      <td>8.250118</td>\n",
       "      <td>1.669375</td>\n",
       "      <td>751.302200</td>\n",
       "      <td>31.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.166200</td>\n",
       "      <td>8.248649</td>\n",
       "      <td>0.168625</td>\n",
       "      <td>750.732000</td>\n",
       "      <td>31.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>8.556200</td>\n",
       "      <td>8.248621</td>\n",
       "      <td>1.839500</td>\n",
       "      <td>750.413900</td>\n",
       "      <td>31.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>8.329400</td>\n",
       "      <td>8.249295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.199300</td>\n",
       "      <td>31.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>8.439200</td>\n",
       "      <td>8.248896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.686600</td>\n",
       "      <td>31.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>8.242500</td>\n",
       "      <td>8.248940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.533100</td>\n",
       "      <td>31.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>8.249400</td>\n",
       "      <td>8.248578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>749.966300</td>\n",
       "      <td>32.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>8.504400</td>\n",
       "      <td>8.248728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.351100</td>\n",
       "      <td>31.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>8.474600</td>\n",
       "      <td>8.248485</td>\n",
       "      <td>0.173125</td>\n",
       "      <td>750.146400</td>\n",
       "      <td>31.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>8.008400</td>\n",
       "      <td>8.248555</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>750.495400</td>\n",
       "      <td>31.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>8.503600</td>\n",
       "      <td>8.248586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.050900</td>\n",
       "      <td>31.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>8.200500</td>\n",
       "      <td>8.248848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.497600</td>\n",
       "      <td>31.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>8.148600</td>\n",
       "      <td>8.248942</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>750.783000</td>\n",
       "      <td>31.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>8.577400</td>\n",
       "      <td>8.248506</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>750.027100</td>\n",
       "      <td>31.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>8.144800</td>\n",
       "      <td>8.248883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.311200</td>\n",
       "      <td>31.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>8.245100</td>\n",
       "      <td>8.248588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.148500</td>\n",
       "      <td>31.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>8.518300</td>\n",
       "      <td>8.248549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.073500</td>\n",
       "      <td>31.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>8.211300</td>\n",
       "      <td>8.248547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.277500</td>\n",
       "      <td>31.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>8.059700</td>\n",
       "      <td>8.248528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.290500</td>\n",
       "      <td>31.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>8.359100</td>\n",
       "      <td>8.248466</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>750.289000</td>\n",
       "      <td>31.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>8.566100</td>\n",
       "      <td>8.249178</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>750.383400</td>\n",
       "      <td>31.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>8.189200</td>\n",
       "      <td>8.248478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>749.749800</td>\n",
       "      <td>32.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>8.466300</td>\n",
       "      <td>8.248870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>749.770700</td>\n",
       "      <td>32.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+INV\n",
      "{'eval_loss': 8.318270683288574, 'eval_accuracy': 0.25, 'eval_f1': 0.1, 'eval_precision': 0.0625, 'eval_recall': 0.25, 'eval_runtime': 222.3891, 'eval_samples_per_second': 34.174, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+INV\n",
      "{'eval_loss': 11.154634475708008, 'eval_accuracy': 0.00014524328249818446, 'eval_f1': 0.00012635835228708617, 'eval_precision': 0.05, 'eval_recall': 6.325910931174089e-05, 'eval_runtime': 201.6115, 'eval_samples_per_second': 34.15, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c16e5355d364030a636e48ad6d2f4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b568a722e22c47f7bd0ff5b9dd2069cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c00722fdd04b62bb44bd5090c438d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='8500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8500/216000 4:01:55 < 98:27:18, 0.59 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.382400</td>\n",
       "      <td>1.174077</td>\n",
       "      <td>0.553556</td>\n",
       "      <td>746.472700</td>\n",
       "      <td>32.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.951900</td>\n",
       "      <td>0.698672</td>\n",
       "      <td>0.732767</td>\n",
       "      <td>746.508200</td>\n",
       "      <td>32.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.653900</td>\n",
       "      <td>0.639262</td>\n",
       "      <td>0.778344</td>\n",
       "      <td>746.459800</td>\n",
       "      <td>32.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.685200</td>\n",
       "      <td>0.621415</td>\n",
       "      <td>0.773479</td>\n",
       "      <td>746.474100</td>\n",
       "      <td>32.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>0.630789</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>746.617800</td>\n",
       "      <td>32.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>0.644635</td>\n",
       "      <td>0.767737</td>\n",
       "      <td>746.676300</td>\n",
       "      <td>32.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>0.590145</td>\n",
       "      <td>0.786911</td>\n",
       "      <td>746.546300</td>\n",
       "      <td>32.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.591975</td>\n",
       "      <td>0.784199</td>\n",
       "      <td>746.461000</td>\n",
       "      <td>32.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.645393</td>\n",
       "      <td>0.769057</td>\n",
       "      <td>746.488100</td>\n",
       "      <td>32.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.606981</td>\n",
       "      <td>0.748131</td>\n",
       "      <td>746.616900</td>\n",
       "      <td>32.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.786198</td>\n",
       "      <td>746.577100</td>\n",
       "      <td>32.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.762444</td>\n",
       "      <td>747.082600</td>\n",
       "      <td>32.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.614300</td>\n",
       "      <td>0.534190</td>\n",
       "      <td>0.774352</td>\n",
       "      <td>747.077600</td>\n",
       "      <td>32.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.609688</td>\n",
       "      <td>0.757639</td>\n",
       "      <td>746.766700</td>\n",
       "      <td>32.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.580200</td>\n",
       "      <td>0.530830</td>\n",
       "      <td>0.780642</td>\n",
       "      <td>746.597300</td>\n",
       "      <td>32.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.566962</td>\n",
       "      <td>0.760355</td>\n",
       "      <td>746.411100</td>\n",
       "      <td>32.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.554697</td>\n",
       "      <td>0.784872</td>\n",
       "      <td>746.609300</td>\n",
       "      <td>32.145000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+SIB\n",
      "{'eval_loss': 31.604143142700195, 'eval_accuracy': 0.9025, 'eval_f1': 0.9018980761938504, 'eval_precision': 0.9055888909995566, 'eval_recall': 0.9025, 'eval_runtime': 222.161, 'eval_samples_per_second': 34.209, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+SIB\n",
      "{'eval_loss': 31.991535186767578, 'eval_accuracy': 0.9000726216412491, 'eval_f1': 0.6618761747173765, 'eval_precision': 0.6813051453656644, 'eval_recall': 0.6453741006942768, 'eval_runtime': 201.337, 'eval_samples_per_second': 34.196, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9627b5b67234beabf3b6bc48ae8e396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8148bdbc7124b418b2a139523280c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f68e14d148491d9da8659f3d573764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='12500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 12500/216000 5:57:06 < 96:54:40, 0.58 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.372300</td>\n",
       "      <td>1.208815</td>\n",
       "      <td>0.557630</td>\n",
       "      <td>750.749400</td>\n",
       "      <td>31.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.573010</td>\n",
       "      <td>0.797760</td>\n",
       "      <td>750.245000</td>\n",
       "      <td>31.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.571900</td>\n",
       "      <td>0.515466</td>\n",
       "      <td>0.826374</td>\n",
       "      <td>749.586900</td>\n",
       "      <td>32.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.548727</td>\n",
       "      <td>0.834158</td>\n",
       "      <td>749.464400</td>\n",
       "      <td>32.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.578794</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>749.841000</td>\n",
       "      <td>32.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.677821</td>\n",
       "      <td>0.813228</td>\n",
       "      <td>749.974200</td>\n",
       "      <td>32.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>0.576479</td>\n",
       "      <td>0.842924</td>\n",
       "      <td>749.858100</td>\n",
       "      <td>32.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.578700</td>\n",
       "      <td>0.520947</td>\n",
       "      <td>0.834613</td>\n",
       "      <td>750.349100</td>\n",
       "      <td>31.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.531700</td>\n",
       "      <td>0.540147</td>\n",
       "      <td>0.834642</td>\n",
       "      <td>749.965700</td>\n",
       "      <td>32.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.589095</td>\n",
       "      <td>0.830191</td>\n",
       "      <td>750.048500</td>\n",
       "      <td>31.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.546400</td>\n",
       "      <td>0.532431</td>\n",
       "      <td>0.842039</td>\n",
       "      <td>749.943600</td>\n",
       "      <td>32.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.563400</td>\n",
       "      <td>0.571090</td>\n",
       "      <td>0.824356</td>\n",
       "      <td>750.055000</td>\n",
       "      <td>31.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.446608</td>\n",
       "      <td>0.836798</td>\n",
       "      <td>750.036300</td>\n",
       "      <td>31.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.510992</td>\n",
       "      <td>0.838527</td>\n",
       "      <td>749.853100</td>\n",
       "      <td>32.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.450628</td>\n",
       "      <td>0.846749</td>\n",
       "      <td>750.226200</td>\n",
       "      <td>31.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.566689</td>\n",
       "      <td>0.840401</td>\n",
       "      <td>749.993300</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.520374</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>749.847200</td>\n",
       "      <td>32.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.835177</td>\n",
       "      <td>750.123000</td>\n",
       "      <td>31.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.502426</td>\n",
       "      <td>0.836411</td>\n",
       "      <td>750.029300</td>\n",
       "      <td>31.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.530300</td>\n",
       "      <td>0.533933</td>\n",
       "      <td>0.840958</td>\n",
       "      <td>750.221500</td>\n",
       "      <td>31.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>0.477533</td>\n",
       "      <td>0.823363</td>\n",
       "      <td>750.265900</td>\n",
       "      <td>31.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.510344</td>\n",
       "      <td>0.839753</td>\n",
       "      <td>750.600000</td>\n",
       "      <td>31.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.519689</td>\n",
       "      <td>0.842144</td>\n",
       "      <td>750.525300</td>\n",
       "      <td>31.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.568700</td>\n",
       "      <td>0.489309</td>\n",
       "      <td>0.838141</td>\n",
       "      <td>750.263600</td>\n",
       "      <td>31.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.510494</td>\n",
       "      <td>0.843238</td>\n",
       "      <td>750.300700</td>\n",
       "      <td>31.987000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 30.015947341918945, 'eval_accuracy': 0.9157894736842105, 'eval_f1': 0.915808306006684, 'eval_precision': 0.9163775179707737, 'eval_recall': 0.9157894736842105, 'eval_runtime': 222.4828, 'eval_samples_per_second': 34.16, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 34.32645797729492, 'eval_accuracy': 0.8175744371822803, 'eval_f1': 0.6200709479497988, 'eval_precision': 0.630872474245495, 'eval_recall': 0.6290870740005385, 'eval_runtime': 201.6809, 'eval_samples_per_second': 34.138, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2ea08f2e7647bd8d8f5eea6bd3e6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134ebceab25240ef9a3d896dd91e6d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7f3ca82f274c8894ce3a10fbab155f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='11500' max='216000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 11500/216000 5:27:53 < 97:11:44, 0.58 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.362800</td>\n",
       "      <td>1.190289</td>\n",
       "      <td>0.559373</td>\n",
       "      <td>749.257600</td>\n",
       "      <td>32.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.957700</td>\n",
       "      <td>0.678102</td>\n",
       "      <td>0.729556</td>\n",
       "      <td>748.599400</td>\n",
       "      <td>32.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.645200</td>\n",
       "      <td>0.612779</td>\n",
       "      <td>0.773538</td>\n",
       "      <td>748.973100</td>\n",
       "      <td>32.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.643700</td>\n",
       "      <td>0.570695</td>\n",
       "      <td>0.789118</td>\n",
       "      <td>748.378100</td>\n",
       "      <td>32.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.577620</td>\n",
       "      <td>0.780190</td>\n",
       "      <td>748.462400</td>\n",
       "      <td>32.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>0.627197</td>\n",
       "      <td>0.766079</td>\n",
       "      <td>748.615700</td>\n",
       "      <td>32.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.636824</td>\n",
       "      <td>0.778618</td>\n",
       "      <td>748.489700</td>\n",
       "      <td>32.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.611300</td>\n",
       "      <td>0.553559</td>\n",
       "      <td>0.794927</td>\n",
       "      <td>747.842100</td>\n",
       "      <td>32.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>0.630268</td>\n",
       "      <td>0.781509</td>\n",
       "      <td>748.413200</td>\n",
       "      <td>32.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.611300</td>\n",
       "      <td>0.613513</td>\n",
       "      <td>0.770542</td>\n",
       "      <td>748.290100</td>\n",
       "      <td>32.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.564620</td>\n",
       "      <td>0.788394</td>\n",
       "      <td>747.612900</td>\n",
       "      <td>32.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.615970</td>\n",
       "      <td>0.771591</td>\n",
       "      <td>747.748600</td>\n",
       "      <td>32.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.598700</td>\n",
       "      <td>0.500157</td>\n",
       "      <td>0.802620</td>\n",
       "      <td>747.560000</td>\n",
       "      <td>32.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>0.558145</td>\n",
       "      <td>0.798079</td>\n",
       "      <td>748.044800</td>\n",
       "      <td>32.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>0.512176</td>\n",
       "      <td>0.798789</td>\n",
       "      <td>747.960200</td>\n",
       "      <td>32.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.623700</td>\n",
       "      <td>0.552421</td>\n",
       "      <td>0.784977</td>\n",
       "      <td>747.980600</td>\n",
       "      <td>32.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.532363</td>\n",
       "      <td>0.785757</td>\n",
       "      <td>748.015900</td>\n",
       "      <td>32.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.578600</td>\n",
       "      <td>0.535364</td>\n",
       "      <td>0.789087</td>\n",
       "      <td>747.641300</td>\n",
       "      <td>32.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.527328</td>\n",
       "      <td>0.799427</td>\n",
       "      <td>747.628200</td>\n",
       "      <td>32.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.521200</td>\n",
       "      <td>0.588185</td>\n",
       "      <td>0.792394</td>\n",
       "      <td>747.542900</td>\n",
       "      <td>32.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.630800</td>\n",
       "      <td>0.501057</td>\n",
       "      <td>0.789086</td>\n",
       "      <td>747.706100</td>\n",
       "      <td>32.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.639800</td>\n",
       "      <td>0.544876</td>\n",
       "      <td>0.773202</td>\n",
       "      <td>748.173900</td>\n",
       "      <td>32.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.580932</td>\n",
       "      <td>0.781005</td>\n",
       "      <td>748.015400</td>\n",
       "      <td>32.085000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 27.249120712280273, 'eval_accuracy': 0.916578947368421, 'eval_f1': 0.9163047903687029, 'eval_precision': 0.91703357855582, 'eval_recall': 0.9165789473684212, 'eval_runtime': 222.3071, 'eval_samples_per_second': 34.187, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 30.009477615356445, 'eval_accuracy': 0.8673928830791576, 'eval_f1': 0.6506783714026064, 'eval_precision': 0.6578139263566914, 'eval_recall': 0.6463484962788832, 'eval_runtime': 201.4438, 'eval_samples_per_second': 34.178, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb7498227e94436bac5b4e7145211f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d719b1f1ed44b1a27443b4d7fbb28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef66c1d54c34717bd8674fc43990af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='17500' max='324000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17500/324000 11:58:59 < 209:53:58, 0.41 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.155400</td>\n",
       "      <td>1.073364</td>\n",
       "      <td>0.384284</td>\n",
       "      <td>1125.170400</td>\n",
       "      <td>31.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.962300</td>\n",
       "      <td>0.721829</td>\n",
       "      <td>0.563439</td>\n",
       "      <td>1125.118600</td>\n",
       "      <td>31.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.652700</td>\n",
       "      <td>0.572934</td>\n",
       "      <td>0.611174</td>\n",
       "      <td>1125.083700</td>\n",
       "      <td>31.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>0.569536</td>\n",
       "      <td>0.627017</td>\n",
       "      <td>1125.122100</td>\n",
       "      <td>31.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>0.517023</td>\n",
       "      <td>0.644191</td>\n",
       "      <td>1125.145500</td>\n",
       "      <td>31.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.503407</td>\n",
       "      <td>0.630524</td>\n",
       "      <td>1125.244500</td>\n",
       "      <td>31.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.525100</td>\n",
       "      <td>0.490855</td>\n",
       "      <td>0.641650</td>\n",
       "      <td>1127.572700</td>\n",
       "      <td>31.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.488100</td>\n",
       "      <td>0.505578</td>\n",
       "      <td>0.650297</td>\n",
       "      <td>1128.260400</td>\n",
       "      <td>31.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.490924</td>\n",
       "      <td>0.647578</td>\n",
       "      <td>1128.278400</td>\n",
       "      <td>31.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.520400</td>\n",
       "      <td>0.501576</td>\n",
       "      <td>0.632909</td>\n",
       "      <td>1126.102400</td>\n",
       "      <td>31.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.540600</td>\n",
       "      <td>0.484040</td>\n",
       "      <td>0.654075</td>\n",
       "      <td>1125.445300</td>\n",
       "      <td>31.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.527289</td>\n",
       "      <td>0.661040</td>\n",
       "      <td>1125.249600</td>\n",
       "      <td>31.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>0.526589</td>\n",
       "      <td>0.654499</td>\n",
       "      <td>1125.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.505094</td>\n",
       "      <td>0.654864</td>\n",
       "      <td>1125.395400</td>\n",
       "      <td>31.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.532700</td>\n",
       "      <td>0.488683</td>\n",
       "      <td>0.619438</td>\n",
       "      <td>1125.160500</td>\n",
       "      <td>31.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.502853</td>\n",
       "      <td>0.666305</td>\n",
       "      <td>1124.769300</td>\n",
       "      <td>32.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.474525</td>\n",
       "      <td>0.660891</td>\n",
       "      <td>1124.990800</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.474700</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>0.644052</td>\n",
       "      <td>1124.922400</td>\n",
       "      <td>32.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.495933</td>\n",
       "      <td>0.646784</td>\n",
       "      <td>1124.947100</td>\n",
       "      <td>32.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>0.486694</td>\n",
       "      <td>0.651862</td>\n",
       "      <td>1124.840200</td>\n",
       "      <td>32.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>0.469375</td>\n",
       "      <td>0.655011</td>\n",
       "      <td>1124.691300</td>\n",
       "      <td>32.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.503776</td>\n",
       "      <td>0.619599</td>\n",
       "      <td>1125.394700</td>\n",
       "      <td>31.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.507058</td>\n",
       "      <td>0.640589</td>\n",
       "      <td>1125.127300</td>\n",
       "      <td>31.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.497644</td>\n",
       "      <td>0.648100</td>\n",
       "      <td>1125.049600</td>\n",
       "      <td>31.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.467013</td>\n",
       "      <td>0.681033</td>\n",
       "      <td>1124.527200</td>\n",
       "      <td>32.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.475500</td>\n",
       "      <td>0.461277</td>\n",
       "      <td>0.678778</td>\n",
       "      <td>1125.110600</td>\n",
       "      <td>31.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>0.472781</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>1124.869500</td>\n",
       "      <td>32.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.469700</td>\n",
       "      <td>0.491883</td>\n",
       "      <td>0.665029</td>\n",
       "      <td>1125.223700</td>\n",
       "      <td>31.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.491680</td>\n",
       "      <td>0.646182</td>\n",
       "      <td>1125.037000</td>\n",
       "      <td>31.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.477704</td>\n",
       "      <td>0.661012</td>\n",
       "      <td>1124.707400</td>\n",
       "      <td>32.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.464200</td>\n",
       "      <td>0.484163</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>1124.726300</td>\n",
       "      <td>32.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.488602</td>\n",
       "      <td>0.632690</td>\n",
       "      <td>1124.621300</td>\n",
       "      <td>32.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.473500</td>\n",
       "      <td>0.505597</td>\n",
       "      <td>0.640767</td>\n",
       "      <td>1124.342600</td>\n",
       "      <td>32.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.485159</td>\n",
       "      <td>0.646527</td>\n",
       "      <td>1124.930700</td>\n",
       "      <td>32.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.487800</td>\n",
       "      <td>0.466352</td>\n",
       "      <td>0.672559</td>\n",
       "      <td>1124.921500</td>\n",
       "      <td>32.002000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 30.555891036987305, 'eval_accuracy': 0.9271052631578948, 'eval_f1': 0.9270176507556998, 'eval_precision': 0.9269841536717776, 'eval_recall': 0.9271052631578948, 'eval_runtime': 222.2903, 'eval_samples_per_second': 34.19, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 35.8184928894043, 'eval_accuracy': 0.8191721132897604, 'eval_f1': 0.584935403376821, 'eval_precision': 0.5995900430213603, 'eval_recall': 0.6008162850221705, 'eval_runtime': 201.4581, 'eval_samples_per_second': 34.176, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1130131857c54bd78019eb6d58a08dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0364f120e240bdbcd43d890b9b1f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac81d3d843c4d6aaf7b928e1173d8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14000' max='432000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 14000/432000 12:27:55 < 372:14:16, 0.31 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.010600</td>\n",
       "      <td>0.938854</td>\n",
       "      <td>0.248261</td>\n",
       "      <td>1495.685100</td>\n",
       "      <td>32.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.914700</td>\n",
       "      <td>0.729477</td>\n",
       "      <td>0.425478</td>\n",
       "      <td>1496.063200</td>\n",
       "      <td>32.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>0.528664</td>\n",
       "      <td>0.480196</td>\n",
       "      <td>1496.228700</td>\n",
       "      <td>32.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.486066</td>\n",
       "      <td>0.500718</td>\n",
       "      <td>1495.095300</td>\n",
       "      <td>32.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.456192</td>\n",
       "      <td>0.514698</td>\n",
       "      <td>1494.784200</td>\n",
       "      <td>32.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.464500</td>\n",
       "      <td>0.449363</td>\n",
       "      <td>0.526991</td>\n",
       "      <td>1495.131100</td>\n",
       "      <td>32.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.455244</td>\n",
       "      <td>0.524048</td>\n",
       "      <td>1495.343200</td>\n",
       "      <td>32.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.465500</td>\n",
       "      <td>0.441125</td>\n",
       "      <td>0.521441</td>\n",
       "      <td>1495.404900</td>\n",
       "      <td>32.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.450900</td>\n",
       "      <td>0.435766</td>\n",
       "      <td>0.536386</td>\n",
       "      <td>1495.024300</td>\n",
       "      <td>32.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.446521</td>\n",
       "      <td>0.529858</td>\n",
       "      <td>1495.255500</td>\n",
       "      <td>32.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.442305</td>\n",
       "      <td>0.531558</td>\n",
       "      <td>1495.126900</td>\n",
       "      <td>32.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.434382</td>\n",
       "      <td>0.540081</td>\n",
       "      <td>1495.032400</td>\n",
       "      <td>32.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.429600</td>\n",
       "      <td>0.416537</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>1495.369700</td>\n",
       "      <td>32.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.414421</td>\n",
       "      <td>0.534655</td>\n",
       "      <td>1495.134900</td>\n",
       "      <td>32.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.433700</td>\n",
       "      <td>0.428164</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>1495.095700</td>\n",
       "      <td>32.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.435957</td>\n",
       "      <td>0.534948</td>\n",
       "      <td>1494.905100</td>\n",
       "      <td>32.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.433417</td>\n",
       "      <td>0.520286</td>\n",
       "      <td>1494.985400</td>\n",
       "      <td>32.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.414464</td>\n",
       "      <td>0.547234</td>\n",
       "      <td>1495.561500</td>\n",
       "      <td>32.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.471836</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>1495.590800</td>\n",
       "      <td>32.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>0.396028</td>\n",
       "      <td>0.506653</td>\n",
       "      <td>1496.061200</td>\n",
       "      <td>32.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.421134</td>\n",
       "      <td>0.536203</td>\n",
       "      <td>1495.577900</td>\n",
       "      <td>32.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.407965</td>\n",
       "      <td>0.528317</td>\n",
       "      <td>1495.571600</td>\n",
       "      <td>32.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.426724</td>\n",
       "      <td>0.519081</td>\n",
       "      <td>1495.527500</td>\n",
       "      <td>32.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.451824</td>\n",
       "      <td>0.542288</td>\n",
       "      <td>1495.358200</td>\n",
       "      <td>32.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.410762</td>\n",
       "      <td>0.539708</td>\n",
       "      <td>1495.675500</td>\n",
       "      <td>32.093000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.425397</td>\n",
       "      <td>0.535136</td>\n",
       "      <td>1495.142700</td>\n",
       "      <td>32.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.393080</td>\n",
       "      <td>0.544931</td>\n",
       "      <td>1495.563400</td>\n",
       "      <td>32.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.449031</td>\n",
       "      <td>0.539252</td>\n",
       "      <td>1495.965400</td>\n",
       "      <td>32.086000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 32.73589324951172, 'eval_accuracy': 0.9146052631578947, 'eval_f1': 0.9142334848723681, 'eval_precision': 0.9140987901658261, 'eval_recall': 0.9146052631578947, 'eval_runtime': 222.1168, 'eval_samples_per_second': 34.216, 'epoch': 0.1}\n",
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 36.50894546508789, 'eval_accuracy': 0.8668119099491649, 'eval_f1': 0.6505277284454216, 'eval_precision': 0.6616983861911796, 'eval_recall': 0.6417526821089767, 'eval_runtime': 201.2307, 'eval_samples_per_second': 34.214, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "use_pretrain = False\n",
    "\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "    for t in ['INV']: \n",
    "        \n",
    "        # run = wandb.init(project=\"train_SST2-\"+t, reinit=True)\n",
    "                \n",
    "        soft_target = False\n",
    "        eval_only = False\n",
    "        \n",
    "        checkpoint = 'pretrained/' + MODEL_NAME + \"-ag_news-ORIG+\" + t \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        if t == 'ORIG':\n",
    "            train_dataset = load_dataset('ag_news', split='train')\n",
    "        else:\n",
    "            # load custom data    \n",
    "            text = npy_load(\"./assets/AG_NEWS/\" + t + \"/text.npy\")\n",
    "            label = npy_load(\"./assets/AG_NEWS/\" + t + \"/label.npy\")\n",
    "            if len(label.shape) > 1:\n",
    "                df = pd.DataFrame({'text': text, 'label': label.tolist()})\n",
    "                df.text = df.text.astype(str)\n",
    "                df.label = df.label.map(lambda y: np.array(y))\n",
    "            else:\n",
    "                df = pd.DataFrame({'text': text, 'label': label})\n",
    "                df.text = df.text.astype(str)\n",
    "                df.label = df.label.astype(object)\n",
    "            train_dataset = Dataset.from_pandas(df)  \n",
    "            \n",
    "            # load orig data\n",
    "            orig_dataset = load_dataset('ag_news', split='train')\n",
    "            df = orig_dataset.to_pandas()\n",
    "            df = df[df.columns[::-1]]\n",
    "            df.text = df.text.astype(str)\n",
    "            if len(label.shape) > 1:\n",
    "                df.label = df.label.map(one_hot_encode)\n",
    "            else:\n",
    "                df.label = df.label.astype(object)\n",
    "            orig_dataset = Dataset.from_pandas(df)\n",
    "            \n",
    "            # merge orig + custom data\n",
    "            train_dataset = concatenate_datasets([orig_dataset, train_dataset])\n",
    "            train_dataset.shuffle()\n",
    "            \n",
    "        if use_pretrain and os.path.exists(checkpoint):\n",
    "            print('loading {}...'.format(checkpoint))\n",
    "            MODEL_NAME = checkpoint\n",
    "            eval_only = True\n",
    "                \n",
    "        dataset_dict = train_dataset.train_test_split(\n",
    "            test_size = 0.05,\n",
    "            train_size = 0.95,\n",
    "            shuffle = True\n",
    "        )\n",
    "        train_dataset = dataset_dict['train']\n",
    "        eval_dataset = dataset_dict['test']\n",
    "        test_dataset = load_dataset('ag_news')['test']\n",
    "        test_dataset_20NG = get_20NG_test_dataset()\n",
    "        \n",
    "        # # reduce training time\n",
    "        # n = 10000\n",
    "        # train_dataset = Dataset.from_dict(train_dataset[:n])\n",
    "        # eval_dataset = Dataset.from_dict(eval_dataset[:n])\n",
    "        # test_dataset = Dataset.from_dict(test_dataset[:n])\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4).to(device)\n",
    "                \n",
    "        train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "        eval_dataset = eval_dataset.map(tokenize, batched=True, batch_size=len(eval_dataset))\n",
    "        test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "        test_dataset_20NG = test_dataset_20NG.map(tokenize, batched=True, batch_size=len(test_dataset_20NG))\n",
    "        train_dataset.rename_column_('label', 'labels')\n",
    "        eval_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset_20NG.rename_column_('label', 'labels')\n",
    "        train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        test_dataset_20NG.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        if len(np.array(train_dataset['labels']).shape) > 1:\n",
    "            soft_target = True\n",
    "\n",
    "        train_batch_size = 3\n",
    "        eval_batch_size = 32\n",
    "        num_epoch = 3\n",
    "        gradient_accumulation_steps=1\n",
    "        max_steps = int((len(train_dataset) * num_epoch / gradient_accumulation_steps) / train_batch_size)\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            seed=1,\n",
    "            # adafactor=True,\n",
    "            output_dir=checkpoint,\n",
    "            overwrite_output_dir=True,\n",
    "            max_steps=max_steps,\n",
    "            save_steps=int(max_steps / 10),\n",
    "            save_total_limit=1,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "            warmup_steps=int(max_steps / 10),\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=1000,\n",
    "            logging_first_step=True,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            run_name=checkpoint,\n",
    "            label_names=['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "        )\n",
    "        \n",
    "        if soft_target:\n",
    "            trainer = Trainer_w_soft_target(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                compute_metrics=compute_metrics_w_soft_target,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                data_collator=DefaultCollator(),\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "            )\n",
    "        else: \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                compute_metrics=compute_metrics,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=test_dataset,\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "            )\n",
    "\n",
    "        if not eval_only:\n",
    "            trainer.train()\n",
    "            \n",
    "        trainer.compute_metrics = compute_metrics\n",
    "        \n",
    "        # test with ORIG data\n",
    "        trainer.eval_dataset = test_dataset\n",
    "        out_orig = trainer.evaluate()\n",
    "        print('ORIG for {}\\n{}'.format(checkpoint, out_orig))\n",
    "        \n",
    "        # test with 20NG data\n",
    "        trainer.eval_dataset = test_dataset_20NG\n",
    "        out_20NG = trainer.evaluate()\n",
    "        print('20NG for {}\\n{}'.format(checkpoint, out_20NG))\n",
    "        \n",
    "        # run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_SST2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00554915f7ad47b9b80d65294dbfdd37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0768ccf7a2e64f819c7401d7db258d16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14dc24ef59d341a88d1bdb69f3cacde6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "212a6447739d45b5b57e5815ff538f57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "367cfe385d38427dbdf4325a70c0dc2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46cc6e7671244f1d9167855a45a36af8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b1f7506e1a44d109d918b1f16d6bb75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5f641be531341dbb007330b7e245169",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00554915f7ad47b9b80d65294dbfdd37",
      "value": 1382015
     }
    },
    "59b96dd300ae4a56b2d58ca0de0bb7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd27134d896448b6b385ce45da7556ee",
       "IPY_MODEL_c92040617a854d8d96cc8ba678f0b271"
      ],
      "layout": "IPY_MODEL_e3c71b92f2a0484bb70123a86f855f9d"
     }
    },
    "7158ce3f315647aba9299519fcec4be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81821a97e02445539ccabcc2091cba95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b1f7506e1a44d109d918b1f16d6bb75",
       "IPY_MODEL_f177b91513ec4039bc7c6e61d15db9a2"
      ],
      "layout": "IPY_MODEL_212a6447739d45b5b57e5815ff538f57"
     }
    },
    "c92040617a854d8d96cc8ba678f0b271": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46cc6e7671244f1d9167855a45a36af8",
      "placeholder": "",
      "style": "IPY_MODEL_14dc24ef59d341a88d1bdb69f3cacde6",
      "value": " 798k/798k [00:00&lt;00:00, 1.99MB/s]"
     }
    },
    "d5f641be531341dbb007330b7e245169": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd27134d896448b6b385ce45da7556ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f86a86b6b9c64cc989e89b27693d8a2f",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_367cfe385d38427dbdf4325a70c0dc2e",
      "value": 798011
     }
    },
    "e3c71b92f2a0484bb70123a86f855f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f177b91513ec4039bc7c6e61d15db9a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0768ccf7a2e64f819c7401d7db258d16",
      "placeholder": "",
      "style": "IPY_MODEL_7158ce3f315647aba9299519fcec4be7",
      "value": " 1.38M/1.38M [00:00&lt;00:00, 5.04MB/s]"
     }
    },
    "f86a86b6b9c64cc989e89b27693d8a2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
