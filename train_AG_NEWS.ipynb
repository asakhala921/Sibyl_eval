{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "utjMLdmqsUuA"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WT_xnGBpTNuZ"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y, nb_classes=4):\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.expand_dims(np.array(y), 0)\n",
    "    res = np.eye(nb_classes)[np.array(y).reshape(-1)]\n",
    "    return res.reshape(list(y.shape)+[nb_classes])[0]\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=250)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1.mean(),\n",
    "        'precision': precision.mean(),\n",
    "        'recall': recall.mean()\n",
    "    }\n",
    "\n",
    "def acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()\n",
    "\n",
    "def CEwST_loss(logits, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Cross Entropy with Soft Target (CEwST) Loss\n",
    "    :param logits: (batch, *)\n",
    "    :param target: (batch, *) same shape as logits, each item must be a valid distribution: target[i, :].sum() == 1.\n",
    "    \"\"\"\n",
    "    logprobs = torch.nn.functional.log_softmax(logits.view(logits.shape[0], -1), dim=1)\n",
    "    batchloss = - torch.sum(target.view(target.shape[0], -1) * logprobs, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return batchloss\n",
    "    elif reduction == 'mean':\n",
    "        return torch.mean(batchloss)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(batchloss)\n",
    "    else:\n",
    "        raise NotImplementedError('Unsupported reduction mode.')\n",
    "\n",
    "def compute_metrics_w_soft_target(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    acc = acc_at_k(labels, preds, k=2)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }\n",
    "\n",
    "class Trainer_w_soft_target(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        loss = CEwST_loss(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "    \n",
    "class DefaultCollator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def get_20NG_test_dataset():\n",
    "    cats = [\n",
    "        'talk.politics.mideast',                                # Wolrd 0\n",
    "        'rec.sport.hockey', 'rec.sport.baseball',               # Sports 1\n",
    "        # 'misc.forsale',                                       # Business 2\n",
    "        'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', # Sci/Tech 3\n",
    "    ]\n",
    "\n",
    "    dataset = fetch_20newsgroups(\n",
    "        subset='all',\n",
    "        categories=cats,\n",
    "        remove=('headers', 'footers', 'quotes')\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame([dataset.data, dataset.target]).T\n",
    "    df.rename(columns={0:'text', 1: 'label'}, inplace=True)\n",
    "\n",
    "    mapper = {\n",
    "        0: 1,\n",
    "        1: 1,\n",
    "        2: 3,\n",
    "        3: 3,\n",
    "        4: 3,\n",
    "        5: 3,\n",
    "        6: 0,\n",
    "    }\n",
    "\n",
    "    df.label = df.label.map(mapper)\n",
    "    df.text = df.text.replace('\\n', ' ', regex=True).str.strip()\n",
    "\n",
    "    test_dataset = Dataset.from_pandas(df)\n",
    "    \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['ORIG', 'INV', 'SIB', 'INVSIB', 'TextMix', 'SentMix', 'WordMix']\n",
    "# ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nq1i8QiBtY0e"
   },
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['bert-base-uncased', 'roberta-base', 'xlnet-base-cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "59b96dd300ae4a56b2d58ca0de0bb7f6",
      "e3c71b92f2a0484bb70123a86f855f9d",
      "dd27134d896448b6b385ce45da7556ee",
      "c92040617a854d8d96cc8ba678f0b271",
      "367cfe385d38427dbdf4325a70c0dc2e",
      "f86a86b6b9c64cc989e89b27693d8a2f",
      "14dc24ef59d341a88d1bdb69f3cacde6",
      "46cc6e7671244f1d9167855a45a36af8",
      "81821a97e02445539ccabcc2091cba95",
      "212a6447739d45b5b57e5815ff538f57",
      "4b1f7506e1a44d109d918b1f16d6bb75",
      "f177b91513ec4039bc7c6e61d15db9a2",
      "00554915f7ad47b9b80d65294dbfdd37",
      "d5f641be531341dbb007330b7e245169",
      "7158ce3f315647aba9299519fcec4be7",
      "0768ccf7a2e64f819c7401d7db258d16"
     ]
    },
    "id": "T-krnPy6TDSB",
    "outputId": "7161b883-f15a-449f-86fa-e8bbbfc6e9c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcf0208c6e34c70aedc1fb6cab34d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b348ab9d93d44d29b4d22128c8343b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29cd31fc93304104af825e6d0d2a5199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rename_column_ is deprecated and will be removed in the next major version of datasets. Use the dataset.rename_column method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='16000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16000/114000 1:04:27 < 6:34:51, 4.14 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.988900</td>\n",
       "      <td>0.352838</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>0.888068</td>\n",
       "      <td>0.888100</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>99.097600</td>\n",
       "      <td>76.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.552767</td>\n",
       "      <td>0.890132</td>\n",
       "      <td>0.890381</td>\n",
       "      <td>0.894159</td>\n",
       "      <td>0.890132</td>\n",
       "      <td>99.547400</td>\n",
       "      <td>76.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.525628</td>\n",
       "      <td>0.891053</td>\n",
       "      <td>0.890309</td>\n",
       "      <td>0.892337</td>\n",
       "      <td>0.891053</td>\n",
       "      <td>99.504600</td>\n",
       "      <td>76.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.410898</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>0.908635</td>\n",
       "      <td>0.909427</td>\n",
       "      <td>0.908553</td>\n",
       "      <td>99.392500</td>\n",
       "      <td>76.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.475200</td>\n",
       "      <td>0.471517</td>\n",
       "      <td>0.905789</td>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.906456</td>\n",
       "      <td>0.905789</td>\n",
       "      <td>99.337900</td>\n",
       "      <td>76.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.403315</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>0.909406</td>\n",
       "      <td>0.909337</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>99.348200</td>\n",
       "      <td>76.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.460300</td>\n",
       "      <td>0.634986</td>\n",
       "      <td>0.885789</td>\n",
       "      <td>0.884347</td>\n",
       "      <td>0.887594</td>\n",
       "      <td>0.885789</td>\n",
       "      <td>99.407900</td>\n",
       "      <td>76.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.900658</td>\n",
       "      <td>0.900565</td>\n",
       "      <td>0.902545</td>\n",
       "      <td>0.900658</td>\n",
       "      <td>99.447000</td>\n",
       "      <td>76.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.483188</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>0.902507</td>\n",
       "      <td>0.907761</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>99.395700</td>\n",
       "      <td>76.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.555143</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.887378</td>\n",
       "      <td>0.892664</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>99.450800</td>\n",
       "      <td>76.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>0.453612</td>\n",
       "      <td>0.900921</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>0.904432</td>\n",
       "      <td>0.900921</td>\n",
       "      <td>99.428700</td>\n",
       "      <td>76.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.596135</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900033</td>\n",
       "      <td>0.903110</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>99.434500</td>\n",
       "      <td>76.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.569100</td>\n",
       "      <td>0.593725</td>\n",
       "      <td>0.890921</td>\n",
       "      <td>0.890902</td>\n",
       "      <td>0.898316</td>\n",
       "      <td>0.890921</td>\n",
       "      <td>99.352200</td>\n",
       "      <td>76.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.898553</td>\n",
       "      <td>0.898468</td>\n",
       "      <td>0.901924</td>\n",
       "      <td>0.898553</td>\n",
       "      <td>99.304400</td>\n",
       "      <td>76.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.546900</td>\n",
       "      <td>0.555309</td>\n",
       "      <td>0.888026</td>\n",
       "      <td>0.886935</td>\n",
       "      <td>0.891507</td>\n",
       "      <td>0.888026</td>\n",
       "      <td>99.338700</td>\n",
       "      <td>76.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.632100</td>\n",
       "      <td>0.717251</td>\n",
       "      <td>0.860132</td>\n",
       "      <td>0.861742</td>\n",
       "      <td>0.871955</td>\n",
       "      <td>0.860132</td>\n",
       "      <td>99.323600</td>\n",
       "      <td>76.518000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+ORIG\n",
      "{'eval_loss': 0.4033150374889374, 'eval_accuracy': 0.9097368421052632, 'eval_f1': 0.9094061072012141, 'eval_precision': 0.9093367410880967, 'eval_recall': 0.9097368421052632, 'eval_runtime': 99.7262, 'eval_samples_per_second': 76.209, 'epoch': 0.42, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+ORIG', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+ORIG\n",
      "{'eval_loss': 0.7385788559913635, 'eval_accuracy': 0.837037037037037, 'eval_f1': 0.6280575721260904, 'eval_precision': 0.6296224723386277, 'eval_recall': 0.6327219457577359, 'eval_runtime': 90.5726, 'eval_samples_per_second': 76.016, 'epoch': 0.42, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662761528d2b458d8eb57e5cecdb98fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0372866447c4cf7ba46ca3a8b756f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8153d7eca8174037b99e5f9730e52c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='21000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21000/228000 1:24:35 < 13:53:55, 4.14 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.252200</td>\n",
       "      <td>0.803688</td>\n",
       "      <td>0.831711</td>\n",
       "      <td>0.828349</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.831711</td>\n",
       "      <td>99.686300</td>\n",
       "      <td>76.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.469749</td>\n",
       "      <td>0.880263</td>\n",
       "      <td>0.880172</td>\n",
       "      <td>0.889672</td>\n",
       "      <td>0.880263</td>\n",
       "      <td>99.495500</td>\n",
       "      <td>76.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.490700</td>\n",
       "      <td>0.438498</td>\n",
       "      <td>0.896053</td>\n",
       "      <td>0.895857</td>\n",
       "      <td>0.900809</td>\n",
       "      <td>0.896053</td>\n",
       "      <td>99.374000</td>\n",
       "      <td>76.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.525659</td>\n",
       "      <td>0.894605</td>\n",
       "      <td>0.893364</td>\n",
       "      <td>0.901063</td>\n",
       "      <td>0.894605</td>\n",
       "      <td>99.401700</td>\n",
       "      <td>76.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.463651</td>\n",
       "      <td>0.907237</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>0.908788</td>\n",
       "      <td>0.907237</td>\n",
       "      <td>99.352800</td>\n",
       "      <td>76.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.412154</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.907110</td>\n",
       "      <td>0.908811</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>99.325300</td>\n",
       "      <td>76.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>0.476239</td>\n",
       "      <td>0.900395</td>\n",
       "      <td>0.900437</td>\n",
       "      <td>0.905031</td>\n",
       "      <td>0.900395</td>\n",
       "      <td>99.284900</td>\n",
       "      <td>76.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.474432</td>\n",
       "      <td>0.908816</td>\n",
       "      <td>0.908096</td>\n",
       "      <td>0.908215</td>\n",
       "      <td>0.908816</td>\n",
       "      <td>99.296000</td>\n",
       "      <td>76.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.418811</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.915012</td>\n",
       "      <td>0.916876</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>99.269900</td>\n",
       "      <td>76.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.413746</td>\n",
       "      <td>0.914342</td>\n",
       "      <td>0.914438</td>\n",
       "      <td>0.915978</td>\n",
       "      <td>0.914342</td>\n",
       "      <td>99.327900</td>\n",
       "      <td>76.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.474800</td>\n",
       "      <td>0.388141</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.919906</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>99.271400</td>\n",
       "      <td>76.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.457106</td>\n",
       "      <td>0.905526</td>\n",
       "      <td>0.906115</td>\n",
       "      <td>0.911761</td>\n",
       "      <td>0.905526</td>\n",
       "      <td>99.191000</td>\n",
       "      <td>76.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.373612</td>\n",
       "      <td>0.919342</td>\n",
       "      <td>0.919636</td>\n",
       "      <td>0.920687</td>\n",
       "      <td>0.919342</td>\n",
       "      <td>99.190600</td>\n",
       "      <td>76.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.457345</td>\n",
       "      <td>0.900132</td>\n",
       "      <td>0.901007</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.900132</td>\n",
       "      <td>99.135000</td>\n",
       "      <td>76.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.413411</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>0.919394</td>\n",
       "      <td>0.919811</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>99.085800</td>\n",
       "      <td>76.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.484805</td>\n",
       "      <td>0.903026</td>\n",
       "      <td>0.903031</td>\n",
       "      <td>0.907592</td>\n",
       "      <td>0.903026</td>\n",
       "      <td>99.086500</td>\n",
       "      <td>76.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.503094</td>\n",
       "      <td>0.905921</td>\n",
       "      <td>0.905534</td>\n",
       "      <td>0.907430</td>\n",
       "      <td>0.905921</td>\n",
       "      <td>99.049500</td>\n",
       "      <td>76.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.523800</td>\n",
       "      <td>0.455026</td>\n",
       "      <td>0.889605</td>\n",
       "      <td>0.887665</td>\n",
       "      <td>0.900484</td>\n",
       "      <td>0.889605</td>\n",
       "      <td>99.030100</td>\n",
       "      <td>76.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.471200</td>\n",
       "      <td>0.530345</td>\n",
       "      <td>0.899079</td>\n",
       "      <td>0.899145</td>\n",
       "      <td>0.904786</td>\n",
       "      <td>0.899079</td>\n",
       "      <td>99.046000</td>\n",
       "      <td>76.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.534621</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.899641</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>99.009800</td>\n",
       "      <td>76.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.514169</td>\n",
       "      <td>0.904342</td>\n",
       "      <td>0.904437</td>\n",
       "      <td>0.908098</td>\n",
       "      <td>0.904342</td>\n",
       "      <td>99.016400</td>\n",
       "      <td>76.755000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.3881412446498871, 'eval_accuracy': 0.9196052631578947, 'eval_f1': 0.9194067849580483, 'eval_precision': 0.9199058408527168, 'eval_recall': 0.9196052631578948, 'eval_runtime': 99.5063, 'eval_samples_per_second': 76.377, 'epoch': 0.28, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+INV', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.6264991164207458, 'eval_accuracy': 0.8460421205519245, 'eval_f1': 0.6470054431060661, 'eval_precision': 0.6649069266909127, 'eval_recall': 0.6313812166447672, 'eval_runtime': 90.4282, 'eval_samples_per_second': 76.138, 'epoch': 0.28, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+INV'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04a065bfaf34c029d457c91c7f1858a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc60fb3204914dc4a9960e4d9eefa6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb9825534564c9d9dfc7e1d18c584ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 24000/228000 2:00:07 < 17:01:08, 3.33 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.248800</td>\n",
       "      <td>0.868032</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>157.149700</td>\n",
       "      <td>76.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.672500</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.762249</td>\n",
       "      <td>156.855200</td>\n",
       "      <td>76.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.611300</td>\n",
       "      <td>0.578718</td>\n",
       "      <td>0.774072</td>\n",
       "      <td>156.941700</td>\n",
       "      <td>76.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.585700</td>\n",
       "      <td>0.618272</td>\n",
       "      <td>0.771641</td>\n",
       "      <td>156.902200</td>\n",
       "      <td>76.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.571500</td>\n",
       "      <td>0.652651</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>156.906800</td>\n",
       "      <td>76.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.578430</td>\n",
       "      <td>0.773788</td>\n",
       "      <td>156.926100</td>\n",
       "      <td>76.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>0.590061</td>\n",
       "      <td>0.775067</td>\n",
       "      <td>156.947000</td>\n",
       "      <td>76.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.635154</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>156.841400</td>\n",
       "      <td>76.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.583565</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>156.903000</td>\n",
       "      <td>76.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.577659</td>\n",
       "      <td>0.764488</td>\n",
       "      <td>156.919300</td>\n",
       "      <td>76.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>0.782315</td>\n",
       "      <td>156.963600</td>\n",
       "      <td>76.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>0.774034</td>\n",
       "      <td>156.966000</td>\n",
       "      <td>76.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>0.605756</td>\n",
       "      <td>0.768630</td>\n",
       "      <td>156.954100</td>\n",
       "      <td>76.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.564669</td>\n",
       "      <td>0.792542</td>\n",
       "      <td>156.896600</td>\n",
       "      <td>76.483000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.567315</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>157.000100</td>\n",
       "      <td>76.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.567800</td>\n",
       "      <td>0.555885</td>\n",
       "      <td>0.771591</td>\n",
       "      <td>156.772900</td>\n",
       "      <td>76.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.594400</td>\n",
       "      <td>0.676927</td>\n",
       "      <td>0.772381</td>\n",
       "      <td>156.695200</td>\n",
       "      <td>76.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.575163</td>\n",
       "      <td>0.763461</td>\n",
       "      <td>156.546200</td>\n",
       "      <td>76.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>0.646248</td>\n",
       "      <td>0.769360</td>\n",
       "      <td>156.555100</td>\n",
       "      <td>76.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.590496</td>\n",
       "      <td>0.765800</td>\n",
       "      <td>156.545700</td>\n",
       "      <td>76.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.586800</td>\n",
       "      <td>0.605474</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>156.687500</td>\n",
       "      <td>76.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.628778</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>156.871600</td>\n",
       "      <td>76.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.646800</td>\n",
       "      <td>0.633106</td>\n",
       "      <td>0.781332</td>\n",
       "      <td>156.913300</td>\n",
       "      <td>76.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.635200</td>\n",
       "      <td>0.641731</td>\n",
       "      <td>0.776030</td>\n",
       "      <td>156.825000</td>\n",
       "      <td>76.518000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+SIB\n",
      "{'eval_loss': 28.322521209716797, 'eval_accuracy': 0.916578947368421, 'eval_f1': 0.9163817606666912, 'eval_precision': 0.9167379706623926, 'eval_recall': 0.916578947368421, 'eval_runtime': 99.4292, 'eval_samples_per_second': 76.436, 'epoch': 0.32, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+SIB', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+SIB\n",
      "{'eval_loss': 30.492338180541992, 'eval_accuracy': 0.837763253449528, 'eval_f1': 0.6353210078306538, 'eval_precision': 0.6499897335014365, 'eval_recall': 0.6299928576520968, 'eval_runtime': 90.3602, 'eval_samples_per_second': 76.195, 'epoch': 0.32, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+SIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eb956cea124421b6e968c05174768b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c11262915a4f7d8c7cc940ae03f808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d61caab1c37422eb89336f3a6cf49fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='21000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21000/228000 1:45:25 < 17:19:22, 3.32 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.217100</td>\n",
       "      <td>0.762999</td>\n",
       "      <td>0.795851</td>\n",
       "      <td>157.545600</td>\n",
       "      <td>76.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.557700</td>\n",
       "      <td>0.513460</td>\n",
       "      <td>0.832335</td>\n",
       "      <td>157.445800</td>\n",
       "      <td>76.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.535400</td>\n",
       "      <td>0.539572</td>\n",
       "      <td>0.833888</td>\n",
       "      <td>157.405600</td>\n",
       "      <td>76.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.556445</td>\n",
       "      <td>0.832132</td>\n",
       "      <td>157.385900</td>\n",
       "      <td>76.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.524399</td>\n",
       "      <td>0.840626</td>\n",
       "      <td>157.771800</td>\n",
       "      <td>76.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.497200</td>\n",
       "      <td>0.514330</td>\n",
       "      <td>0.824058</td>\n",
       "      <td>157.984700</td>\n",
       "      <td>75.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.532900</td>\n",
       "      <td>0.468887</td>\n",
       "      <td>0.832444</td>\n",
       "      <td>157.989300</td>\n",
       "      <td>75.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.541108</td>\n",
       "      <td>0.835458</td>\n",
       "      <td>157.878200</td>\n",
       "      <td>76.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.526469</td>\n",
       "      <td>0.846403</td>\n",
       "      <td>157.967100</td>\n",
       "      <td>75.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.516500</td>\n",
       "      <td>0.501617</td>\n",
       "      <td>0.838525</td>\n",
       "      <td>157.888800</td>\n",
       "      <td>76.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>0.465314</td>\n",
       "      <td>0.847793</td>\n",
       "      <td>157.909000</td>\n",
       "      <td>75.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>0.641925</td>\n",
       "      <td>0.809469</td>\n",
       "      <td>157.954100</td>\n",
       "      <td>75.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.520500</td>\n",
       "      <td>0.470172</td>\n",
       "      <td>0.842813</td>\n",
       "      <td>157.974700</td>\n",
       "      <td>75.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.452562</td>\n",
       "      <td>0.843657</td>\n",
       "      <td>157.960400</td>\n",
       "      <td>75.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.548200</td>\n",
       "      <td>0.527427</td>\n",
       "      <td>0.839473</td>\n",
       "      <td>157.925800</td>\n",
       "      <td>75.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.462887</td>\n",
       "      <td>0.845576</td>\n",
       "      <td>157.944800</td>\n",
       "      <td>75.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.530611</td>\n",
       "      <td>0.845047</td>\n",
       "      <td>157.902200</td>\n",
       "      <td>75.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.549400</td>\n",
       "      <td>0.560158</td>\n",
       "      <td>0.842917</td>\n",
       "      <td>157.876500</td>\n",
       "      <td>76.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.619866</td>\n",
       "      <td>0.817008</td>\n",
       "      <td>157.838400</td>\n",
       "      <td>76.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.554199</td>\n",
       "      <td>0.828910</td>\n",
       "      <td>157.819500</td>\n",
       "      <td>76.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.559100</td>\n",
       "      <td>0.489122</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>157.745400</td>\n",
       "      <td>76.072000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 29.862548828125, 'eval_accuracy': 0.9123684210526316, 'eval_f1': 0.9121085818185244, 'eval_precision': 0.9124523394613038, 'eval_recall': 0.9123684210526315, 'eval_runtime': 99.7859, 'eval_samples_per_second': 76.163, 'epoch': 0.28, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+INVSIB', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 32.26008224487305, 'eval_accuracy': 0.8437182280319535, 'eval_f1': 0.6348138177857947, 'eval_precision': 0.6405850390711187, 'eval_recall': 0.6333807046505737, 'eval_runtime': 90.6306, 'eval_samples_per_second': 75.968, 'epoch': 0.28, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+INVSIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea2dcc8b1bb47b3affa26dba313296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588a5686027841a9b1077e8ca6a68351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8dd57845664255b6814a11470045ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 24000/228000 2:00:16 < 17:02:25, 3.33 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.248500</td>\n",
       "      <td>0.875998</td>\n",
       "      <td>0.692331</td>\n",
       "      <td>157.658700</td>\n",
       "      <td>76.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.587132</td>\n",
       "      <td>0.777458</td>\n",
       "      <td>157.202800</td>\n",
       "      <td>76.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.577437</td>\n",
       "      <td>0.748185</td>\n",
       "      <td>157.168000</td>\n",
       "      <td>76.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.578300</td>\n",
       "      <td>0.648647</td>\n",
       "      <td>0.771997</td>\n",
       "      <td>156.997400</td>\n",
       "      <td>76.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.580755</td>\n",
       "      <td>0.790991</td>\n",
       "      <td>156.820200</td>\n",
       "      <td>76.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>0.578808</td>\n",
       "      <td>0.776330</td>\n",
       "      <td>156.770100</td>\n",
       "      <td>76.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.586657</td>\n",
       "      <td>0.777040</td>\n",
       "      <td>156.768000</td>\n",
       "      <td>76.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.554200</td>\n",
       "      <td>0.562955</td>\n",
       "      <td>0.803224</td>\n",
       "      <td>156.872500</td>\n",
       "      <td>76.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.583660</td>\n",
       "      <td>0.765461</td>\n",
       "      <td>156.869700</td>\n",
       "      <td>76.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.543700</td>\n",
       "      <td>0.567263</td>\n",
       "      <td>0.773353</td>\n",
       "      <td>157.095500</td>\n",
       "      <td>76.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.553100</td>\n",
       "      <td>0.552022</td>\n",
       "      <td>0.791431</td>\n",
       "      <td>157.329200</td>\n",
       "      <td>76.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.587700</td>\n",
       "      <td>0.623499</td>\n",
       "      <td>0.775846</td>\n",
       "      <td>157.270600</td>\n",
       "      <td>76.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.563907</td>\n",
       "      <td>0.790348</td>\n",
       "      <td>157.248800</td>\n",
       "      <td>76.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.586391</td>\n",
       "      <td>0.819458</td>\n",
       "      <td>157.357200</td>\n",
       "      <td>76.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>0.532560</td>\n",
       "      <td>0.788124</td>\n",
       "      <td>157.258000</td>\n",
       "      <td>76.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.534400</td>\n",
       "      <td>0.545852</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>157.296600</td>\n",
       "      <td>76.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.553605</td>\n",
       "      <td>0.790946</td>\n",
       "      <td>157.190300</td>\n",
       "      <td>76.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.527287</td>\n",
       "      <td>0.798005</td>\n",
       "      <td>157.283500</td>\n",
       "      <td>76.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.554589</td>\n",
       "      <td>0.764560</td>\n",
       "      <td>157.281400</td>\n",
       "      <td>76.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.563900</td>\n",
       "      <td>0.557016</td>\n",
       "      <td>0.785840</td>\n",
       "      <td>157.245200</td>\n",
       "      <td>76.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.536900</td>\n",
       "      <td>0.724913</td>\n",
       "      <td>0.743800</td>\n",
       "      <td>157.272500</td>\n",
       "      <td>76.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.519777</td>\n",
       "      <td>0.767294</td>\n",
       "      <td>157.353800</td>\n",
       "      <td>76.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.685729</td>\n",
       "      <td>0.741552</td>\n",
       "      <td>157.184500</td>\n",
       "      <td>76.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.610568</td>\n",
       "      <td>0.783238</td>\n",
       "      <td>157.167100</td>\n",
       "      <td>76.352000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 30.897172927856445, 'eval_accuracy': 0.9222368421052631, 'eval_f1': 0.9222287729685831, 'eval_precision': 0.9225743264714401, 'eval_recall': 0.9222368421052632, 'eval_runtime': 99.1179, 'eval_samples_per_second': 76.676, 'epoch': 0.32, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 35.25430679321289, 'eval_accuracy': 0.8827886710239652, 'eval_f1': 0.6527804137681926, 'eval_precision': 0.6748044403786122, 'eval_recall': 0.6335572844876527, 'eval_runtime': 89.9611, 'eval_samples_per_second': 76.533, 'epoch': 0.32, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+TextMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c9869d45d4288b0f49b1dad797ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0597c89ab23242b0a8b610a6279496c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff915e995564bd99996a47eca0bf00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24000' max='342000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 24000/342000 2:32:05 < 33:35:21, 2.63 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.090200</td>\n",
       "      <td>0.871683</td>\n",
       "      <td>0.552291</td>\n",
       "      <td>237.105100</td>\n",
       "      <td>75.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.674100</td>\n",
       "      <td>0.539954</td>\n",
       "      <td>0.635341</td>\n",
       "      <td>236.788100</td>\n",
       "      <td>76.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.545500</td>\n",
       "      <td>0.494252</td>\n",
       "      <td>0.648102</td>\n",
       "      <td>236.519400</td>\n",
       "      <td>76.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.480785</td>\n",
       "      <td>0.641924</td>\n",
       "      <td>236.616300</td>\n",
       "      <td>76.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.506100</td>\n",
       "      <td>0.478216</td>\n",
       "      <td>0.652450</td>\n",
       "      <td>236.727100</td>\n",
       "      <td>76.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.486739</td>\n",
       "      <td>0.632091</td>\n",
       "      <td>236.691100</td>\n",
       "      <td>76.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.467688</td>\n",
       "      <td>0.638218</td>\n",
       "      <td>236.737300</td>\n",
       "      <td>76.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.470502</td>\n",
       "      <td>0.645665</td>\n",
       "      <td>236.732300</td>\n",
       "      <td>76.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.488926</td>\n",
       "      <td>0.650672</td>\n",
       "      <td>236.745700</td>\n",
       "      <td>76.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.463300</td>\n",
       "      <td>0.461195</td>\n",
       "      <td>0.664419</td>\n",
       "      <td>236.545300</td>\n",
       "      <td>76.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>0.483927</td>\n",
       "      <td>0.650202</td>\n",
       "      <td>235.925700</td>\n",
       "      <td>76.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.489011</td>\n",
       "      <td>0.651101</td>\n",
       "      <td>235.891100</td>\n",
       "      <td>76.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.468100</td>\n",
       "      <td>0.440721</td>\n",
       "      <td>0.659851</td>\n",
       "      <td>235.921500</td>\n",
       "      <td>76.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.693066</td>\n",
       "      <td>235.895900</td>\n",
       "      <td>76.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.454491</td>\n",
       "      <td>0.683555</td>\n",
       "      <td>236.032300</td>\n",
       "      <td>76.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.482267</td>\n",
       "      <td>0.680457</td>\n",
       "      <td>236.259400</td>\n",
       "      <td>76.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.440781</td>\n",
       "      <td>0.689759</td>\n",
       "      <td>236.375500</td>\n",
       "      <td>76.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.435246</td>\n",
       "      <td>0.670823</td>\n",
       "      <td>236.495900</td>\n",
       "      <td>76.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.478200</td>\n",
       "      <td>0.440368</td>\n",
       "      <td>0.670248</td>\n",
       "      <td>236.545400</td>\n",
       "      <td>76.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.511098</td>\n",
       "      <td>0.662899</td>\n",
       "      <td>236.591300</td>\n",
       "      <td>76.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.461831</td>\n",
       "      <td>0.671588</td>\n",
       "      <td>236.662600</td>\n",
       "      <td>76.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.516875</td>\n",
       "      <td>0.665949</td>\n",
       "      <td>236.627600</td>\n",
       "      <td>76.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.524904</td>\n",
       "      <td>0.678160</td>\n",
       "      <td>236.776000</td>\n",
       "      <td>76.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.636177</td>\n",
       "      <td>236.715000</td>\n",
       "      <td>76.041000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 28.166885375976562, 'eval_accuracy': 0.9234210526315789, 'eval_f1': 0.9232460652517472, 'eval_precision': 0.9234335183887521, 'eval_recall': 0.9234210526315789, 'eval_runtime': 99.6893, 'eval_samples_per_second': 76.237, 'epoch': 0.21, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 31.715604782104492, 'eval_accuracy': 0.8610021786492374, 'eval_f1': 0.6217180999731503, 'eval_precision': 0.6560021103465739, 'eval_recall': 0.599704937595565, 'eval_runtime': 90.6367, 'eval_samples_per_second': 75.963, 'epoch': 0.21, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+SentMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a105e11518aa46d5a65f8bfe52adb0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b63feec57a4b9198215f7480eb8842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-ad6459d6b11e013c.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ed492c7fa14d6a8fc9638aa34d4a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='30000' max='456000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 30000/456000 3:49:08 < 54:14:07, 2.18 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.951800</td>\n",
       "      <td>0.858275</td>\n",
       "      <td>0.356838</td>\n",
       "      <td>315.339200</td>\n",
       "      <td>76.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.502162</td>\n",
       "      <td>0.509839</td>\n",
       "      <td>314.814800</td>\n",
       "      <td>76.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.444456</td>\n",
       "      <td>0.518961</td>\n",
       "      <td>314.754800</td>\n",
       "      <td>76.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.423378</td>\n",
       "      <td>0.534421</td>\n",
       "      <td>314.607300</td>\n",
       "      <td>76.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.416031</td>\n",
       "      <td>0.536883</td>\n",
       "      <td>314.898000</td>\n",
       "      <td>76.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.401901</td>\n",
       "      <td>0.537332</td>\n",
       "      <td>314.837000</td>\n",
       "      <td>76.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.430192</td>\n",
       "      <td>0.528145</td>\n",
       "      <td>314.658100</td>\n",
       "      <td>76.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.401363</td>\n",
       "      <td>0.534487</td>\n",
       "      <td>314.425400</td>\n",
       "      <td>76.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.401350</td>\n",
       "      <td>0.545044</td>\n",
       "      <td>314.507100</td>\n",
       "      <td>76.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.416524</td>\n",
       "      <td>0.549767</td>\n",
       "      <td>314.544700</td>\n",
       "      <td>76.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.423280</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>314.732700</td>\n",
       "      <td>76.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.410638</td>\n",
       "      <td>0.532572</td>\n",
       "      <td>314.580600</td>\n",
       "      <td>76.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.435814</td>\n",
       "      <td>0.544481</td>\n",
       "      <td>314.756200</td>\n",
       "      <td>76.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.424852</td>\n",
       "      <td>0.543937</td>\n",
       "      <td>314.399000</td>\n",
       "      <td>76.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.412087</td>\n",
       "      <td>0.528495</td>\n",
       "      <td>314.833300</td>\n",
       "      <td>76.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.426841</td>\n",
       "      <td>0.537155</td>\n",
       "      <td>314.923800</td>\n",
       "      <td>76.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.405331</td>\n",
       "      <td>0.560517</td>\n",
       "      <td>314.849900</td>\n",
       "      <td>76.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.439076</td>\n",
       "      <td>0.548942</td>\n",
       "      <td>314.726500</td>\n",
       "      <td>76.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.409384</td>\n",
       "      <td>0.553242</td>\n",
       "      <td>314.775200</td>\n",
       "      <td>76.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.403761</td>\n",
       "      <td>0.561430</td>\n",
       "      <td>314.537600</td>\n",
       "      <td>76.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.416568</td>\n",
       "      <td>0.526686</td>\n",
       "      <td>314.245900</td>\n",
       "      <td>76.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.401083</td>\n",
       "      <td>0.534232</td>\n",
       "      <td>313.656000</td>\n",
       "      <td>76.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.398319</td>\n",
       "      <td>0.554293</td>\n",
       "      <td>313.703700</td>\n",
       "      <td>76.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.439253</td>\n",
       "      <td>0.535982</td>\n",
       "      <td>313.756300</td>\n",
       "      <td>76.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.382209</td>\n",
       "      <td>0.559884</td>\n",
       "      <td>314.265300</td>\n",
       "      <td>76.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.420124</td>\n",
       "      <td>0.558633</td>\n",
       "      <td>314.721600</td>\n",
       "      <td>76.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.419492</td>\n",
       "      <td>0.540173</td>\n",
       "      <td>314.742800</td>\n",
       "      <td>76.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.384669</td>\n",
       "      <td>0.557908</td>\n",
       "      <td>314.899500</td>\n",
       "      <td>76.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.407887</td>\n",
       "      <td>0.518896</td>\n",
       "      <td>314.939700</td>\n",
       "      <td>76.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.414059</td>\n",
       "      <td>0.535619</td>\n",
       "      <td>314.905500</td>\n",
       "      <td>76.213000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/bert-base-uncased-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 29.58136749267578, 'eval_accuracy': 0.9196052631578947, 'eval_f1': 0.9197204941804656, 'eval_precision': 0.9207344909193765, 'eval_recall': 0.9196052631578947, 'eval_runtime': 99.6425, 'eval_samples_per_second': 76.273, 'epoch': 0.2, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/bert-base-uncased-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 34.08938217163086, 'eval_accuracy': 0.8663761801016703, 'eval_f1': 0.6379973514983143, 'eval_precision': 0.6448958199824899, 'eval_recall': 0.6326280193756362, 'eval_runtime': 90.4663, 'eval_samples_per_second': 76.106, 'epoch': 0.2, 'run': 'pretrained/bert-base-uncased-ag_news-ORIG+WordMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391b8a61a6ce4b0399bde6a16ffa4859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3af3876327e4617820b82f6c16c06d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5fcbe168dd4f1d93e2af8d588d151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 14000/114000 57:42 < 6:52:12, 4.04 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.937400</td>\n",
       "      <td>0.432164</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894513</td>\n",
       "      <td>0.897194</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>98.939600</td>\n",
       "      <td>76.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.603055</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.892208</td>\n",
       "      <td>0.897569</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>98.815500</td>\n",
       "      <td>76.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.474691</td>\n",
       "      <td>0.904474</td>\n",
       "      <td>0.904231</td>\n",
       "      <td>0.904497</td>\n",
       "      <td>0.904474</td>\n",
       "      <td>98.766100</td>\n",
       "      <td>76.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.909079</td>\n",
       "      <td>0.909006</td>\n",
       "      <td>0.910443</td>\n",
       "      <td>0.909079</td>\n",
       "      <td>98.770300</td>\n",
       "      <td>76.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.465900</td>\n",
       "      <td>0.526399</td>\n",
       "      <td>0.900789</td>\n",
       "      <td>0.900731</td>\n",
       "      <td>0.902092</td>\n",
       "      <td>0.900789</td>\n",
       "      <td>98.744300</td>\n",
       "      <td>76.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.463600</td>\n",
       "      <td>0.459006</td>\n",
       "      <td>0.907368</td>\n",
       "      <td>0.907355</td>\n",
       "      <td>0.907718</td>\n",
       "      <td>0.907368</td>\n",
       "      <td>98.769100</td>\n",
       "      <td>76.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.581536</td>\n",
       "      <td>0.882368</td>\n",
       "      <td>0.882437</td>\n",
       "      <td>0.891973</td>\n",
       "      <td>0.882368</td>\n",
       "      <td>98.776500</td>\n",
       "      <td>76.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.517888</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.905364</td>\n",
       "      <td>0.906708</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>98.733900</td>\n",
       "      <td>76.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.514500</td>\n",
       "      <td>0.548614</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894357</td>\n",
       "      <td>0.898308</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>98.747900</td>\n",
       "      <td>76.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.552400</td>\n",
       "      <td>0.574086</td>\n",
       "      <td>0.890132</td>\n",
       "      <td>0.888993</td>\n",
       "      <td>0.893776</td>\n",
       "      <td>0.890132</td>\n",
       "      <td>98.679600</td>\n",
       "      <td>77.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.580500</td>\n",
       "      <td>0.586290</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.867130</td>\n",
       "      <td>0.882841</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>98.748000</td>\n",
       "      <td>76.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.811731</td>\n",
       "      <td>0.682368</td>\n",
       "      <td>0.605776</td>\n",
       "      <td>0.567845</td>\n",
       "      <td>0.682368</td>\n",
       "      <td>98.665700</td>\n",
       "      <td>77.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.813300</td>\n",
       "      <td>0.806048</td>\n",
       "      <td>0.649868</td>\n",
       "      <td>0.579339</td>\n",
       "      <td>0.575133</td>\n",
       "      <td>0.649868</td>\n",
       "      <td>98.649200</td>\n",
       "      <td>77.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.397742</td>\n",
       "      <td>0.267763</td>\n",
       "      <td>0.134748</td>\n",
       "      <td>0.531480</td>\n",
       "      <td>0.267763</td>\n",
       "      <td>98.676200</td>\n",
       "      <td>77.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+ORIG\n",
      "{'eval_loss': 0.47654083371162415, 'eval_accuracy': 0.9090789473684211, 'eval_f1': 0.9090061024100096, 'eval_precision': 0.910443011846536, 'eval_recall': 0.9090789473684211, 'eval_runtime': 98.412, 'eval_samples_per_second': 77.226, 'epoch': 0.37, 'run': 'pretrained/roberta-base-ag_news-ORIG+ORIG', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+ORIG\n",
      "{'eval_loss': 0.6181355714797974, 'eval_accuracy': 0.8723311546840958, 'eval_f1': 0.6425970259273684, 'eval_precision': 0.6457203714922186, 'eval_recall': 0.6408438120509388, 'eval_runtime': 89.693, 'eval_samples_per_second': 76.762, 'epoch': 0.37, 'run': 'pretrained/roberta-base-ag_news-ORIG+ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35855a2c660644aea03304d07c25b2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd3e01ebcdb4449bd50ed8938805ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f9395918d2495d9ee6ff576114a4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='23000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 23000/228000 1:34:53 < 14:05:52, 4.04 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.166000</td>\n",
       "      <td>0.394815</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.874449</td>\n",
       "      <td>0.875480</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>99.031000</td>\n",
       "      <td>76.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.484500</td>\n",
       "      <td>0.561577</td>\n",
       "      <td>0.891579</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>0.894082</td>\n",
       "      <td>0.891579</td>\n",
       "      <td>98.908600</td>\n",
       "      <td>76.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.391491</td>\n",
       "      <td>0.907632</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.909636</td>\n",
       "      <td>0.907632</td>\n",
       "      <td>98.792500</td>\n",
       "      <td>76.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>0.512982</td>\n",
       "      <td>0.904868</td>\n",
       "      <td>0.903972</td>\n",
       "      <td>0.908100</td>\n",
       "      <td>0.904868</td>\n",
       "      <td>98.807700</td>\n",
       "      <td>76.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.521181</td>\n",
       "      <td>0.904079</td>\n",
       "      <td>0.903531</td>\n",
       "      <td>0.904649</td>\n",
       "      <td>0.904079</td>\n",
       "      <td>98.804500</td>\n",
       "      <td>76.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.487700</td>\n",
       "      <td>0.465242</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>0.909120</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>98.779200</td>\n",
       "      <td>76.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.538200</td>\n",
       "      <td>0.406012</td>\n",
       "      <td>0.912105</td>\n",
       "      <td>0.911902</td>\n",
       "      <td>0.913485</td>\n",
       "      <td>0.912105</td>\n",
       "      <td>98.779100</td>\n",
       "      <td>76.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.534182</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.908239</td>\n",
       "      <td>0.908382</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>98.833600</td>\n",
       "      <td>76.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.443947</td>\n",
       "      <td>0.909211</td>\n",
       "      <td>0.909157</td>\n",
       "      <td>0.911095</td>\n",
       "      <td>0.909211</td>\n",
       "      <td>98.798000</td>\n",
       "      <td>76.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.527275</td>\n",
       "      <td>0.903553</td>\n",
       "      <td>0.903497</td>\n",
       "      <td>0.905428</td>\n",
       "      <td>0.903553</td>\n",
       "      <td>98.810200</td>\n",
       "      <td>76.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.528800</td>\n",
       "      <td>0.456860</td>\n",
       "      <td>0.911316</td>\n",
       "      <td>0.911174</td>\n",
       "      <td>0.912628</td>\n",
       "      <td>0.911316</td>\n",
       "      <td>98.796900</td>\n",
       "      <td>76.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.489021</td>\n",
       "      <td>0.901184</td>\n",
       "      <td>0.900125</td>\n",
       "      <td>0.909889</td>\n",
       "      <td>0.901184</td>\n",
       "      <td>98.782800</td>\n",
       "      <td>76.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>0.419195</td>\n",
       "      <td>0.915395</td>\n",
       "      <td>0.915411</td>\n",
       "      <td>0.915605</td>\n",
       "      <td>0.915395</td>\n",
       "      <td>98.867200</td>\n",
       "      <td>76.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.504100</td>\n",
       "      <td>0.470701</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>0.906941</td>\n",
       "      <td>0.907919</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>98.802100</td>\n",
       "      <td>76.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.516900</td>\n",
       "      <td>0.418136</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>0.910624</td>\n",
       "      <td>0.910854</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>98.764600</td>\n",
       "      <td>76.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>0.469574</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.905249</td>\n",
       "      <td>0.905585</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>98.843300</td>\n",
       "      <td>76.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>0.522357</td>\n",
       "      <td>0.888684</td>\n",
       "      <td>0.887458</td>\n",
       "      <td>0.892203</td>\n",
       "      <td>0.888684</td>\n",
       "      <td>98.799400</td>\n",
       "      <td>76.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.754600</td>\n",
       "      <td>0.783553</td>\n",
       "      <td>0.661579</td>\n",
       "      <td>0.589635</td>\n",
       "      <td>0.710025</td>\n",
       "      <td>0.661579</td>\n",
       "      <td>98.769600</td>\n",
       "      <td>76.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.906081</td>\n",
       "      <td>0.819474</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.861099</td>\n",
       "      <td>0.819474</td>\n",
       "      <td>98.796900</td>\n",
       "      <td>76.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.795700</td>\n",
       "      <td>0.749514</td>\n",
       "      <td>0.651184</td>\n",
       "      <td>0.584397</td>\n",
       "      <td>0.669048</td>\n",
       "      <td>0.651184</td>\n",
       "      <td>98.784600</td>\n",
       "      <td>76.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.183600</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>0.470395</td>\n",
       "      <td>0.353857</td>\n",
       "      <td>0.320889</td>\n",
       "      <td>0.470395</td>\n",
       "      <td>98.727300</td>\n",
       "      <td>76.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.156600</td>\n",
       "      <td>1.398035</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>98.718400</td>\n",
       "      <td>76.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.364500</td>\n",
       "      <td>1.214715</td>\n",
       "      <td>0.418684</td>\n",
       "      <td>0.282422</td>\n",
       "      <td>0.223751</td>\n",
       "      <td>0.418684</td>\n",
       "      <td>98.780600</td>\n",
       "      <td>76.938000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.4191950559616089, 'eval_accuracy': 0.9153947368421053, 'eval_f1': 0.9154108410249024, 'eval_precision': 0.9156046729186273, 'eval_recall': 0.9153947368421053, 'eval_runtime': 98.298, 'eval_samples_per_second': 77.316, 'epoch': 0.3, 'run': 'pretrained/roberta-base-ag_news-ORIG+INV', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.8295277953147888, 'eval_accuracy': 0.792156862745098, 'eval_f1': 0.6253903754257321, 'eval_precision': 0.66251156421205, 'eval_recall': 0.595616620037, 'eval_runtime': 89.6263, 'eval_samples_per_second': 76.819, 'epoch': 0.3, 'run': 'pretrained/roberta-base-ag_news-ORIG+INV'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b801431439094443b38749dbf44bbc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbab1c73bd7a43e59141f1c4d83e9006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca1bca4a3844028a751900813809a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='17000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17000/228000 1:26:53 < 17:58:31, 3.26 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.219700</td>\n",
       "      <td>0.652420</td>\n",
       "      <td>0.768045</td>\n",
       "      <td>157.318400</td>\n",
       "      <td>76.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.612829</td>\n",
       "      <td>0.790573</td>\n",
       "      <td>156.833400</td>\n",
       "      <td>76.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>0.565237</td>\n",
       "      <td>0.792021</td>\n",
       "      <td>156.767000</td>\n",
       "      <td>76.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.605146</td>\n",
       "      <td>0.764189</td>\n",
       "      <td>156.738500</td>\n",
       "      <td>76.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.595900</td>\n",
       "      <td>0.673987</td>\n",
       "      <td>0.766294</td>\n",
       "      <td>156.784100</td>\n",
       "      <td>76.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.591082</td>\n",
       "      <td>0.787536</td>\n",
       "      <td>156.770400</td>\n",
       "      <td>76.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.569322</td>\n",
       "      <td>0.811584</td>\n",
       "      <td>156.713400</td>\n",
       "      <td>76.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.624532</td>\n",
       "      <td>0.765035</td>\n",
       "      <td>156.776800</td>\n",
       "      <td>76.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>0.589353</td>\n",
       "      <td>0.778963</td>\n",
       "      <td>156.716300</td>\n",
       "      <td>76.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.591600</td>\n",
       "      <td>0.681393</td>\n",
       "      <td>0.770979</td>\n",
       "      <td>156.773500</td>\n",
       "      <td>76.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.594900</td>\n",
       "      <td>0.544670</td>\n",
       "      <td>0.763346</td>\n",
       "      <td>156.711300</td>\n",
       "      <td>76.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.619500</td>\n",
       "      <td>0.569417</td>\n",
       "      <td>0.780436</td>\n",
       "      <td>156.724400</td>\n",
       "      <td>76.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.587994</td>\n",
       "      <td>0.778513</td>\n",
       "      <td>156.906800</td>\n",
       "      <td>76.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.599200</td>\n",
       "      <td>0.576215</td>\n",
       "      <td>0.762242</td>\n",
       "      <td>156.654100</td>\n",
       "      <td>76.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>0.642740</td>\n",
       "      <td>0.769863</td>\n",
       "      <td>156.476700</td>\n",
       "      <td>76.689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.596502</td>\n",
       "      <td>0.783108</td>\n",
       "      <td>156.405700</td>\n",
       "      <td>76.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>0.616554</td>\n",
       "      <td>0.783222</td>\n",
       "      <td>156.326200</td>\n",
       "      <td>76.763000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+SIB\n",
      "{'eval_loss': 28.4146785736084, 'eval_accuracy': 0.9139473684210526, 'eval_f1': 0.9138727969768815, 'eval_precision': 0.9147344530067089, 'eval_recall': 0.9139473684210526, 'eval_runtime': 97.9732, 'eval_samples_per_second': 77.572, 'epoch': 0.22, 'run': 'pretrained/roberta-base-ag_news-ORIG+SIB', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+SIB\n",
      "{'eval_loss': 35.062110900878906, 'eval_accuracy': 0.8621641249092229, 'eval_f1': 0.6336866606603448, 'eval_precision': 0.6727786799117397, 'eval_recall': 0.6056947042705287, 'eval_runtime': 89.299, 'eval_samples_per_second': 77.101, 'epoch': 0.22, 'run': 'pretrained/roberta-base-ag_news-ORIG+SIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eed5b77f7f348ed99840ac3f609d59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadb2c8bd8b84d6483dd39c791f4a8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad7335ae70b4083852aae4d757e7169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='25000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 25000/228000 2:07:04 < 17:11:53, 3.28 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.194900</td>\n",
       "      <td>0.560067</td>\n",
       "      <td>0.810959</td>\n",
       "      <td>155.988500</td>\n",
       "      <td>76.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>0.547729</td>\n",
       "      <td>0.844907</td>\n",
       "      <td>155.747200</td>\n",
       "      <td>77.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.587455</td>\n",
       "      <td>0.833147</td>\n",
       "      <td>155.911800</td>\n",
       "      <td>76.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.630189</td>\n",
       "      <td>0.828062</td>\n",
       "      <td>156.051100</td>\n",
       "      <td>76.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.594924</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>156.015500</td>\n",
       "      <td>76.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.521130</td>\n",
       "      <td>0.833656</td>\n",
       "      <td>156.015700</td>\n",
       "      <td>76.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>0.564910</td>\n",
       "      <td>0.829595</td>\n",
       "      <td>155.922400</td>\n",
       "      <td>76.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.603293</td>\n",
       "      <td>0.830018</td>\n",
       "      <td>155.922700</td>\n",
       "      <td>76.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.529500</td>\n",
       "      <td>0.453696</td>\n",
       "      <td>0.841100</td>\n",
       "      <td>155.952100</td>\n",
       "      <td>76.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.544400</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.840132</td>\n",
       "      <td>155.964200</td>\n",
       "      <td>76.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.536200</td>\n",
       "      <td>0.472321</td>\n",
       "      <td>0.836949</td>\n",
       "      <td>156.041100</td>\n",
       "      <td>76.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.593970</td>\n",
       "      <td>0.811711</td>\n",
       "      <td>155.999000</td>\n",
       "      <td>76.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.511502</td>\n",
       "      <td>0.844515</td>\n",
       "      <td>155.965800</td>\n",
       "      <td>76.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.580445</td>\n",
       "      <td>0.818985</td>\n",
       "      <td>156.062200</td>\n",
       "      <td>76.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.547100</td>\n",
       "      <td>0.495680</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>155.986500</td>\n",
       "      <td>76.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.519033</td>\n",
       "      <td>0.841725</td>\n",
       "      <td>156.009600</td>\n",
       "      <td>76.918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>0.565097</td>\n",
       "      <td>0.822049</td>\n",
       "      <td>155.908600</td>\n",
       "      <td>76.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.526541</td>\n",
       "      <td>0.833723</td>\n",
       "      <td>155.981300</td>\n",
       "      <td>76.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>0.551526</td>\n",
       "      <td>0.839413</td>\n",
       "      <td>155.867000</td>\n",
       "      <td>76.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.549900</td>\n",
       "      <td>0.674312</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>155.705000</td>\n",
       "      <td>77.069000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>0.579509</td>\n",
       "      <td>0.820414</td>\n",
       "      <td>155.669500</td>\n",
       "      <td>77.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.647300</td>\n",
       "      <td>0.663802</td>\n",
       "      <td>0.812751</td>\n",
       "      <td>155.614600</td>\n",
       "      <td>77.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.631799</td>\n",
       "      <td>0.812870</td>\n",
       "      <td>155.587800</td>\n",
       "      <td>77.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.683061</td>\n",
       "      <td>0.796491</td>\n",
       "      <td>155.583900</td>\n",
       "      <td>77.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.638043</td>\n",
       "      <td>0.803385</td>\n",
       "      <td>155.590000</td>\n",
       "      <td>77.126000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 28.758499145507812, 'eval_accuracy': 0.9167105263157894, 'eval_f1': 0.9166299656987345, 'eval_precision': 0.916595346491176, 'eval_recall': 0.9167105263157895, 'eval_runtime': 97.9767, 'eval_samples_per_second': 77.569, 'epoch': 0.33, 'run': 'pretrained/roberta-base-ag_news-ORIG+INVSIB', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+INVSIB\n",
      "{'eval_loss': 34.00143051147461, 'eval_accuracy': 0.8217864923747277, 'eval_f1': 0.6221824558656399, 'eval_precision': 0.6439190515643213, 'eval_recall': 0.6080798774693251, 'eval_runtime': 89.3043, 'eval_samples_per_second': 77.096, 'epoch': 0.33, 'run': 'pretrained/roberta-base-ag_news-ORIG+INVSIB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b018327519d94f038c17f591eb2060fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36db13155a34e00976071a605bbd418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058ccc1ad7384ef09552b22a92d6744b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='12000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 12000/228000 1:01:00 < 18:18:22, 3.28 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.169300</td>\n",
       "      <td>0.588143</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>155.752400</td>\n",
       "      <td>77.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.586900</td>\n",
       "      <td>0.585704</td>\n",
       "      <td>0.804957</td>\n",
       "      <td>155.511500</td>\n",
       "      <td>77.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.557359</td>\n",
       "      <td>0.779747</td>\n",
       "      <td>155.505600</td>\n",
       "      <td>77.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>0.562697</td>\n",
       "      <td>0.786823</td>\n",
       "      <td>155.556800</td>\n",
       "      <td>77.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.595800</td>\n",
       "      <td>0.591833</td>\n",
       "      <td>0.799420</td>\n",
       "      <td>155.616700</td>\n",
       "      <td>77.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.600729</td>\n",
       "      <td>0.779856</td>\n",
       "      <td>155.601200</td>\n",
       "      <td>77.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.593605</td>\n",
       "      <td>0.794404</td>\n",
       "      <td>155.608500</td>\n",
       "      <td>77.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>0.614918</td>\n",
       "      <td>0.795494</td>\n",
       "      <td>155.603900</td>\n",
       "      <td>77.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>0.621258</td>\n",
       "      <td>0.782794</td>\n",
       "      <td>155.616100</td>\n",
       "      <td>77.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.557200</td>\n",
       "      <td>0.634508</td>\n",
       "      <td>0.785453</td>\n",
       "      <td>155.504800</td>\n",
       "      <td>77.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.576700</td>\n",
       "      <td>0.557939</td>\n",
       "      <td>0.793246</td>\n",
       "      <td>155.531000</td>\n",
       "      <td>77.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.593100</td>\n",
       "      <td>0.507361</td>\n",
       "      <td>0.789064</td>\n",
       "      <td>155.585700</td>\n",
       "      <td>77.128000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 24.32720375061035, 'eval_accuracy': 0.9046052631578947, 'eval_f1': 0.904234236570405, 'eval_precision': 0.9041800493775376, 'eval_recall': 0.9046052631578947, 'eval_runtime': 98.0354, 'eval_samples_per_second': 77.523, 'epoch': 0.16, 'run': 'pretrained/roberta-base-ag_news-ORIG+TextMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+TextMix\n",
      "{'eval_loss': 29.201152801513672, 'eval_accuracy': 0.8986201888162673, 'eval_f1': 0.6643465973185576, 'eval_precision': 0.6698015285063132, 'eval_recall': 0.6592862927257201, 'eval_runtime': 89.3629, 'eval_samples_per_second': 77.045, 'epoch': 0.16, 'run': 'pretrained/roberta-base-ag_news-ORIG+TextMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec022623a6b64d67b781642f435e66b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202b0486a71d474fb15e86204c30ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdcfe4260e14bf3b1161597c26f3dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='29000' max='342000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 29000/342000 3:05:22 < 33:20:58, 2.61 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.137700</td>\n",
       "      <td>0.766543</td>\n",
       "      <td>0.596303</td>\n",
       "      <td>234.370900</td>\n",
       "      <td>76.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.496281</td>\n",
       "      <td>0.659713</td>\n",
       "      <td>234.009600</td>\n",
       "      <td>76.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.519208</td>\n",
       "      <td>0.652801</td>\n",
       "      <td>234.516600</td>\n",
       "      <td>76.754000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.492097</td>\n",
       "      <td>0.662016</td>\n",
       "      <td>234.920600</td>\n",
       "      <td>76.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.516600</td>\n",
       "      <td>0.498778</td>\n",
       "      <td>0.656389</td>\n",
       "      <td>234.970700</td>\n",
       "      <td>76.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>0.495899</td>\n",
       "      <td>0.631686</td>\n",
       "      <td>235.117800</td>\n",
       "      <td>76.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.507700</td>\n",
       "      <td>0.457510</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>235.383400</td>\n",
       "      <td>76.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.479700</td>\n",
       "      <td>0.466726</td>\n",
       "      <td>0.675621</td>\n",
       "      <td>234.967200</td>\n",
       "      <td>76.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.537422</td>\n",
       "      <td>0.662960</td>\n",
       "      <td>234.501800</td>\n",
       "      <td>76.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.475589</td>\n",
       "      <td>0.659696</td>\n",
       "      <td>234.094800</td>\n",
       "      <td>76.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.566242</td>\n",
       "      <td>0.640234</td>\n",
       "      <td>233.932000</td>\n",
       "      <td>76.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.507831</td>\n",
       "      <td>0.669502</td>\n",
       "      <td>233.685000</td>\n",
       "      <td>77.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.512772</td>\n",
       "      <td>0.640135</td>\n",
       "      <td>233.631200</td>\n",
       "      <td>77.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>0.517268</td>\n",
       "      <td>0.670796</td>\n",
       "      <td>233.480800</td>\n",
       "      <td>77.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>0.500544</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>233.654000</td>\n",
       "      <td>77.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.482697</td>\n",
       "      <td>0.668430</td>\n",
       "      <td>233.310200</td>\n",
       "      <td>77.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.473600</td>\n",
       "      <td>0.443165</td>\n",
       "      <td>0.677857</td>\n",
       "      <td>233.968400</td>\n",
       "      <td>76.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.447918</td>\n",
       "      <td>0.660533</td>\n",
       "      <td>234.057500</td>\n",
       "      <td>76.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.454521</td>\n",
       "      <td>0.686323</td>\n",
       "      <td>234.007800</td>\n",
       "      <td>76.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.478685</td>\n",
       "      <td>0.658434</td>\n",
       "      <td>234.083000</td>\n",
       "      <td>76.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>0.488097</td>\n",
       "      <td>0.654606</td>\n",
       "      <td>234.006100</td>\n",
       "      <td>76.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>0.527654</td>\n",
       "      <td>0.639823</td>\n",
       "      <td>234.070900</td>\n",
       "      <td>76.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.473981</td>\n",
       "      <td>0.654303</td>\n",
       "      <td>234.080500</td>\n",
       "      <td>76.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.527121</td>\n",
       "      <td>0.640026</td>\n",
       "      <td>234.060000</td>\n",
       "      <td>76.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.509364</td>\n",
       "      <td>0.650299</td>\n",
       "      <td>234.016400</td>\n",
       "      <td>76.918000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.477895</td>\n",
       "      <td>0.675297</td>\n",
       "      <td>234.052500</td>\n",
       "      <td>76.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.519592</td>\n",
       "      <td>0.672169</td>\n",
       "      <td>234.222000</td>\n",
       "      <td>76.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.476549</td>\n",
       "      <td>0.669981</td>\n",
       "      <td>234.069700</td>\n",
       "      <td>76.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.518400</td>\n",
       "      <td>0.474122</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>233.991100</td>\n",
       "      <td>76.926000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 28.718870162963867, 'eval_accuracy': 0.9265789473684211, 'eval_f1': 0.9264409099390788, 'eval_precision': 0.9280269124277573, 'eval_recall': 0.926578947368421, 'eval_runtime': 98.0561, 'eval_samples_per_second': 77.507, 'epoch': 0.25, 'run': 'pretrained/roberta-base-ag_news-ORIG+SentMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+SentMix\n",
      "{'eval_loss': 34.066078186035156, 'eval_accuracy': 0.8335511982570806, 'eval_f1': 0.5908967108776653, 'eval_precision': 0.6685967602921301, 'eval_recall': 0.5524350655788238, 'eval_runtime': 89.4286, 'eval_samples_per_second': 76.989, 'epoch': 0.25, 'run': 'pretrained/roberta-base-ag_news-ORIG+SentMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22224d4ce454401bac4ce9756308150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f41d889c9d84531b49cab461089c998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-2682ce8e25ccad82.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc97573a75d943c08032aab9fba7fd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='30000' max='456000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 30000/456000 3:50:30 < 54:33:22, 2.17 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.945800</td>\n",
       "      <td>0.834376</td>\n",
       "      <td>0.380255</td>\n",
       "      <td>311.989400</td>\n",
       "      <td>76.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>0.441671</td>\n",
       "      <td>0.534052</td>\n",
       "      <td>311.506000</td>\n",
       "      <td>77.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.533294</td>\n",
       "      <td>311.220600</td>\n",
       "      <td>77.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.423524</td>\n",
       "      <td>0.543366</td>\n",
       "      <td>311.011100</td>\n",
       "      <td>77.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.437813</td>\n",
       "      <td>0.531892</td>\n",
       "      <td>310.881000</td>\n",
       "      <td>77.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.419100</td>\n",
       "      <td>0.427785</td>\n",
       "      <td>0.533463</td>\n",
       "      <td>310.851900</td>\n",
       "      <td>77.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.434439</td>\n",
       "      <td>0.536819</td>\n",
       "      <td>311.397400</td>\n",
       "      <td>77.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.419204</td>\n",
       "      <td>0.524049</td>\n",
       "      <td>311.396400</td>\n",
       "      <td>77.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.430208</td>\n",
       "      <td>0.530205</td>\n",
       "      <td>311.415300</td>\n",
       "      <td>77.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.439601</td>\n",
       "      <td>0.550988</td>\n",
       "      <td>311.383700</td>\n",
       "      <td>77.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.436322</td>\n",
       "      <td>0.525576</td>\n",
       "      <td>311.520900</td>\n",
       "      <td>77.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.406859</td>\n",
       "      <td>0.535155</td>\n",
       "      <td>311.574100</td>\n",
       "      <td>77.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.440877</td>\n",
       "      <td>0.547146</td>\n",
       "      <td>311.577000</td>\n",
       "      <td>77.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.437758</td>\n",
       "      <td>0.534883</td>\n",
       "      <td>311.645500</td>\n",
       "      <td>77.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.404700</td>\n",
       "      <td>0.378470</td>\n",
       "      <td>0.543998</td>\n",
       "      <td>311.587700</td>\n",
       "      <td>77.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.478550</td>\n",
       "      <td>0.522216</td>\n",
       "      <td>311.710300</td>\n",
       "      <td>76.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>0.423060</td>\n",
       "      <td>0.555349</td>\n",
       "      <td>311.776300</td>\n",
       "      <td>76.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.443862</td>\n",
       "      <td>0.539426</td>\n",
       "      <td>311.675600</td>\n",
       "      <td>77.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.393115</td>\n",
       "      <td>0.537741</td>\n",
       "      <td>311.650500</td>\n",
       "      <td>77.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.420753</td>\n",
       "      <td>0.561867</td>\n",
       "      <td>311.789600</td>\n",
       "      <td>76.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.432755</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>311.858900</td>\n",
       "      <td>76.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.424518</td>\n",
       "      <td>0.516944</td>\n",
       "      <td>311.947900</td>\n",
       "      <td>76.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.382459</td>\n",
       "      <td>0.551389</td>\n",
       "      <td>310.724300</td>\n",
       "      <td>77.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.416821</td>\n",
       "      <td>0.551301</td>\n",
       "      <td>311.916700</td>\n",
       "      <td>76.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.402700</td>\n",
       "      <td>0.411216</td>\n",
       "      <td>0.548122</td>\n",
       "      <td>312.006700</td>\n",
       "      <td>76.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.440959</td>\n",
       "      <td>0.544026</td>\n",
       "      <td>311.882100</td>\n",
       "      <td>76.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.449658</td>\n",
       "      <td>0.541842</td>\n",
       "      <td>311.232500</td>\n",
       "      <td>77.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.388928</td>\n",
       "      <td>0.542119</td>\n",
       "      <td>311.448900</td>\n",
       "      <td>77.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.411674</td>\n",
       "      <td>0.527553</td>\n",
       "      <td>311.979500</td>\n",
       "      <td>76.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.411724</td>\n",
       "      <td>0.541659</td>\n",
       "      <td>311.700700</td>\n",
       "      <td>76.997000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 03:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/roberta-base-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 29.938947677612305, 'eval_accuracy': 0.9242105263157895, 'eval_f1': 0.924116800973805, 'eval_precision': 0.9241857466700161, 'eval_recall': 0.9242105263157895, 'eval_runtime': 98.0989, 'eval_samples_per_second': 77.473, 'epoch': 0.2, 'run': 'pretrained/roberta-base-ag_news-ORIG+WordMix', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/roberta-base-ag_news-ORIG+WordMix\n",
      "{'eval_loss': 35.76468276977539, 'eval_accuracy': 0.831517792302106, 'eval_f1': 0.6124722567486625, 'eval_precision': 0.6178121955233269, 'eval_recall': 0.6137361046471246, 'eval_runtime': 89.4029, 'eval_samples_per_second': 77.011, 'epoch': 0.2, 'run': 'pretrained/roberta-base-ag_news-ORIG+WordMix'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Loading cached split indices for dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-e574b06a521f7d4b.arrow and C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-00ad71102627cc55.arrow\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477a63ce8edd44deb0549829f07d9909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1bb5fb6b3a4f3787ae473e1411b0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711dffad0b4849c3b9f8ded00299bec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='15000' max='114000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 15000/114000 1:51:54 < 12:18:41, 2.23 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.893100</td>\n",
       "      <td>0.431875</td>\n",
       "      <td>0.882368</td>\n",
       "      <td>0.882211</td>\n",
       "      <td>0.887275</td>\n",
       "      <td>0.882368</td>\n",
       "      <td>237.695000</td>\n",
       "      <td>31.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>0.504996</td>\n",
       "      <td>0.905921</td>\n",
       "      <td>0.905729</td>\n",
       "      <td>0.906243</td>\n",
       "      <td>0.905921</td>\n",
       "      <td>237.880500</td>\n",
       "      <td>31.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.478151</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909644</td>\n",
       "      <td>0.912840</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>237.747900</td>\n",
       "      <td>31.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.465701</td>\n",
       "      <td>0.910395</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.911163</td>\n",
       "      <td>0.910395</td>\n",
       "      <td>237.856200</td>\n",
       "      <td>31.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.471499</td>\n",
       "      <td>0.913026</td>\n",
       "      <td>0.912850</td>\n",
       "      <td>0.913047</td>\n",
       "      <td>0.913026</td>\n",
       "      <td>238.333600</td>\n",
       "      <td>31.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.524322</td>\n",
       "      <td>0.895395</td>\n",
       "      <td>0.894724</td>\n",
       "      <td>0.899958</td>\n",
       "      <td>0.895395</td>\n",
       "      <td>237.657000</td>\n",
       "      <td>31.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.596230</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>0.884514</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>0.884868</td>\n",
       "      <td>238.020200</td>\n",
       "      <td>31.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.455152</td>\n",
       "      <td>0.905658</td>\n",
       "      <td>0.905615</td>\n",
       "      <td>0.908236</td>\n",
       "      <td>0.905658</td>\n",
       "      <td>237.992200</td>\n",
       "      <td>31.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>0.469370</td>\n",
       "      <td>0.911447</td>\n",
       "      <td>0.910767</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.911447</td>\n",
       "      <td>237.797800</td>\n",
       "      <td>31.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.569938</td>\n",
       "      <td>0.896579</td>\n",
       "      <td>0.896157</td>\n",
       "      <td>0.901764</td>\n",
       "      <td>0.896579</td>\n",
       "      <td>237.771200</td>\n",
       "      <td>31.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.552843</td>\n",
       "      <td>0.876579</td>\n",
       "      <td>0.876284</td>\n",
       "      <td>0.893260</td>\n",
       "      <td>0.876579</td>\n",
       "      <td>237.744400</td>\n",
       "      <td>31.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.747948</td>\n",
       "      <td>0.849474</td>\n",
       "      <td>0.850883</td>\n",
       "      <td>0.868521</td>\n",
       "      <td>0.849474</td>\n",
       "      <td>237.763200</td>\n",
       "      <td>31.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>0.581328</td>\n",
       "      <td>0.887895</td>\n",
       "      <td>0.887087</td>\n",
       "      <td>0.893968</td>\n",
       "      <td>0.887895</td>\n",
       "      <td>237.754700</td>\n",
       "      <td>31.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.800100</td>\n",
       "      <td>0.596071</td>\n",
       "      <td>0.877237</td>\n",
       "      <td>0.877386</td>\n",
       "      <td>0.886461</td>\n",
       "      <td>0.877237</td>\n",
       "      <td>237.692000</td>\n",
       "      <td>31.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.874002</td>\n",
       "      <td>0.649079</td>\n",
       "      <td>0.574893</td>\n",
       "      <td>0.551034</td>\n",
       "      <td>0.649079</td>\n",
       "      <td>237.707100</td>\n",
       "      <td>31.972000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+ORIG\n",
      "{'eval_loss': 0.47149935364723206, 'eval_accuracy': 0.9130263157894737, 'eval_f1': 0.9128498614830755, 'eval_precision': 0.9130469836991691, 'eval_recall': 0.9130263157894737, 'eval_runtime': 237.9381, 'eval_samples_per_second': 31.941, 'epoch': 0.39, 'run': 'pretrained/xlnet-base-cased-ag_news-ORIG+ORIG', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+ORIG\n",
      "{'eval_loss': 0.8703216910362244, 'eval_accuracy': 0.8496732026143791, 'eval_f1': 0.6538763069868, 'eval_precision': 0.6731572192682987, 'eval_recall': 0.6364644046662674, 'eval_runtime': 201.756, 'eval_samples_per_second': 34.125, 'epoch': 0.39, 'run': 'pretrained/xlnet-base-cased-ag_news-ORIG+ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464d9e7cfb1f4936bf7918ea2eb16fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf48604179e447db518c82f74208bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdb6f8bda1c4e2489fc357b01b74f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='28000' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 28000/228000 3:28:16 < 24:47:49, 2.24 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.157400</td>\n",
       "      <td>0.443578</td>\n",
       "      <td>0.861316</td>\n",
       "      <td>0.860555</td>\n",
       "      <td>0.861548</td>\n",
       "      <td>0.861316</td>\n",
       "      <td>236.249700</td>\n",
       "      <td>32.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.543957</td>\n",
       "      <td>0.896974</td>\n",
       "      <td>0.896597</td>\n",
       "      <td>0.896916</td>\n",
       "      <td>0.896974</td>\n",
       "      <td>236.337100</td>\n",
       "      <td>32.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.591800</td>\n",
       "      <td>0.479478</td>\n",
       "      <td>0.898947</td>\n",
       "      <td>0.899018</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>0.898947</td>\n",
       "      <td>236.236600</td>\n",
       "      <td>32.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.580400</td>\n",
       "      <td>0.576850</td>\n",
       "      <td>0.896184</td>\n",
       "      <td>0.894642</td>\n",
       "      <td>0.899134</td>\n",
       "      <td>0.896184</td>\n",
       "      <td>236.248100</td>\n",
       "      <td>32.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.524765</td>\n",
       "      <td>0.908026</td>\n",
       "      <td>0.907709</td>\n",
       "      <td>0.908437</td>\n",
       "      <td>0.908026</td>\n",
       "      <td>236.271200</td>\n",
       "      <td>32.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.543400</td>\n",
       "      <td>0.457579</td>\n",
       "      <td>0.912763</td>\n",
       "      <td>0.912378</td>\n",
       "      <td>0.912797</td>\n",
       "      <td>0.912763</td>\n",
       "      <td>236.265200</td>\n",
       "      <td>32.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.547550</td>\n",
       "      <td>0.902763</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>0.910045</td>\n",
       "      <td>0.902763</td>\n",
       "      <td>236.216100</td>\n",
       "      <td>32.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.555692</td>\n",
       "      <td>0.908816</td>\n",
       "      <td>0.908492</td>\n",
       "      <td>0.908916</td>\n",
       "      <td>0.908816</td>\n",
       "      <td>236.278800</td>\n",
       "      <td>32.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.525100</td>\n",
       "      <td>0.490537</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>0.906092</td>\n",
       "      <td>0.909691</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>236.261700</td>\n",
       "      <td>32.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.483726</td>\n",
       "      <td>0.914868</td>\n",
       "      <td>0.914874</td>\n",
       "      <td>0.915743</td>\n",
       "      <td>0.914868</td>\n",
       "      <td>236.280000</td>\n",
       "      <td>32.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.452811</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>0.909641</td>\n",
       "      <td>0.912813</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>236.205700</td>\n",
       "      <td>32.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>0.533704</td>\n",
       "      <td>0.899737</td>\n",
       "      <td>0.899901</td>\n",
       "      <td>0.906575</td>\n",
       "      <td>0.899737</td>\n",
       "      <td>236.250800</td>\n",
       "      <td>32.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.530400</td>\n",
       "      <td>0.538870</td>\n",
       "      <td>0.899868</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.902951</td>\n",
       "      <td>0.899868</td>\n",
       "      <td>236.244600</td>\n",
       "      <td>32.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.421841</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.914952</td>\n",
       "      <td>0.916864</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>236.275600</td>\n",
       "      <td>32.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.527700</td>\n",
       "      <td>0.514363</td>\n",
       "      <td>0.902763</td>\n",
       "      <td>0.902119</td>\n",
       "      <td>0.904361</td>\n",
       "      <td>0.902763</td>\n",
       "      <td>236.278000</td>\n",
       "      <td>32.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>0.462205</td>\n",
       "      <td>0.915132</td>\n",
       "      <td>0.914878</td>\n",
       "      <td>0.915093</td>\n",
       "      <td>0.915132</td>\n",
       "      <td>236.278200</td>\n",
       "      <td>32.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.518400</td>\n",
       "      <td>0.863591</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>0.591621</td>\n",
       "      <td>0.604363</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>236.189400</td>\n",
       "      <td>32.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.420974</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.915638</td>\n",
       "      <td>0.915605</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>236.207800</td>\n",
       "      <td>32.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.541550</td>\n",
       "      <td>0.903026</td>\n",
       "      <td>0.902882</td>\n",
       "      <td>0.905670</td>\n",
       "      <td>0.903026</td>\n",
       "      <td>236.261300</td>\n",
       "      <td>32.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.722400</td>\n",
       "      <td>0.571949</td>\n",
       "      <td>0.873947</td>\n",
       "      <td>0.873242</td>\n",
       "      <td>0.881001</td>\n",
       "      <td>0.873947</td>\n",
       "      <td>236.254700</td>\n",
       "      <td>32.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.743900</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.885263</td>\n",
       "      <td>0.884102</td>\n",
       "      <td>0.888702</td>\n",
       "      <td>0.885263</td>\n",
       "      <td>236.218300</td>\n",
       "      <td>32.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.587468</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.891221</td>\n",
       "      <td>0.893457</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>236.205400</td>\n",
       "      <td>32.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.021500</td>\n",
       "      <td>0.942936</td>\n",
       "      <td>0.626974</td>\n",
       "      <td>0.636984</td>\n",
       "      <td>0.790020</td>\n",
       "      <td>0.626974</td>\n",
       "      <td>236.256400</td>\n",
       "      <td>32.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.166700</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.670658</td>\n",
       "      <td>0.586565</td>\n",
       "      <td>0.538414</td>\n",
       "      <td>0.670658</td>\n",
       "      <td>236.296000</td>\n",
       "      <td>32.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.294800</td>\n",
       "      <td>1.401967</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>236.178700</td>\n",
       "      <td>32.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.416300</td>\n",
       "      <td>1.393134</td>\n",
       "      <td>0.250263</td>\n",
       "      <td>0.100578</td>\n",
       "      <td>0.187541</td>\n",
       "      <td>0.250263</td>\n",
       "      <td>236.230000</td>\n",
       "      <td>32.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.405700</td>\n",
       "      <td>1.389687</td>\n",
       "      <td>0.250395</td>\n",
       "      <td>0.100820</td>\n",
       "      <td>0.312525</td>\n",
       "      <td>0.250395</td>\n",
       "      <td>236.142700</td>\n",
       "      <td>32.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.335400</td>\n",
       "      <td>1.388840</td>\n",
       "      <td>0.232237</td>\n",
       "      <td>0.130691</td>\n",
       "      <td>0.149523</td>\n",
       "      <td>0.232237</td>\n",
       "      <td>236.218200</td>\n",
       "      <td>32.174000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='454' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 07:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG for pretrained/xlnet-base-cased-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.4209737479686737, 'eval_accuracy': 0.9157894736842105, 'eval_f1': 0.9156375582128906, 'eval_precision': 0.915605058138296, 'eval_recall': 0.9157894736842105, 'eval_runtime': 237.3088, 'eval_samples_per_second': 32.026, 'epoch': 0.37, 'run': 'pretrained/xlnet-base-cased-ag_news-ORIG+INV', 'test': 'ORIG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sleev\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG for pretrained/xlnet-base-cased-ag_news-ORIG+INV\n",
      "{'eval_loss': 0.6510989665985107, 'eval_accuracy': 0.8264342774146696, 'eval_f1': 0.604001301328089, 'eval_precision': 0.6114328875586422, 'eval_recall': 0.6068399284220588, 'eval_runtime': 201.1389, 'eval_samples_per_second': 34.23, 'epoch': 0.37, 'run': 'pretrained/xlnet-base-cased-ag_news-ORIG+INV'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf5ed31e560402ba802cc5bfa84f742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bfb278b7664b3ea6c345fec7845a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\sleev\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a\\cache-6943bef4b721d7aa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71f6dbeed1a4470bf52a23d4a53ff1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9534' max='228000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9534/228000 1:29:46 < 34:17:22, 1.77 it/s, Epoch 0.13/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.175200</td>\n",
       "      <td>0.721647</td>\n",
       "      <td>0.715345</td>\n",
       "      <td>374.946300</td>\n",
       "      <td>32.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.596559</td>\n",
       "      <td>0.769013</td>\n",
       "      <td>374.938100</td>\n",
       "      <td>32.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.578555</td>\n",
       "      <td>0.772692</td>\n",
       "      <td>375.040500</td>\n",
       "      <td>31.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.597769</td>\n",
       "      <td>0.765442</td>\n",
       "      <td>374.840200</td>\n",
       "      <td>32.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.606800</td>\n",
       "      <td>0.605279</td>\n",
       "      <td>0.766563</td>\n",
       "      <td>375.221400</td>\n",
       "      <td>31.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.578200</td>\n",
       "      <td>0.587795</td>\n",
       "      <td>0.777467</td>\n",
       "      <td>375.103700</td>\n",
       "      <td>31.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.685981</td>\n",
       "      <td>0.754559</td>\n",
       "      <td>374.951000</td>\n",
       "      <td>32.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.638225</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>375.269200</td>\n",
       "      <td>31.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.587492</td>\n",
       "      <td>0.778258</td>\n",
       "      <td>375.408000</td>\n",
       "      <td>31.965000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-437929b93a19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0meval_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m    959\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m                             \u001b[1;31m# Revert to normal clipping otherwise, handling Apex or full precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m                             torch.nn.utils.clip_grad_norm_(\n\u001b[0m\u001b[0;32m    962\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unknown error"
     ]
    }
   ],
   "source": [
    "use_pretrain = False\n",
    "\n",
    "results = []\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "    for t in ['ORIG', 'INV', 'SIB', 'INVSIB', 'TextMix', 'SentMix', 'WordMix']: \n",
    "                        \n",
    "        soft_target = False\n",
    "        eval_only = False\n",
    "        \n",
    "        checkpoint = 'pretrained/' + MODEL_NAME + \"-ag_news-ORIG+\" + t \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        if t == 'ORIG':\n",
    "            train_dataset = load_dataset('ag_news', split='train')\n",
    "        else:\n",
    "            # load custom data    \n",
    "            text = npy_load(\"./assets/AG_NEWS/\" + t + \"/text.npy\")\n",
    "            label = npy_load(\"./assets/AG_NEWS/\" + t + \"/label.npy\")\n",
    "            if len(label.shape) > 1:\n",
    "                df = pd.DataFrame({'text': text, 'label': label.tolist()})\n",
    "                df.text = df.text.astype(str)\n",
    "                df.label = df.label.map(lambda y: np.array(y))\n",
    "            else:\n",
    "                df = pd.DataFrame({'text': text, 'label': label})\n",
    "                df.text = df.text.astype(str)\n",
    "                df.label = df.label.astype(object)\n",
    "            train_dataset = Dataset.from_pandas(df)  \n",
    "            \n",
    "            # load orig data\n",
    "            orig_dataset = load_dataset('ag_news', split='train')\n",
    "            df = orig_dataset.to_pandas()\n",
    "            df = df[df.columns[::-1]]\n",
    "            df.text = df.text.astype(str)\n",
    "            if len(label.shape) > 1:\n",
    "                df.label = df.label.map(one_hot_encode)\n",
    "            else:\n",
    "                df.label = df.label.astype(object)\n",
    "            orig_dataset = Dataset.from_pandas(df)\n",
    "            \n",
    "            # merge orig + custom data\n",
    "            train_dataset = concatenate_datasets([orig_dataset, train_dataset])\n",
    "            train_dataset.shuffle()\n",
    "            \n",
    "        if use_pretrain and os.path.exists(checkpoint):\n",
    "            print('loading {}...'.format(checkpoint))\n",
    "            MODEL_NAME = checkpoint\n",
    "            eval_only = True\n",
    "                \n",
    "        dataset_dict = train_dataset.train_test_split(\n",
    "            test_size = 0.05,\n",
    "            train_size = 0.95,\n",
    "            shuffle = True\n",
    "        )\n",
    "        train_dataset = dataset_dict['train']\n",
    "        eval_dataset = dataset_dict['test']\n",
    "        test_dataset = load_dataset('ag_news')['test']\n",
    "        test_dataset_20NG = get_20NG_test_dataset()\n",
    "        \n",
    "        # # reduce training time\n",
    "        # n = 10000\n",
    "        # train_dataset = Dataset.from_dict(train_dataset[:n])\n",
    "        # eval_dataset = Dataset.from_dict(eval_dataset[:n])\n",
    "        # test_dataset = Dataset.from_dict(test_dataset[:n])\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4).to(device)\n",
    "                \n",
    "        train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "        eval_dataset = eval_dataset.map(tokenize, batched=True, batch_size=len(eval_dataset))\n",
    "        test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "        test_dataset_20NG = test_dataset_20NG.map(tokenize, batched=True, batch_size=len(test_dataset_20NG))\n",
    "        train_dataset.rename_column_('label', 'labels')\n",
    "        eval_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset.rename_column_('label', 'labels')\n",
    "        test_dataset_20NG.rename_column_('label', 'labels')\n",
    "        train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        test_dataset_20NG.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        if len(np.array(train_dataset['labels']).shape) > 1:\n",
    "            soft_target = True\n",
    "\n",
    "        train_batch_size = 3\n",
    "        eval_batch_size = 32\n",
    "        num_epoch = 3\n",
    "        gradient_accumulation_steps=1\n",
    "        max_steps = int((len(train_dataset) * num_epoch / gradient_accumulation_steps) / train_batch_size)\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            seed=1,\n",
    "            # adafactor=True,\n",
    "            output_dir=checkpoint,\n",
    "            overwrite_output_dir=True,\n",
    "            max_steps=max_steps,\n",
    "            save_steps=int(max_steps / 10),\n",
    "            save_total_limit=1,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            per_device_eval_batch_size=eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "            warmup_steps=int(max_steps / 10),\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=2000,\n",
    "            logging_first_step=True,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            run_name=checkpoint,\n",
    "            label_names=['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "        )\n",
    "        \n",
    "        if soft_target:\n",
    "            trainer = Trainer_w_soft_target(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                compute_metrics=compute_metrics_w_soft_target,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                data_collator=DefaultCollator(),\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "            )\n",
    "        else: \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                compute_metrics=compute_metrics,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=test_dataset,\n",
    "                callbacks=[EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "            )\n",
    "\n",
    "        if not eval_only:\n",
    "            trainer.train()\n",
    "            \n",
    "        trainer.compute_metrics = compute_metrics\n",
    "        \n",
    "        # test with ORIG data\n",
    "        trainer.eval_dataset = test_dataset\n",
    "        out_orig = trainer.evaluate()\n",
    "        out_orig['run'] = checkpoint\n",
    "        out_orig['test'] = \"ORIG\"\n",
    "        print('ORIG for {}\\n{}'.format(checkpoint, out_orig))\n",
    "        \n",
    "        # test with 20NG data\n",
    "        trainer.eval_dataset = test_dataset_20NG\n",
    "        out_20NG = trainer.evaluate()\n",
    "        out_20NG['run'] = checkpoint\n",
    "        out_orig['test'] = \"20NG\"\n",
    "        print('20NG for {}\\n{}'.format(checkpoint, out_20NG))\n",
    "        \n",
    "        results.append(out_orig)\n",
    "        results.append(out_20NG)\n",
    "        \n",
    "        # run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>epoch</th>\n",
       "      <th>run</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403315</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>0.909406</td>\n",
       "      <td>0.909337</td>\n",
       "      <td>0.909737</td>\n",
       "      <td>99.7262</td>\n",
       "      <td>76.209</td>\n",
       "      <td>0.42</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+ORIG</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.738579</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.628058</td>\n",
       "      <td>0.629622</td>\n",
       "      <td>0.632722</td>\n",
       "      <td>90.5726</td>\n",
       "      <td>76.016</td>\n",
       "      <td>0.42</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+ORIG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388141</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.919906</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>99.5063</td>\n",
       "      <td>76.377</td>\n",
       "      <td>0.28</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+INV</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.626499</td>\n",
       "      <td>0.846042</td>\n",
       "      <td>0.647005</td>\n",
       "      <td>0.664907</td>\n",
       "      <td>0.631381</td>\n",
       "      <td>90.4282</td>\n",
       "      <td>76.138</td>\n",
       "      <td>0.28</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+INV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.322521</td>\n",
       "      <td>0.916579</td>\n",
       "      <td>0.916382</td>\n",
       "      <td>0.916738</td>\n",
       "      <td>0.916579</td>\n",
       "      <td>99.4292</td>\n",
       "      <td>76.436</td>\n",
       "      <td>0.32</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+SIB</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.492338</td>\n",
       "      <td>0.837763</td>\n",
       "      <td>0.635321</td>\n",
       "      <td>0.649990</td>\n",
       "      <td>0.629993</td>\n",
       "      <td>90.3602</td>\n",
       "      <td>76.195</td>\n",
       "      <td>0.32</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+SIB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.862549</td>\n",
       "      <td>0.912368</td>\n",
       "      <td>0.912109</td>\n",
       "      <td>0.912452</td>\n",
       "      <td>0.912368</td>\n",
       "      <td>99.7859</td>\n",
       "      <td>76.163</td>\n",
       "      <td>0.28</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+INVSIB</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.260082</td>\n",
       "      <td>0.843718</td>\n",
       "      <td>0.634814</td>\n",
       "      <td>0.640585</td>\n",
       "      <td>0.633381</td>\n",
       "      <td>90.6306</td>\n",
       "      <td>75.968</td>\n",
       "      <td>0.28</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+INVSIB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.897173</td>\n",
       "      <td>0.922237</td>\n",
       "      <td>0.922229</td>\n",
       "      <td>0.922574</td>\n",
       "      <td>0.922237</td>\n",
       "      <td>99.1179</td>\n",
       "      <td>76.676</td>\n",
       "      <td>0.32</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+TextMix</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.254307</td>\n",
       "      <td>0.882789</td>\n",
       "      <td>0.652780</td>\n",
       "      <td>0.674804</td>\n",
       "      <td>0.633557</td>\n",
       "      <td>89.9611</td>\n",
       "      <td>76.533</td>\n",
       "      <td>0.32</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+TextMix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.166885</td>\n",
       "      <td>0.923421</td>\n",
       "      <td>0.923246</td>\n",
       "      <td>0.923434</td>\n",
       "      <td>0.923421</td>\n",
       "      <td>99.6893</td>\n",
       "      <td>76.237</td>\n",
       "      <td>0.21</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+SentMix</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.715605</td>\n",
       "      <td>0.861002</td>\n",
       "      <td>0.621718</td>\n",
       "      <td>0.656002</td>\n",
       "      <td>0.599705</td>\n",
       "      <td>90.6367</td>\n",
       "      <td>75.963</td>\n",
       "      <td>0.21</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+SentMix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29.581367</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>0.919720</td>\n",
       "      <td>0.920734</td>\n",
       "      <td>0.919605</td>\n",
       "      <td>99.6425</td>\n",
       "      <td>76.273</td>\n",
       "      <td>0.20</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+WordMix</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34.089382</td>\n",
       "      <td>0.866376</td>\n",
       "      <td>0.637997</td>\n",
       "      <td>0.644896</td>\n",
       "      <td>0.632628</td>\n",
       "      <td>90.4663</td>\n",
       "      <td>76.106</td>\n",
       "      <td>0.20</td>\n",
       "      <td>pretrained/bert-base-uncased-ag_news-ORIG+WordMix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.909079</td>\n",
       "      <td>0.909006</td>\n",
       "      <td>0.910443</td>\n",
       "      <td>0.909079</td>\n",
       "      <td>98.4120</td>\n",
       "      <td>77.226</td>\n",
       "      <td>0.37</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+ORIG</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.618136</td>\n",
       "      <td>0.872331</td>\n",
       "      <td>0.642597</td>\n",
       "      <td>0.645720</td>\n",
       "      <td>0.640844</td>\n",
       "      <td>89.6930</td>\n",
       "      <td>76.762</td>\n",
       "      <td>0.37</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+ORIG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.419195</td>\n",
       "      <td>0.915395</td>\n",
       "      <td>0.915411</td>\n",
       "      <td>0.915605</td>\n",
       "      <td>0.915395</td>\n",
       "      <td>98.2980</td>\n",
       "      <td>77.316</td>\n",
       "      <td>0.30</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+INV</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.829528</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.625390</td>\n",
       "      <td>0.662512</td>\n",
       "      <td>0.595617</td>\n",
       "      <td>89.6263</td>\n",
       "      <td>76.819</td>\n",
       "      <td>0.30</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+INV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28.414679</td>\n",
       "      <td>0.913947</td>\n",
       "      <td>0.913873</td>\n",
       "      <td>0.914734</td>\n",
       "      <td>0.913947</td>\n",
       "      <td>97.9732</td>\n",
       "      <td>77.572</td>\n",
       "      <td>0.22</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+SIB</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35.062111</td>\n",
       "      <td>0.862164</td>\n",
       "      <td>0.633687</td>\n",
       "      <td>0.672779</td>\n",
       "      <td>0.605695</td>\n",
       "      <td>89.2990</td>\n",
       "      <td>77.101</td>\n",
       "      <td>0.22</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+SIB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28.758499</td>\n",
       "      <td>0.916711</td>\n",
       "      <td>0.916630</td>\n",
       "      <td>0.916595</td>\n",
       "      <td>0.916711</td>\n",
       "      <td>97.9767</td>\n",
       "      <td>77.569</td>\n",
       "      <td>0.33</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+INVSIB</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.001431</td>\n",
       "      <td>0.821786</td>\n",
       "      <td>0.622182</td>\n",
       "      <td>0.643919</td>\n",
       "      <td>0.608080</td>\n",
       "      <td>89.3043</td>\n",
       "      <td>77.096</td>\n",
       "      <td>0.33</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+INVSIB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24.327204</td>\n",
       "      <td>0.904605</td>\n",
       "      <td>0.904234</td>\n",
       "      <td>0.904180</td>\n",
       "      <td>0.904605</td>\n",
       "      <td>98.0354</td>\n",
       "      <td>77.523</td>\n",
       "      <td>0.16</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+TextMix</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29.201153</td>\n",
       "      <td>0.898620</td>\n",
       "      <td>0.664347</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.659286</td>\n",
       "      <td>89.3629</td>\n",
       "      <td>77.045</td>\n",
       "      <td>0.16</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+TextMix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28.718870</td>\n",
       "      <td>0.926579</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.928027</td>\n",
       "      <td>0.926579</td>\n",
       "      <td>98.0561</td>\n",
       "      <td>77.507</td>\n",
       "      <td>0.25</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+SentMix</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>34.066078</td>\n",
       "      <td>0.833551</td>\n",
       "      <td>0.590897</td>\n",
       "      <td>0.668597</td>\n",
       "      <td>0.552435</td>\n",
       "      <td>89.4286</td>\n",
       "      <td>76.989</td>\n",
       "      <td>0.25</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+SentMix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29.938948</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>0.924186</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>98.0989</td>\n",
       "      <td>77.473</td>\n",
       "      <td>0.20</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+WordMix</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35.764683</td>\n",
       "      <td>0.831518</td>\n",
       "      <td>0.612472</td>\n",
       "      <td>0.617812</td>\n",
       "      <td>0.613736</td>\n",
       "      <td>89.4029</td>\n",
       "      <td>77.011</td>\n",
       "      <td>0.20</td>\n",
       "      <td>pretrained/roberta-base-ag_news-ORIG+WordMix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.471499</td>\n",
       "      <td>0.913026</td>\n",
       "      <td>0.912850</td>\n",
       "      <td>0.913047</td>\n",
       "      <td>0.913026</td>\n",
       "      <td>237.9381</td>\n",
       "      <td>31.941</td>\n",
       "      <td>0.39</td>\n",
       "      <td>pretrained/xlnet-base-cased-ag_news-ORIG+ORIG</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.870322</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.653876</td>\n",
       "      <td>0.673157</td>\n",
       "      <td>0.636464</td>\n",
       "      <td>201.7560</td>\n",
       "      <td>34.125</td>\n",
       "      <td>0.39</td>\n",
       "      <td>pretrained/xlnet-base-cased-ag_news-ORIG+ORIG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.420974</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.915638</td>\n",
       "      <td>0.915605</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>237.3088</td>\n",
       "      <td>32.026</td>\n",
       "      <td>0.37</td>\n",
       "      <td>pretrained/xlnet-base-cased-ag_news-ORIG+INV</td>\n",
       "      <td>20NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.651099</td>\n",
       "      <td>0.826434</td>\n",
       "      <td>0.604001</td>\n",
       "      <td>0.611433</td>\n",
       "      <td>0.606840</td>\n",
       "      <td>201.1389</td>\n",
       "      <td>34.230</td>\n",
       "      <td>0.37</td>\n",
       "      <td>pretrained/xlnet-base-cased-ag_news-ORIG+INV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eval_loss  eval_accuracy   eval_f1  eval_precision  eval_recall  \\\n",
       "0    0.403315       0.909737  0.909406        0.909337     0.909737   \n",
       "1    0.738579       0.837037  0.628058        0.629622     0.632722   \n",
       "2    0.388141       0.919605  0.919407        0.919906     0.919605   \n",
       "3    0.626499       0.846042  0.647005        0.664907     0.631381   \n",
       "4   28.322521       0.916579  0.916382        0.916738     0.916579   \n",
       "5   30.492338       0.837763  0.635321        0.649990     0.629993   \n",
       "6   29.862549       0.912368  0.912109        0.912452     0.912368   \n",
       "7   32.260082       0.843718  0.634814        0.640585     0.633381   \n",
       "8   30.897173       0.922237  0.922229        0.922574     0.922237   \n",
       "9   35.254307       0.882789  0.652780        0.674804     0.633557   \n",
       "10  28.166885       0.923421  0.923246        0.923434     0.923421   \n",
       "11  31.715605       0.861002  0.621718        0.656002     0.599705   \n",
       "12  29.581367       0.919605  0.919720        0.920734     0.919605   \n",
       "13  34.089382       0.866376  0.637997        0.644896     0.632628   \n",
       "14   0.476541       0.909079  0.909006        0.910443     0.909079   \n",
       "15   0.618136       0.872331  0.642597        0.645720     0.640844   \n",
       "16   0.419195       0.915395  0.915411        0.915605     0.915395   \n",
       "17   0.829528       0.792157  0.625390        0.662512     0.595617   \n",
       "18  28.414679       0.913947  0.913873        0.914734     0.913947   \n",
       "19  35.062111       0.862164  0.633687        0.672779     0.605695   \n",
       "20  28.758499       0.916711  0.916630        0.916595     0.916711   \n",
       "21  34.001431       0.821786  0.622182        0.643919     0.608080   \n",
       "22  24.327204       0.904605  0.904234        0.904180     0.904605   \n",
       "23  29.201153       0.898620  0.664347        0.669802     0.659286   \n",
       "24  28.718870       0.926579  0.926441        0.928027     0.926579   \n",
       "25  34.066078       0.833551  0.590897        0.668597     0.552435   \n",
       "26  29.938948       0.924211  0.924117        0.924186     0.924211   \n",
       "27  35.764683       0.831518  0.612472        0.617812     0.613736   \n",
       "28   0.471499       0.913026  0.912850        0.913047     0.913026   \n",
       "29   0.870322       0.849673  0.653876        0.673157     0.636464   \n",
       "30   0.420974       0.915789  0.915638        0.915605     0.915789   \n",
       "31   0.651099       0.826434  0.604001        0.611433     0.606840   \n",
       "\n",
       "    eval_runtime  eval_samples_per_second  epoch  \\\n",
       "0        99.7262                   76.209   0.42   \n",
       "1        90.5726                   76.016   0.42   \n",
       "2        99.5063                   76.377   0.28   \n",
       "3        90.4282                   76.138   0.28   \n",
       "4        99.4292                   76.436   0.32   \n",
       "5        90.3602                   76.195   0.32   \n",
       "6        99.7859                   76.163   0.28   \n",
       "7        90.6306                   75.968   0.28   \n",
       "8        99.1179                   76.676   0.32   \n",
       "9        89.9611                   76.533   0.32   \n",
       "10       99.6893                   76.237   0.21   \n",
       "11       90.6367                   75.963   0.21   \n",
       "12       99.6425                   76.273   0.20   \n",
       "13       90.4663                   76.106   0.20   \n",
       "14       98.4120                   77.226   0.37   \n",
       "15       89.6930                   76.762   0.37   \n",
       "16       98.2980                   77.316   0.30   \n",
       "17       89.6263                   76.819   0.30   \n",
       "18       97.9732                   77.572   0.22   \n",
       "19       89.2990                   77.101   0.22   \n",
       "20       97.9767                   77.569   0.33   \n",
       "21       89.3043                   77.096   0.33   \n",
       "22       98.0354                   77.523   0.16   \n",
       "23       89.3629                   77.045   0.16   \n",
       "24       98.0561                   77.507   0.25   \n",
       "25       89.4286                   76.989   0.25   \n",
       "26       98.0989                   77.473   0.20   \n",
       "27       89.4029                   77.011   0.20   \n",
       "28      237.9381                   31.941   0.39   \n",
       "29      201.7560                   34.125   0.39   \n",
       "30      237.3088                   32.026   0.37   \n",
       "31      201.1389                   34.230   0.37   \n",
       "\n",
       "                                                  run  test  \n",
       "0      pretrained/bert-base-uncased-ag_news-ORIG+ORIG  20NG  \n",
       "1      pretrained/bert-base-uncased-ag_news-ORIG+ORIG   NaN  \n",
       "2       pretrained/bert-base-uncased-ag_news-ORIG+INV  20NG  \n",
       "3       pretrained/bert-base-uncased-ag_news-ORIG+INV   NaN  \n",
       "4       pretrained/bert-base-uncased-ag_news-ORIG+SIB  20NG  \n",
       "5       pretrained/bert-base-uncased-ag_news-ORIG+SIB   NaN  \n",
       "6    pretrained/bert-base-uncased-ag_news-ORIG+INVSIB  20NG  \n",
       "7    pretrained/bert-base-uncased-ag_news-ORIG+INVSIB   NaN  \n",
       "8   pretrained/bert-base-uncased-ag_news-ORIG+TextMix  20NG  \n",
       "9   pretrained/bert-base-uncased-ag_news-ORIG+TextMix   NaN  \n",
       "10  pretrained/bert-base-uncased-ag_news-ORIG+SentMix  20NG  \n",
       "11  pretrained/bert-base-uncased-ag_news-ORIG+SentMix   NaN  \n",
       "12  pretrained/bert-base-uncased-ag_news-ORIG+WordMix  20NG  \n",
       "13  pretrained/bert-base-uncased-ag_news-ORIG+WordMix   NaN  \n",
       "14          pretrained/roberta-base-ag_news-ORIG+ORIG  20NG  \n",
       "15          pretrained/roberta-base-ag_news-ORIG+ORIG   NaN  \n",
       "16           pretrained/roberta-base-ag_news-ORIG+INV  20NG  \n",
       "17           pretrained/roberta-base-ag_news-ORIG+INV   NaN  \n",
       "18           pretrained/roberta-base-ag_news-ORIG+SIB  20NG  \n",
       "19           pretrained/roberta-base-ag_news-ORIG+SIB   NaN  \n",
       "20        pretrained/roberta-base-ag_news-ORIG+INVSIB  20NG  \n",
       "21        pretrained/roberta-base-ag_news-ORIG+INVSIB   NaN  \n",
       "22       pretrained/roberta-base-ag_news-ORIG+TextMix  20NG  \n",
       "23       pretrained/roberta-base-ag_news-ORIG+TextMix   NaN  \n",
       "24       pretrained/roberta-base-ag_news-ORIG+SentMix  20NG  \n",
       "25       pretrained/roberta-base-ag_news-ORIG+SentMix   NaN  \n",
       "26       pretrained/roberta-base-ag_news-ORIG+WordMix  20NG  \n",
       "27       pretrained/roberta-base-ag_news-ORIG+WordMix   NaN  \n",
       "28      pretrained/xlnet-base-cased-ag_news-ORIG+ORIG  20NG  \n",
       "29      pretrained/xlnet-base-cased-ag_news-ORIG+ORIG   NaN  \n",
       "30       pretrained/xlnet-base-cased-ag_news-ORIG+INV  20NG  \n",
       "31       pretrained/xlnet-base-cased-ag_news-ORIG+INV   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_SST2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00554915f7ad47b9b80d65294dbfdd37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0768ccf7a2e64f819c7401d7db258d16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14dc24ef59d341a88d1bdb69f3cacde6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "212a6447739d45b5b57e5815ff538f57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "367cfe385d38427dbdf4325a70c0dc2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46cc6e7671244f1d9167855a45a36af8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b1f7506e1a44d109d918b1f16d6bb75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5f641be531341dbb007330b7e245169",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00554915f7ad47b9b80d65294dbfdd37",
      "value": 1382015
     }
    },
    "59b96dd300ae4a56b2d58ca0de0bb7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd27134d896448b6b385ce45da7556ee",
       "IPY_MODEL_c92040617a854d8d96cc8ba678f0b271"
      ],
      "layout": "IPY_MODEL_e3c71b92f2a0484bb70123a86f855f9d"
     }
    },
    "7158ce3f315647aba9299519fcec4be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81821a97e02445539ccabcc2091cba95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b1f7506e1a44d109d918b1f16d6bb75",
       "IPY_MODEL_f177b91513ec4039bc7c6e61d15db9a2"
      ],
      "layout": "IPY_MODEL_212a6447739d45b5b57e5815ff538f57"
     }
    },
    "c92040617a854d8d96cc8ba678f0b271": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46cc6e7671244f1d9167855a45a36af8",
      "placeholder": "​",
      "style": "IPY_MODEL_14dc24ef59d341a88d1bdb69f3cacde6",
      "value": " 798k/798k [00:00&lt;00:00, 1.99MB/s]"
     }
    },
    "d5f641be531341dbb007330b7e245169": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd27134d896448b6b385ce45da7556ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f86a86b6b9c64cc989e89b27693d8a2f",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_367cfe385d38427dbdf4325a70c0dc2e",
      "value": 798011
     }
    },
    "e3c71b92f2a0484bb70123a86f855f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f177b91513ec4039bc7c6e61d15db9a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0768ccf7a2e64f819c7401d7db258d16",
      "placeholder": "​",
      "style": "IPY_MODEL_7158ce3f315647aba9299519fcec4be7",
      "value": " 1.38M/1.38M [00:00&lt;00:00, 5.04MB/s]"
     }
    },
    "f86a86b6b9c64cc989e89b27693d8a2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
