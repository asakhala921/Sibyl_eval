{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_true, y_pred):\n",
    "    total = y_true.size(0)\n",
    "    correct = (y_pred == y_true).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def get_acc_at_k(y_true, y_pred, k=2):\n",
    "    y_true = torch.tensor(y_true) if type(y_true) != torch.Tensor else y_true\n",
    "    y_pred = torch.tensor(y_pred) if type(y_pred) != torch.Tensor else y_pred\n",
    "    total = len(y_true)\n",
    "    y_weights, y_idx = torch.topk(y_true, k=k, dim=-1)\n",
    "    out_weights, out_idx = torch.topk(y_pred, k=k, dim=-1)\n",
    "    correct = torch.sum(torch.eq(y_idx, out_idx) * y_weights)\n",
    "    acc = correct / total\n",
    "    return acc.item()\n",
    "\n",
    "class CustomModelWrapper:\n",
    "    def __init__(self, model, tokenizer, batch_size=4):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(self.model.parameters()).device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __call__(self, text_input_list):\n",
    "        out = []\n",
    "        i = 0\n",
    "        while i < len(text_input_list):\n",
    "            batch = text_input_list[i : i + self.batch_size]\n",
    "            encoding = self.tokenizer(batch, padding=True, truncation=True, max_length=250, return_tensors='pt')\n",
    "            outputs = self.model(encoding['input_ids'].to(self.device), attention_mask=encoding['attention_mask'].to(self.device))\n",
    "            # preds = torch.nn.functional.softmax(outputs.logits, dim=1).detach().cpu()\n",
    "            out.append(outputs.logits.detach().cpu())\n",
    "            i += self.batch_size\n",
    "        out = torch.cat(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-ORIG, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-ORIG', 'test_acc': 0.9871999999999994}\n",
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-INV, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-INV', 'test_acc': 0.7443000000000005}\n",
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-SIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-SIB', 'test_acc': 0.7052740745272483}\n",
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-INVSIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-INVSIB', 'test_acc': 0.7184545924036227}\n",
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-TextMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-TextMix', 'test_acc': 0.8232}\n",
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-SentMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-SentMix', 'test_acc': 0.8133999999999999}\n",
      "MODEL_NAME: textattack/bert-base-uncased-SST-2, dataset: SST2-WordMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-SST-2', 'dataset': 'SST2-WordMix', 'test_acc': 0.7411999999999999}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db84b95b5f6418ca22ae170a1ced919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=525.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9080f25dab6e4c6a8d18d5ec068b0fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863e3ed7bffd45958b1cd54c80eadd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83c3513568c4167b941483d77ca046a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08bdab5e78841eeaf1edda45e907b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dbfecf2434438ca091825317d079ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501003010.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-ORIG, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-ORIG', 'test_acc': 0.9625999999999998}\n",
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-INV, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-INV', 'test_acc': 0.7603}\n",
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-SIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-SIB', 'test_acc': 0.6835538111180094}\n",
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-INVSIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-INVSIB', 'test_acc': 0.7172590575584402}\n",
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-TextMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-TextMix', 'test_acc': 0.8348000000000002}\n",
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-SentMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-SentMix', 'test_acc': 0.8379000000000005}\n",
      "MODEL_NAME: textattack/roberta-base-SST-2, dataset: SST2-WordMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-SST-2', 'dataset': 'SST2-WordMix', 'test_acc': 0.7451999999999995}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-ORIG, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-ORIG', 'test_acc': 0.9966999999999999}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-INV, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-INV', 'test_acc': 0.8707000000000003}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-SIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-SIB', 'test_acc': 0.6263205652793788}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-INVSIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-INVSIB', 'test_acc': 0.7476135029318455}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-TextMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-TextMix', 'test_acc': 0.6350003955604787}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-SentMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-SentMix', 'test_acc': 0.4823382956552988}\n",
      "MODEL_NAME: textattack/bert-base-uncased-ag-news, dataset: AG_NEWS-WordMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/bert-base-uncased-ag-news', 'dataset': 'AG_NEWS-WordMix', 'test_acc': 0.6024598559873575}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3c2cc3e37e4d6a96fa2921ea2c7de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=754.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e4299cb545473caf22565af81da05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798293.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fd90a8e92c49dbb14bfd584dd77de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456356.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ad8c4ec4734319b4168ccc56d7ca8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=239.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32d7694d7b44915a7bc256c8322585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cef22e646c4c6fbdfb5bee2fe1f30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501009162.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-ag-news were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-ORIG, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-ORIG', 'test_acc': 0.985799999999999}\n",
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-INV, is_soft_label: False\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-INV', 'test_acc': 0.8363999999999998}\n",
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-SIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-SIB', 'test_acc': 0.6100767345357251}\n",
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-INVSIB, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-INVSIB', 'test_acc': 0.6975635848964127}\n",
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-TextMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-TextMix', 'test_acc': 0.6133232601808546}\n",
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-SentMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-SentMix', 'test_acc': 0.47063869278065484}\n",
      "MODEL_NAME: textattack/roberta-base-ag-news, dataset: AG_NEWS-WordMix, is_soft_label: True\n",
      "{'MODEL_NAME': 'textattack/roberta-base-ag-news', 'dataset': 'AG_NEWS-WordMix', 'test_acc': 0.5504593993039856}\n"
     ]
    }
   ],
   "source": [
    "num_suites = 100\n",
    "num_tests = 100\n",
    "\n",
    "datasets = [('AG_NEWS', 'ag-news'), ('SST2', 'SST-2')]\n",
    "tranforms = ['ORIG', 'INV', 'SIB', 'INVSIB', 'TextMix', 'SentMix', 'WordMix']\n",
    "MODEL_NAMES = [\n",
    "    \"textattack/bert-base-uncased-SST-2\",\n",
    "    \"textattack/roberta-base-SST-2\",\n",
    "    \"textattack/bert-base-uncased-ag-news\",\n",
    "    \"textattack/roberta-base-ag-news\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for MODEL_NAME in MODEL_NAMES:\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "    mw = CustomModelWrapper(model, tokenizer)\n",
    "    \n",
    "    for d, d_ in datasets:\n",
    "        \n",
    "        if d_ not in MODEL_NAME:\n",
    "            continue\n",
    "        \n",
    "        for t in tranforms:\n",
    "            \n",
    "            text = npy_load(\"./assets/\" + d + \"/\" + t + \"/text.npy\")\n",
    "            label = npy_load(\"./assets/\" + d + \"/\" + t + \"/label.npy\")\n",
    "            is_soft_label = False\n",
    "            if len(label.shape) > 1:\n",
    "                is_soft_label = True\n",
    "                                \n",
    "            # print(\"MODEL_NAME: {}, dataset: {}-{}, is_soft_label: {}\".format(MODEL_NAME, d, t, is_soft_label))\n",
    "            \n",
    "            accs = []\n",
    "            for i in range(num_suites):\n",
    "                \n",
    "                idx = np.random.choice(np.arange(len(text)), num_tests, replace=False)\n",
    "                text_sample = text[idx]\n",
    "                label_sample = label[idx]\n",
    "                               \n",
    "                logits = mw([str(x) for x in text_sample])\n",
    "                y_true = torch.tensor(label_sample)\n",
    "                \n",
    "                if is_soft_label:\n",
    "                    acc = get_acc_at_k(y_true, logits, k=2)\n",
    "                else:\n",
    "                    soft_m = torch.softmax(logits, dim=1)\n",
    "                    y_pred = torch.argmax(soft_m, dim=1)\n",
    "                    acc = get_acc(y_true, y_pred)\n",
    "                    \n",
    "                accs.append(acc)\n",
    "                \n",
    "            test_acc = sum(accs) / len(accs)\n",
    "                \n",
    "            out = {\n",
    "                \"MODEL_NAME\": MODEL_NAME,\n",
    "                \"dataset\": d + \"-\" + t,\n",
    "                \"test_acc\": test_acc\n",
    "            }\n",
    "            \n",
    "            print(out)\n",
    "            results.append(out)\n",
    "            \n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-ORIG</td>\n",
       "      <td>0.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-INV</td>\n",
       "      <td>0.744300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-SIB</td>\n",
       "      <td>0.705274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-INVSIB</td>\n",
       "      <td>0.718455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-TextMix</td>\n",
       "      <td>0.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-SentMix</td>\n",
       "      <td>0.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>textattack/bert-base-uncased-SST-2</td>\n",
       "      <td>SST2-WordMix</td>\n",
       "      <td>0.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-ORIG</td>\n",
       "      <td>0.962600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-INV</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-SIB</td>\n",
       "      <td>0.683554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-INVSIB</td>\n",
       "      <td>0.717259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-TextMix</td>\n",
       "      <td>0.834800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-SentMix</td>\n",
       "      <td>0.837900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>textattack/roberta-base-SST-2</td>\n",
       "      <td>SST2-WordMix</td>\n",
       "      <td>0.745200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-ORIG</td>\n",
       "      <td>0.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-INV</td>\n",
       "      <td>0.870700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-SIB</td>\n",
       "      <td>0.626321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-INVSIB</td>\n",
       "      <td>0.747614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-TextMix</td>\n",
       "      <td>0.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-SentMix</td>\n",
       "      <td>0.482338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>textattack/bert-base-uncased-ag-news</td>\n",
       "      <td>AG_NEWS-WordMix</td>\n",
       "      <td>0.602460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-ORIG</td>\n",
       "      <td>0.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-INV</td>\n",
       "      <td>0.836400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-SIB</td>\n",
       "      <td>0.610077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-INVSIB</td>\n",
       "      <td>0.697564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-TextMix</td>\n",
       "      <td>0.613323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-SentMix</td>\n",
       "      <td>0.470639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>textattack/roberta-base-ag-news</td>\n",
       "      <td>AG_NEWS-WordMix</td>\n",
       "      <td>0.550459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              MODEL_NAME          dataset  test_acc\n",
       "0     textattack/bert-base-uncased-SST-2        SST2-ORIG  0.987200\n",
       "1     textattack/bert-base-uncased-SST-2         SST2-INV  0.744300\n",
       "2     textattack/bert-base-uncased-SST-2         SST2-SIB  0.705274\n",
       "3     textattack/bert-base-uncased-SST-2      SST2-INVSIB  0.718455\n",
       "4     textattack/bert-base-uncased-SST-2     SST2-TextMix  0.823200\n",
       "5     textattack/bert-base-uncased-SST-2     SST2-SentMix  0.813400\n",
       "6     textattack/bert-base-uncased-SST-2     SST2-WordMix  0.741200\n",
       "7          textattack/roberta-base-SST-2        SST2-ORIG  0.962600\n",
       "8          textattack/roberta-base-SST-2         SST2-INV  0.760300\n",
       "9          textattack/roberta-base-SST-2         SST2-SIB  0.683554\n",
       "10         textattack/roberta-base-SST-2      SST2-INVSIB  0.717259\n",
       "11         textattack/roberta-base-SST-2     SST2-TextMix  0.834800\n",
       "12         textattack/roberta-base-SST-2     SST2-SentMix  0.837900\n",
       "13         textattack/roberta-base-SST-2     SST2-WordMix  0.745200\n",
       "14  textattack/bert-base-uncased-ag-news     AG_NEWS-ORIG  0.996700\n",
       "15  textattack/bert-base-uncased-ag-news      AG_NEWS-INV  0.870700\n",
       "16  textattack/bert-base-uncased-ag-news      AG_NEWS-SIB  0.626321\n",
       "17  textattack/bert-base-uncased-ag-news   AG_NEWS-INVSIB  0.747614\n",
       "18  textattack/bert-base-uncased-ag-news  AG_NEWS-TextMix  0.635000\n",
       "19  textattack/bert-base-uncased-ag-news  AG_NEWS-SentMix  0.482338\n",
       "20  textattack/bert-base-uncased-ag-news  AG_NEWS-WordMix  0.602460\n",
       "21       textattack/roberta-base-ag-news     AG_NEWS-ORIG  0.985800\n",
       "22       textattack/roberta-base-ag-news      AG_NEWS-INV  0.836400\n",
       "23       textattack/roberta-base-ag-news      AG_NEWS-SIB  0.610077\n",
       "24       textattack/roberta-base-ag-news   AG_NEWS-INVSIB  0.697564\n",
       "25       textattack/roberta-base-ag-news  AG_NEWS-TextMix  0.613323\n",
       "26       textattack/roberta-base-ag-news  AG_NEWS-SentMix  0.470639\n",
       "27       textattack/roberta-base-ag-news  AG_NEWS-WordMix  0.550459"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_models_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
