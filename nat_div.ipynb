{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow as tf\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# tf.compat.v1.flags.DEFINE_string('f','','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "def get_ttr_by_ids(input_ids):\n",
    "    '''\n",
    "    Type Token Ratio (TTR)\n",
    "    higher -> more diversity\n",
    "    '''\n",
    "    token_ids, counts = np.unique(input_ids, return_counts=True)\n",
    "    idx = np.isin(token_ids, [0, 101, 102], assume_unique=True, invert=True)\n",
    "    token_ids, counts = token_ids[idx], counts[idx]\n",
    "    ttr = len(token_ids) / counts.sum() * 100\n",
    "    return ttr\n",
    "\n",
    "def get_ttr_by_text(text):\n",
    "    '''\n",
    "    Type Token Ratio (TTR)\n",
    "    higher -> more diversity\n",
    "    '''\n",
    "    tokens = [word_tokenize(x) for x in text]\n",
    "    tokens = [item for sublist in tokens for item in sublist]\n",
    "    toks, tok_counts = np.unique(tokens, return_counts=True)\n",
    "    ttr = len(toks) / tok_counts.sum() * 100\n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: datasets.load_metric('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Fabrice\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\0989b2f25cefa5363b32fb8de03c83fe189c82f971eabcd6248d372510de0c71\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Performs basic checks...\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Loading model...\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "# Init tokenizer and metrics\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "bertscore_metric = load_metric(\"bertscore\")\n",
    "bleurt_metric = load_metric(\"bleurt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1000 examples of ('glue', 'sst2')...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4\\cache-82e6569f2ab6ac94.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sst2 ORIG\n",
      "loading sst2 INV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b772920b94bf6bb6bce0d4dd43768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading sst2 SIB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dd049df3e44c9e80ab88cc25bbfcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating BERTScores...\n",
      "precision tensor(1.)\n",
      "recall tensor(1.)\n",
      "f1 tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting precision to be 0.\n",
      "Warning: Empty candidate sentence detected; setting precision to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision tensor(0.7802)\n",
      "recall tensor(0.8215)\n",
      "f1 tensor(0.7993)\n",
      "precision tensor(0.7920)\n",
      "recall tensor(0.8252)\n",
      "f1 tensor(0.8078)\n",
      "calculating BLEURT Scores...\n",
      "score 1.0111331019800156\n",
      "score -1.5404506878353654\n"
     ]
    }
   ],
   "source": [
    "datasets = [('glue', 'sst2'), 'ag_news']\n",
    "\n",
    "for d in datasets:\n",
    "    \n",
    "    n = min(len(ORIG_train_dataset), len(INV_train_dataset), len(SIB_train_dataset))\n",
    "    \n",
    "    print('processing {} examples of {}...'.format(n, d))\n",
    "    \n",
    "    if type(d) == tuple and d[0] == 'glue':\n",
    "        task = 'sentiment'\n",
    "        SIB_type = 'SIB'\n",
    "        ORIG_train_dataset = load_dataset(d[0], d[1])['train']\n",
    "        ORIG_train_dataset.rename_column_('sentence', 'text')\n",
    "        d = d[1]\n",
    "    else:\n",
    "        task = 'topic'\n",
    "        SIB_type = 'SIB-mix'\n",
    "        ORIG_train_dataset = load_dataset(d)['train']\n",
    "        \n",
    "    print('loading {} ORIG'.format(d))\n",
    "    ORIG_train_dataset_tok = ORIG_train_dataset.map(tokenize, batched=True, batch_size=len(ORIG_train_dataset))\n",
    "    ORIG_train_dataset_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    \n",
    "    # INV\n",
    "    print('loading {} INV'.format(d))\n",
    "    text = npy_load(\"./assets/\" + d + \"/\" + task + \"/INV/text2.npy\")\n",
    "    label = npy_load(\"./assets/\" + d + \"/\" + task + \"/INV/label2.npy\")\n",
    "    df = pd.DataFrame({'text': text, 'label': label})\n",
    "    df.text = df.text.astype(str)\n",
    "    df.label = df.label.astype(int)\n",
    "    INV_train_dataset = Dataset.from_pandas(df)\n",
    "    INV_train_dataset_tok = INV_train_dataset.map(tokenize, batched=True, batch_size=len(INV_train_dataset))\n",
    "    INV_train_dataset_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "    # SIB\n",
    "    print('loading {} {}'.format(d, SIB_type))\n",
    "    text = npy_load(\"./assets/\" + d + \"/\" + task + \"/\" + SIB_type + \"/text2.npy\")\n",
    "    label = npy_load(\"./assets/\" + d + \"/\" + task + \"/\" + SIB_type + \"/label2.npy\")\n",
    "    if SIB_type == 'SIB-mix':\n",
    "        df = pd.DataFrame({'text': text, 'label': label.tolist()})\n",
    "        df.text = df.text.astype(str)\n",
    "        df.label = df.label.map(lambda y: np.array(y))\n",
    "    else:\n",
    "        df = pd.DataFrame({'text': text, 'label': label})\n",
    "        df.text = df.text.astype(str)\n",
    "        df.label = df.label.astype(int)\n",
    "    SIB_train_dataset = Dataset.from_pandas(df)\n",
    "    SIB_train_dataset_tok = SIB_train_dataset.map(tokenize, batched=True, batch_size=len(SIB_train_dataset))\n",
    "    SIB_train_dataset_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    \n",
    "    # Naturalness | BERTScore\n",
    "    print('calculating BERTScores...')\n",
    "    \n",
    "    scores = bertscore_metric._compute(ORIG, ORIG, lang=\"en\")\n",
    "    for key, value in list(scores.items())[:-1]:\n",
    "        print('ORIG - ORIG', key, value.mean())\n",
    "        \n",
    "    scores = bertscore_metric._compute(INV, ORIG, lang=\"en\")\n",
    "    for key, value in list(scores.items())[:-1]:\n",
    "        print('INV - ORIG', key, value.mean())\n",
    "        \n",
    "    scores = bertscore_metric._compute(SIB, ORIG, lang=\"en\")\n",
    "    for key, value in list(scores.items())[:-1]:\n",
    "        print('SIB - ORIG', key, value.mean())\n",
    "        \n",
    "    # Naturalness | BLEURT Scores\n",
    "    print('calculating BLEURT Scores...')\n",
    "    \n",
    "    scores = bleurt_metric._compute(ORIG, ORIG)\n",
    "    print('ORIG - ORIG score', np.array(scores['scores']).mean())\n",
    "        \n",
    "    scores = bleurt_metric._compute(INV, ORIG)\n",
    "    print('INV - ORIG score', np.array(scores['scores']).mean())\n",
    "\n",
    "    scores = bleurt_metric._compute(SIB, ORIG)\n",
    "    print('SIB - ORIG score', np.array(scores['scores']).mean())\n",
    "    \n",
    "    # Diversity | TTR (lexical diversity)\n",
    "    \n",
    "    # by input_ids (tokenizing replaces many words with [UNK] and reduces lexical diversity)\n",
    "    print('ORIG TTR: {0:0.2f} %'.format(get_ttr_by_ids(ORIG_train_dataset_tok['input_ids'][:n])))\n",
    "    print('INV  TTR: {0:0.2f} %'.format(get_ttr_by_ids(INV_train_dataset_tok['input_ids'][:n])))\n",
    "    print('SIB  TTR: {0:0.2f} %'.format(get_ttr_by_ids(SIB_train_dataset_tok['input_ids'][:n])))\n",
    "    \n",
    "    # by text\n",
    "    print('ORIG TTR: {0:0.2f} %'.format(get_ttr_by_text(ORIG_train_dataset['text'][:n])))\n",
    "    print('INV  TTR: {0:0.2f} %'.format(get_ttr_by_text(INV_train_dataset['text'][:n])))\n",
    "    print('SIB  TTR: {0:0.2f} %'.format(get_ttr_by_text(SIB_train_dataset['text'][:n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalness Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore_metric = load_metric(\"bertscore\")\n",
    "\n",
    "n = 10000\n",
    "ORIG = ORIG_train_dataset['text'][:n]\n",
    "INV = INV_train_dataset['text'][:n]\n",
    "SIB = SIB_train_dataset['text'][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision tensor(1.)\n",
      "recall tensor(1.)\n",
      "f1 tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "scores = bertscore_metric._compute(ORIG, ORIG, lang=\"en\")\n",
    "for key, value in list(scores.items())[:-1]:\n",
    "    print(key, value.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting precision to be 0.\n",
      "Warning: Empty candidate sentence detected; setting precision to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision tensor(0.7802)\n",
      "recall tensor(0.8215)\n",
      "f1 tensor(0.7993)\n"
     ]
    }
   ],
   "source": [
    "scores = bertscore_metric._compute(INV, ORIG, lang=\"en\")\n",
    "for key, value in list(scores.items())[:-1]:\n",
    "    print(key, value.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision tensor(0.7920)\n",
      "recall tensor(0.8252)\n",
      "f1 tensor(0.8078)\n"
     ]
    }
   ],
   "source": [
    "scores = bertscore_metric._compute(SIB, ORIG, lang=\"en\")\n",
    "for key, value in list(scores.items())[:-1]:\n",
    "    print(key, value.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEURT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: datasets.load_metric('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Fabrice\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\0989b2f25cefa5363b32fb8de03c83fe189c82f971eabcd6248d372510de0c71\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Performs basic checks...\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Loading model...\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "bleurt_metric = load_metric(\"bleurt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1.0065633410215378\n"
     ]
    }
   ],
   "source": [
    "scores = bleurt_metric._compute(ORIG, ORIG)\n",
    "print('score', np.array(scores['scores']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score -1.563182808160782\n"
     ]
    }
   ],
   "source": [
    "scores = bleurt_metric._compute(INV, ORIG)\n",
    "print('score', np.array(scores['scores']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score -1.6391020435094834\n"
     ]
    }
   ],
   "source": [
    "scores = bleurt_metric._compute(SIB, ORIG)\n",
    "print('score', np.array(scores['scores']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def get_ttr_by_ids(input_ids):\n",
    "    '''\n",
    "    Type Token Ratio (TTR)\n",
    "    higher -> more diversity\n",
    "    '''\n",
    "    token_ids, counts = np.unique(input_ids, return_counts=True)\n",
    "    idx = np.isin(token_ids, [0, 101, 102], assume_unique=True, invert=True)\n",
    "    token_ids, counts = token_ids[idx], counts[idx]\n",
    "    ttr = len(token_ids) / counts.sum() * 100\n",
    "    return ttr\n",
    "\n",
    "def get_ttr_by_text(text):\n",
    "    '''\n",
    "    Type Token Ratio (TTR)\n",
    "    higher -> more diversity\n",
    "    '''\n",
    "    tokens = [word_tokenize(x) for x in text]\n",
    "    tokens = [item for sublist in tokens for item in sublist]\n",
    "    toks, tok_counts = np.unique(tokens, return_counts=True)\n",
    "    ttr = len(toks) / tok_counts.sum() * 100\n",
    "    return ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG TTR: 1.68 %\n",
      "INV  TTR: 2.08 %\n",
      "SIB  TTR: 0.92 %\n"
     ]
    }
   ],
   "source": [
    "n = 60614\n",
    "print('ORIG TTR: {0:0.2f} %'.format(get_ttr_by_ids(ORIG_train_dataset_tok['input_ids'][:n])))\n",
    "print('INV  TTR: {0:0.2f} %'.format(get_ttr_by_ids(INV_train_dataset_tok['input_ids'][:n])))\n",
    "print('SIB  TTR: {0:0.2f} %'.format(get_ttr_by_ids(SIB_train_dataset_tok['input_ids'][:n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG TTR: 2.58 %\n",
      "INV  TTR: 15.63 %\n",
      "SIB  TTR: 2.57 %\n"
     ]
    }
   ],
   "source": [
    "n = 60614\n",
    "print('ORIG TTR: {0:0.2f} %'.format(get_ttr_by_text(ORIG_train_dataset['text'][:n])))\n",
    "print('INV  TTR: {0:0.2f} %'.format(get_ttr_by_text(INV_train_dataset['text'][:n])))\n",
    "print('SIB  TTR: {0:0.2f} %'.format(get_ttr_by_text(SIB_train_dataset['text'][:n])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.326202392578125"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_dist = torch.ones(tokenizer.vocab_size) * (1./tokenizer.vocab_size)\n",
    "max_entropy = torch.distributions.Categorical(probs=uniform_dist).entropy().item()\n",
    "max_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1144,  0.1937,  0.1250,  ..., -0.3827,  0.2107,  0.5407],\n",
      "         [ 0.5308,  0.3207,  0.3665,  ..., -0.0036,  0.7579,  0.0388],\n",
      "         [-0.4877,  0.8849,  0.4256,  ..., -0.6976,  0.4458,  0.1231],\n",
      "         ...,\n",
      "         [-0.7003, -0.1815,  0.3297,  ..., -0.4838,  0.0680,  0.8901],\n",
      "         [-1.0355, -0.2567, -0.0317,  ...,  0.3197,  0.3999,  0.1795],\n",
      "         [ 0.6080,  0.2610, -0.3131,  ...,  0.0311, -0.6283, -0.1994]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "\n",
    "print(outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.encode(\"I love NY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.11437133,  0.19371387,  0.12495928, ..., -0.3826907 ,\n",
       "          0.21065906,  0.5407081 ],\n",
       "        [ 0.53082454,  0.32074875,  0.3664592 , ..., -0.00360663,\n",
       "          0.7578603 ,  0.03884365],\n",
       "        [-0.4876514 ,  0.8849247 ,  0.42556354, ..., -0.697621  ,\n",
       "          0.44583374,  0.12309406],\n",
       "        ...,\n",
       "        [-0.70027876, -0.18150657,  0.32969624, ..., -0.4837927 ,\n",
       "          0.06802326,  0.8900844 ],\n",
       "        [-1.0354625 , -0.2566779 , -0.03165251, ...,  0.31974295,\n",
       "          0.39990267,  0.17954752],\n",
       "        [ 0.60799193,  0.2609697 , -0.31307226, ...,  0.03109809,\n",
       "         -0.62827194, -0.19942497]]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.059098"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = outputs.last_hidden_state.detach().numpy().squeeze().mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00907731, -0.00968672, -0.01235135, -0.01130538, -0.01403303,\n",
       "       -0.01283057, -0.01095144, -0.01752734], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = p / p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09285002, 0.09908357, 0.12633954, 0.11564054, 0.14354114,\n",
       "       0.13124135, 0.11202013, 0.17928374], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.326202392578125"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
